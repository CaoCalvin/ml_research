{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5e364c",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c054d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dill in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (0.3.9)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadr in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pyreadr) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas>=1.2.0->pyreadr) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas>=1.2.0->pyreadr) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas>=1.2.0->pyreadr) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas>=1.2.0->pyreadr) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadr) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==2.1.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from xgboost) (2.1.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from xgboost) (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from seaborn) (2.1.0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typeguard in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from typeguard) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyQt6 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (6.8.0)\n",
      "Requirement already satisfied: PyQt6-sip<14,>=13.8 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from PyQt6) (13.9.1)\n",
      "Requirement already satisfied: PyQt6-Qt6<6.9.0,>=6.8.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from PyQt6) (6.8.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smogn in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from smogn) (2.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from smogn) (2.2.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from smogn) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas->smogn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas->smogn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas->smogn) (2024.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from tqdm->smogn) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->smogn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from seaborn) (2.1.0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from imbalanced-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from imbalanced-learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from imbalanced-learn) (1.6.0)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from shap) (2.1.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from shap) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from shap) (24.2)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from shap) (0.61.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from numba->shap) (0.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas->shap) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas->shap) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (0.61.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from numba) (0.44.0)\n",
      "Requirement already satisfied: numpy<2.2,>=1.24 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from numba) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install dill\n",
    "%pip install pyreadr\n",
    "%pip install scikit-learn\n",
    "%pip install pandas\n",
    "%pip install numpy==2.1.0\n",
    "%pip install xgboost\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install typeguard\n",
    "%pip install PyQt6\n",
    "%pip install smogn\n",
    "%pip install seaborn\n",
    "%pip install imbalanced-learn\n",
    "%pip install shap\n",
    "%pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a6cbc7-e77d-47fa-b099-e0f911c53168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kevin\\dev\\ml_research\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Library to check function types of imported modules\n",
    "from typeguard import install_import_hook\n",
    "\n",
    "# Data import and export\n",
    "import pyreadr\n",
    "import dill\n",
    "\n",
    "# Data management libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, percentileofscore\n",
    "\n",
    "# Plotting libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Model training and evaluation\n",
    "import shap\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "import xgboost as xgb\n",
    "\n",
    "# Preprocessing\n",
    "from smogn import smoter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# K-fold cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Custom functions for plotting, data operations, and model training\n",
    "with install_import_hook('custom_ml_plots'):\n",
    "    import custom_ml_plots as cmp\n",
    "with install_import_hook('custom_dataset_tools'):\n",
    "    import custom_dataset_tools as cdt\n",
    "with install_import_hook('basic_ml_operations'):\n",
    "    import basic_ml_operations as bmo\n",
    "with install_import_hook('ml_data_objects'):\n",
    "    import ml_data_objects as mdo\n",
    "with install_import_hook('pandas_relational_algebra'):\n",
    "    import pandas_relational_algebra as pra\n",
    "\n",
    "# Global parameters\n",
    "RANDOM_STATE = 42\n",
    "TOP_THRESHOLD_QUANTILE = 0.8  # Values to test: 0.5, 0.6, 0.7, 0.8, 0.9\n",
    "SMOGN_PREPROCESS = True\n",
    "UNDERSAMPLE = True\n",
    "SHAP = False # Set to True to run SHAP analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c80ae051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dill session\n",
    "dill.load_session(r\"C:\\Users\\kevin\\dev\\ml_research\\saved_data_and_plots\\thresh_0.8_undersample_False\\project_ipynb_env_RO.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91967ef",
   "metadata": {},
   "source": [
    "## Setup Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4180a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shaded_scatter_grids(y_preds_grid: np.ndarray, y_test_grid: np.ndarray, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, pearson_grid: np.ndarray, plot_title: str) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot predictions vs actuals and colour by pearson coefficient and add best fit\n",
    "    Created: 2024/11/30\n",
    "\n",
    "    Args:\n",
    "        y_preds_grid (np.ndarray): 2D array of predicted values from different models.\n",
    "        y_test_grid (np.ndarray): 2D array of actual values corresponding to the predictions.\n",
    "        axis1_params (mdo.AxisParams): Hyperparameters for the first axis.\n",
    "        axis2_params (mdo.AxisParams): Hyperparameters for the second axis.\n",
    "        pearson_grid (np.ndarray): 2D array of Pearson coefficients for each model.\n",
    "        plot_title (str): Title of the plot.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: The resulting figure object containing the scatter plots.\n",
    "    \"\"\"\n",
    "    # Create a grid of scatter plots with predictions vs actuals\n",
    "    fig, axs = cmp.create_scatter_grid(y_preds_grid, y_test_grid, axis1_params, axis2_params, plot_title)\n",
    "\n",
    "    # Color the scatter plots by Pearson coefficient and add best fit lines and title\n",
    "    cmp.color_spectrum(fig, axs, pearson_grid, label=\"Pearson Coefficient\")\n",
    "    cmp.add_best_fit(axs)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b3abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shaded_roc_grids(y_preds_grid: np.ndarray, y_test_grid: np.ndarray, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, f1_grid: np.ndarray, plot_title: str) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot predictions vs actuals and colour by f1 score and add best fit\n",
    "    Created: 2024/12/22\n",
    "\n",
    "    Args:\n",
    "        y_preds_grid (np.ndarray): 2D array of predicted probabilities from different models.\n",
    "        y_test_grid (np.ndarray): 2D array of actual binary values corresponding to the predictions.\n",
    "        axis1_params (mdo.AxisParams): Hyperparameters for the first axis.\n",
    "        axis2_params (mdo.AxisParams): Hyperparameters for the second axis.\n",
    "        f1_grid (np.ndarray): 2D array of F1 scores for each model.\n",
    "        plot_title (str): Title of the plot.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: The resulting figure object containing the ROC plots.\n",
    "    \"\"\"\n",
    "    # Create a grid of ROC plots with predictions vs actuals\n",
    "    fig, axs = cmp.create_roc_grid(y_preds_grid, y_test_grid, axis1_params, axis2_params, plot_title)\n",
    "\n",
    "    # Color the ROC plots by F1 score and add best fit lines and title\n",
    "    cmp.color_spectrum(fig, axs, f1_grid, label=\"F1 Score\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13ebd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores average metrics for each model for final comparison\n",
    "# See Montesinos-Lopez research paper and README for details on metrics and the different models\n",
    "B_average_metrics = pd.DataFrame(columns=['F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "R_average_metrics = pd.DataFrame(columns=['Pearson', 'F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "RO_average_metrics = pd.DataFrame(columns=['Pearson', 'F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "\n",
    "# Add existing GBLUP regression model data from Montesinos-Lopez paper\n",
    "B_average_metrics.loc['GBLUP'] =  [0.411, 0.696, 0.577, 0.180]\n",
    "R_average_metrics.loc['GBLUP'] =  [None, 0.215, 0.128, 0.987, 0.164]\n",
    "RO_average_metrics.loc['GBLUP'] = [None, 0.487, 0.711, 0.699, 0.304]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "740e548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(data: pd.DataFrame, title: str, x_ax_label: str = 'Grain Yield (GY)', y_ax_label: str = 'Frequency', vline_value: float = None) -> None:\n",
    "    \"\"\"\n",
    "    Create a stacked histogram of grain yield values for each column in the DataFrame.\n",
    "    Created: 2024/01/12\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame containing values; can have multiple columns for a stacked histogram\n",
    "        title (str): Title of the plot\n",
    "        x_ax_label (str): Label for the x-axis (default is 'Grain Yield (GY)')\n",
    "        y_ax_label (str): Label for the y-axis (default is 'Frequency')\n",
    "        vline_value (float, optional): Value at which to draw a dotted red vertical line (default is None)\n",
    "    \"\"\"\n",
    "    # Plot stacked histogram for each column in the DataFrame\n",
    "    data.plot.hist(stacked=True, bins=60, edgecolor='black', alpha=0.7)\n",
    "\n",
    "    # Add labels for x-axis and y-axis\n",
    "    plt.xlabel(x_ax_label)\n",
    "    plt.ylabel(y_ax_label)\n",
    "    \n",
    "    # Add title to the plot\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Draw a dotted red vertical line if vline_value is specified\n",
    "    if vline_value is not None:\n",
    "        plt.axvline(x=vline_value, color='red', linestyle='--', linewidth=1.5)\n",
    "    \n",
    "    # Save the plot as an SVG file in the specified storage directory\n",
    "    plt.savefig(f'{storage_dir}\\\\{title}.svg', format=\"svg\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    \n",
    "    # Close the plot to free up memory\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3df08d",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a24d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_numbered_subdir():\n",
    "    \"\"\"\n",
    "    Creates a new subdirectory within the 'saved_data_and_plots' directory, \n",
    "    with a name that is the next available number in sequence, formatted as a \n",
    "    three-digit number (e.g., '001', '002', etc.).\n",
    "    Created: 2024/01/01\n",
    "    Returns:\n",
    "        str: The path to the newly created numbered subdirectory.\n",
    "    \"\"\"\n",
    "    # Define the parent directory where subdirectories will be created\n",
    "    parent_dir = \"saved_data_and_plots\"\n",
    "    \n",
    "    # Create parent directory if it doesn't exist\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    \n",
    "    # List all existing directories within the parent directory\n",
    "    existing_dirs = [d for d in os.listdir(parent_dir) \n",
    "                    if os.path.isdir(os.path.join(parent_dir, d))]\n",
    "    \n",
    "    # Extract numeric values from directory names and find the next available number\n",
    "    existing_nums = [int(d) for d in existing_dirs if d.isdigit()]\n",
    "    next_num = max(existing_nums + [-1]) + 1\n",
    "    \n",
    "    # Create the new numbered directory with the next available number\n",
    "    new_dir = os.path.join(parent_dir, f\"{next_num:03d}\")\n",
    "    os.makedirs(new_dir)\n",
    "    \n",
    "    # Return the path to the newly created directory\n",
    "    return new_dir\n",
    "\n",
    "# Create a new numbered subdirectory and store its path in the variable 'storage_dir'\n",
    "storage_dir = create_numbered_subdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e06ae33-23b5-42a2-a4c1-e063428c27b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GID6569128</th>\n",
       "      <td>6.119272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6569128</th>\n",
       "      <td>5.905515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6569128</th>\n",
       "      <td>2.160587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6569128</th>\n",
       "      <td>6.456711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688880</th>\n",
       "      <td>3.616688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GY\n",
       "GID                 \n",
       "GID6569128  6.119272\n",
       "GID6569128  5.905515\n",
       "GID6569128  2.160587\n",
       "GID6569128  6.456711\n",
       "GID6688880  3.616688"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>766.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.517416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.333979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.305651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.301989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.517454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.748336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.394285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GY\n",
       "count  766.000000\n",
       "mean     5.517416\n",
       "std      0.333979\n",
       "min      4.305651\n",
       "25%      5.301989\n",
       "50%      5.517454\n",
       "75%      5.748336\n",
       "max      6.394285"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "eyt1 = pyreadr.read_r('./data/eyt1.RData')\n",
    "\n",
    "# Extract training example labels\n",
    "y = eyt1['Pheno_Disc_Env1'][['GY']]\n",
    "\n",
    "# Set index to gene IDs and sort by index\n",
    "y = y.set_index(eyt1['Pheno_Disc_Env1']['GID'])\n",
    "y = y.sort_index()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "display(y.head())\n",
    "\n",
    "# Check for missing values\n",
    "cdt.assert_no_bad_values(y)\n",
    "\n",
    "# Each seed was planted in 4 different environments, but we don't care about environmental differences\n",
    "# So we take the average of every group of four rows to reduce the dataset to 1/4 its original size\n",
    "y = cdt.avg_rows(y, 4)\n",
    "\n",
    "# Plot histogram of grain yield values\n",
    "histogram(y, 'GY, Unscaled')\n",
    "\n",
    "# Display summary statistics of the dataset\n",
    "y.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c6a9b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID6569128</th>\n",
       "      <th>GID6688880</th>\n",
       "      <th>GID6688916</th>\n",
       "      <th>GID6688933</th>\n",
       "      <th>GID6688934</th>\n",
       "      <th>GID6688949</th>\n",
       "      <th>GID6689407</th>\n",
       "      <th>GID6689482</th>\n",
       "      <th>GID6689550</th>\n",
       "      <th>GID6738288</th>\n",
       "      <th>...</th>\n",
       "      <th>GID6939899</th>\n",
       "      <th>GID6939900</th>\n",
       "      <th>GID6939902</th>\n",
       "      <th>GID6939903</th>\n",
       "      <th>GID6939904</th>\n",
       "      <th>GID6939917</th>\n",
       "      <th>GID6939919</th>\n",
       "      <th>GID6939938</th>\n",
       "      <th>GID6939941</th>\n",
       "      <th>GID6939945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GID6569128</th>\n",
       "      <td>0.788801</td>\n",
       "      <td>-0.006443</td>\n",
       "      <td>0.025987</td>\n",
       "      <td>-0.138795</td>\n",
       "      <td>-0.157880</td>\n",
       "      <td>0.096213</td>\n",
       "      <td>-0.110899</td>\n",
       "      <td>0.013069</td>\n",
       "      <td>-0.040445</td>\n",
       "      <td>0.007931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125612</td>\n",
       "      <td>0.133808</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>0.127674</td>\n",
       "      <td>0.130468</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.091188</td>\n",
       "      <td>0.074009</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.199459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688880</th>\n",
       "      <td>-0.006443</td>\n",
       "      <td>0.980542</td>\n",
       "      <td>0.064585</td>\n",
       "      <td>-0.168773</td>\n",
       "      <td>-0.081006</td>\n",
       "      <td>0.078890</td>\n",
       "      <td>-0.201346</td>\n",
       "      <td>0.124671</td>\n",
       "      <td>0.253505</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072171</td>\n",
       "      <td>0.061650</td>\n",
       "      <td>0.057898</td>\n",
       "      <td>0.079085</td>\n",
       "      <td>0.061086</td>\n",
       "      <td>0.104630</td>\n",
       "      <td>0.113878</td>\n",
       "      <td>0.108757</td>\n",
       "      <td>0.154718</td>\n",
       "      <td>0.004447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688916</th>\n",
       "      <td>0.025987</td>\n",
       "      <td>0.064585</td>\n",
       "      <td>1.170073</td>\n",
       "      <td>-0.021636</td>\n",
       "      <td>-0.031717</td>\n",
       "      <td>0.101532</td>\n",
       "      <td>-0.196780</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>0.126464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428609</td>\n",
       "      <td>0.423184</td>\n",
       "      <td>0.427788</td>\n",
       "      <td>0.408326</td>\n",
       "      <td>0.426844</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.209395</td>\n",
       "      <td>0.240468</td>\n",
       "      <td>0.255337</td>\n",
       "      <td>0.163524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688933</th>\n",
       "      <td>-0.138795</td>\n",
       "      <td>-0.168773</td>\n",
       "      <td>-0.021636</td>\n",
       "      <td>0.879004</td>\n",
       "      <td>0.443678</td>\n",
       "      <td>-0.080560</td>\n",
       "      <td>0.402479</td>\n",
       "      <td>-0.218803</td>\n",
       "      <td>-0.102718</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079312</td>\n",
       "      <td>-0.087824</td>\n",
       "      <td>-0.089912</td>\n",
       "      <td>-0.067028</td>\n",
       "      <td>-0.084206</td>\n",
       "      <td>-0.140529</td>\n",
       "      <td>-0.088961</td>\n",
       "      <td>-0.096740</td>\n",
       "      <td>-0.159136</td>\n",
       "      <td>-0.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688934</th>\n",
       "      <td>-0.157880</td>\n",
       "      <td>-0.081006</td>\n",
       "      <td>-0.031717</td>\n",
       "      <td>0.443678</td>\n",
       "      <td>0.996666</td>\n",
       "      <td>-0.140766</td>\n",
       "      <td>0.395843</td>\n",
       "      <td>-0.310471</td>\n",
       "      <td>-0.138902</td>\n",
       "      <td>0.088169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016690</td>\n",
       "      <td>-0.017375</td>\n",
       "      <td>-0.026372</td>\n",
       "      <td>-0.014478</td>\n",
       "      <td>-0.016350</td>\n",
       "      <td>-0.098509</td>\n",
       "      <td>-0.052304</td>\n",
       "      <td>-0.012778</td>\n",
       "      <td>-0.100318</td>\n",
       "      <td>-0.154557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6939917</th>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.104630</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>-0.140529</td>\n",
       "      <td>-0.098509</td>\n",
       "      <td>0.048248</td>\n",
       "      <td>-0.114305</td>\n",
       "      <td>0.062388</td>\n",
       "      <td>0.060255</td>\n",
       "      <td>0.034630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144931</td>\n",
       "      <td>0.144932</td>\n",
       "      <td>0.155032</td>\n",
       "      <td>0.150037</td>\n",
       "      <td>0.161459</td>\n",
       "      <td>1.112390</td>\n",
       "      <td>0.077593</td>\n",
       "      <td>0.107666</td>\n",
       "      <td>0.121171</td>\n",
       "      <td>0.087428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6939919</th>\n",
       "      <td>0.091188</td>\n",
       "      <td>0.113878</td>\n",
       "      <td>0.209395</td>\n",
       "      <td>-0.088961</td>\n",
       "      <td>-0.052304</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>-0.141205</td>\n",
       "      <td>0.184798</td>\n",
       "      <td>0.070163</td>\n",
       "      <td>0.015030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255040</td>\n",
       "      <td>0.249602</td>\n",
       "      <td>0.262775</td>\n",
       "      <td>0.242206</td>\n",
       "      <td>0.253641</td>\n",
       "      <td>0.077593</td>\n",
       "      <td>0.986131</td>\n",
       "      <td>0.159823</td>\n",
       "      <td>0.380622</td>\n",
       "      <td>0.167608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6939938</th>\n",
       "      <td>0.074009</td>\n",
       "      <td>0.108757</td>\n",
       "      <td>0.240468</td>\n",
       "      <td>-0.096740</td>\n",
       "      <td>-0.012778</td>\n",
       "      <td>0.058980</td>\n",
       "      <td>-0.149919</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.063573</td>\n",
       "      <td>0.090066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719743</td>\n",
       "      <td>0.728707</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.708062</td>\n",
       "      <td>0.704652</td>\n",
       "      <td>0.107666</td>\n",
       "      <td>0.159823</td>\n",
       "      <td>1.118190</td>\n",
       "      <td>0.388284</td>\n",
       "      <td>0.389739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6939941</th>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.154718</td>\n",
       "      <td>0.255337</td>\n",
       "      <td>-0.159136</td>\n",
       "      <td>-0.100318</td>\n",
       "      <td>0.045545</td>\n",
       "      <td>-0.206353</td>\n",
       "      <td>0.194754</td>\n",
       "      <td>0.043889</td>\n",
       "      <td>0.084022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465269</td>\n",
       "      <td>0.461691</td>\n",
       "      <td>0.473004</td>\n",
       "      <td>0.432339</td>\n",
       "      <td>0.435412</td>\n",
       "      <td>0.121171</td>\n",
       "      <td>0.380622</td>\n",
       "      <td>0.388284</td>\n",
       "      <td>1.070441</td>\n",
       "      <td>0.219306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6939945</th>\n",
       "      <td>0.199459</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.163524</td>\n",
       "      <td>-0.108800</td>\n",
       "      <td>-0.154557</td>\n",
       "      <td>0.152167</td>\n",
       "      <td>-0.163107</td>\n",
       "      <td>0.160584</td>\n",
       "      <td>0.030285</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660434</td>\n",
       "      <td>0.664936</td>\n",
       "      <td>0.645452</td>\n",
       "      <td>0.639670</td>\n",
       "      <td>0.649749</td>\n",
       "      <td>0.087428</td>\n",
       "      <td>0.167608</td>\n",
       "      <td>0.389739</td>\n",
       "      <td>0.219306</td>\n",
       "      <td>1.145606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>766 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            GID6569128  GID6688880  GID6688916  GID6688933  GID6688934  \\\n",
       "GID6569128    0.788801   -0.006443    0.025987   -0.138795   -0.157880   \n",
       "GID6688880   -0.006443    0.980542    0.064585   -0.168773   -0.081006   \n",
       "GID6688916    0.025987    0.064585    1.170073   -0.021636   -0.031717   \n",
       "GID6688933   -0.138795   -0.168773   -0.021636    0.879004    0.443678   \n",
       "GID6688934   -0.157880   -0.081006   -0.031717    0.443678    0.996666   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "GID6939917    0.004096    0.104630    0.006038   -0.140529   -0.098509   \n",
       "GID6939919    0.091188    0.113878    0.209395   -0.088961   -0.052304   \n",
       "GID6939938    0.074009    0.108757    0.240468   -0.096740   -0.012778   \n",
       "GID6939941    0.032992    0.154718    0.255337   -0.159136   -0.100318   \n",
       "GID6939945    0.199459    0.004447    0.163524   -0.108800   -0.154557   \n",
       "\n",
       "            GID6688949  GID6689407  GID6689482  GID6689550  GID6738288  ...  \\\n",
       "GID6569128    0.096213   -0.110899    0.013069   -0.040445    0.007931  ...   \n",
       "GID6688880    0.078890   -0.201346    0.124671    0.253505    0.013636  ...   \n",
       "GID6688916    0.101532   -0.196780    0.041900   -0.013459    0.126464  ...   \n",
       "GID6688933   -0.080560    0.402479   -0.218803   -0.102718   -0.002303  ...   \n",
       "GID6688934   -0.140766    0.395843   -0.310471   -0.138902    0.088169  ...   \n",
       "...                ...         ...         ...         ...         ...  ...   \n",
       "GID6939917    0.048248   -0.114305    0.062388    0.060255    0.034630  ...   \n",
       "GID6939919    0.139241   -0.141205    0.184798    0.070163    0.015030  ...   \n",
       "GID6939938    0.058980   -0.149919    0.000392    0.063573    0.090066  ...   \n",
       "GID6939941    0.045545   -0.206353    0.194754    0.043889    0.084022  ...   \n",
       "GID6939945    0.152167   -0.163107    0.160584    0.030285    0.010552  ...   \n",
       "\n",
       "            GID6939899  GID6939900  GID6939902  GID6939903  GID6939904  \\\n",
       "GID6569128    0.125612    0.133808    0.137456    0.127674    0.130468   \n",
       "GID6688880    0.072171    0.061650    0.057898    0.079085    0.061086   \n",
       "GID6688916    0.428609    0.423184    0.427788    0.408326    0.426844   \n",
       "GID6688933   -0.079312   -0.087824   -0.089912   -0.067028   -0.084206   \n",
       "GID6688934   -0.016690   -0.017375   -0.026372   -0.014478   -0.016350   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "GID6939917    0.144931    0.144932    0.155032    0.150037    0.161459   \n",
       "GID6939919    0.255040    0.249602    0.262775    0.242206    0.253641   \n",
       "GID6939938    0.719743    0.728707    0.732558    0.708062    0.704652   \n",
       "GID6939941    0.465269    0.461691    0.473004    0.432339    0.435412   \n",
       "GID6939945    0.660434    0.664936    0.645452    0.639670    0.649749   \n",
       "\n",
       "            GID6939917  GID6939919  GID6939938  GID6939941  GID6939945  \n",
       "GID6569128    0.004096    0.091188    0.074009    0.032992    0.199459  \n",
       "GID6688880    0.104630    0.113878    0.108757    0.154718    0.004447  \n",
       "GID6688916    0.006038    0.209395    0.240468    0.255337    0.163524  \n",
       "GID6688933   -0.140529   -0.088961   -0.096740   -0.159136   -0.108800  \n",
       "GID6688934   -0.098509   -0.052304   -0.012778   -0.100318   -0.154557  \n",
       "...                ...         ...         ...         ...         ...  \n",
       "GID6939917    1.112390    0.077593    0.107666    0.121171    0.087428  \n",
       "GID6939919    0.077593    0.986131    0.159823    0.380622    0.167608  \n",
       "GID6939938    0.107666    0.159823    1.118190    0.388284    0.389739  \n",
       "GID6939941    0.121171    0.380622    0.388284    1.070441    0.219306  \n",
       "GID6939945    0.087428    0.167608    0.389739    0.219306    1.145606  \n",
       "\n",
       "[766 rows x 766 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the feature matrix and set the index to match y\n",
    "X = eyt1['Geno_Env1'].sort_index()\n",
    "\n",
    "# Display the feature matrix\n",
    "display(X)\n",
    "\n",
    "# Reset the index for both X and y to ensure they match\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c222e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features_and_target(X: pd.DataFrame, y: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame, StandardScaler, StandardScaler):\n",
    "    \"\"\"\n",
    "    Scale the feature matrix and target values using StandardScaler.\n",
    "\n",
    "    Created: 2024/01/01\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): Feature matrix.\n",
    "        y (pd.DataFrame): Target values.\n",
    "    \n",
    "    Returns:\n",
    "        X_sc (pd.DataFrame): Scaled feature matrix.\n",
    "        y_sc (pd.DataFrame): Scaled target values.\n",
    "        X_scaler (StandardScaler): Scaler used for features.\n",
    "        y_scaler (StandardScaler): Scaler used for target.\n",
    "        \n",
    "    \"\"\"\n",
    "    X_sc, y_sc, X_scaler, y_scaler = None, None, None, None\n",
    "\n",
    "    # Scale the feature matrix\n",
    "    if X is not None:\n",
    "        X_scaler = StandardScaler()\n",
    "        X_sc = X_scaler.fit_transform(X)\n",
    "        X_sc = pd.DataFrame(X_sc, index=X.index, columns=X.columns)\n",
    "\n",
    "    # Scale the target values\n",
    "    if y is not None:\n",
    "        y_scaler = StandardScaler()\n",
    "        y_sc = y_scaler.fit_transform(y)\n",
    "        y_sc = pd.DataFrame(y_sc, index=y.index, columns=y.columns)\n",
    "    \n",
    "    return X_sc, y_sc, X_scaler, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11428d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smogn_prep(X: pd.DataFrame, y: pd.DataFrame, top_threshold_quantile: float, undersample: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset using the SMOGN algorithm\n",
    "    Created: 2024/02/05\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Feature matrix\n",
    "        y (pd.DataFrame): DataFrame containing grain yield values\n",
    "        top_threshold_quantile (float): The quantile value to use as the threshold for the top class\n",
    "        undersample (bool): Whether to undersample the majority class (default is True)\n",
    "    \"\"\"\n",
    "\n",
    "    # Temporarily combine X and y for compatibility with the SMOGN library\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    smogn_X_y = pd.concat([X, y], axis=1)\n",
    "\n",
    "    # Get GY distribution points\n",
    "    gy_min = y['GY'].min()\n",
    "    gy_max = y['GY'].max()\n",
    "    gy_just_under_threshold = y['GY'].quantile(top_threshold_quantile - 0.0001)\n",
    "    gy_just_over_threshold = y['GY'].quantile(top_threshold_quantile + 0.0001)\n",
    "\n",
    "    # Define control points for the SMOGN augmentation relevance function\n",
    "    ctrl_points = [\n",
    "        [gy_min, 0, 0],\n",
    "        [gy_just_under_threshold, 0, 0],\n",
    "        [gy_just_over_threshold, 1, 0],\n",
    "        [gy_max, 1, 0]\n",
    "    ]\n",
    "\n",
    "    # Display the combined DataFrame\n",
    "    display(smogn_X_y)\n",
    "\n",
    "    n_tries = 0\n",
    "    done = False\n",
    "\n",
    "    # Unfortunately the library has a bug where it randomly throws exceptions occasionally regardless of input\n",
    "    # So we have to try multiple times until it works... this is hacky but it will have to do until the library is fixed\n",
    "    while not done:\n",
    "        try:\n",
    "            # Apply the SMOGN algorithm to balance the dataset\n",
    "            X = smoter(\n",
    "                data=smogn_X_y,\n",
    "                y='GY',\n",
    "                k=5,\n",
    "                under_samp=undersample,\n",
    "                samp_method='balance',\n",
    "                rel_thres=top_threshold_quantile,\n",
    "                rel_method='manual',\n",
    "                rel_ctrl_pts_rg=ctrl_points,\n",
    "                rel_xtrm_type='high',\n",
    "                rel_coef=1.50\n",
    "            )\n",
    "            done = True\n",
    "\n",
    "        except ValueError:\n",
    "            if n_tries < 5:\n",
    "                n_tries += 1\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    # Split X and y back into separate DataFrames\n",
    "    y = X[['GY']]\n",
    "    X = X.drop(columns=['GY'])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "589e47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the cutoff value for the \"Top Line\" classification of grain yield values\n",
    "top_boundary_val = y[\"GY\"].quantile(TOP_THRESHOLD_QUANTILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713f8edf",
   "metadata": {},
   "source": [
    "# Model R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08cbb868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV_R(n_splits: int, X : pd.DataFrame, y : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, \n",
    "               train_model_callback, kfold_random_state: int, plot_title: str = \"\", **kwargs):\n",
    "    \"\"\"Perform inner cross-validation with grid search to find the best model parameters.\n",
    "    Created: 2024/12/03\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_splits : int\n",
    "        Number of splits for KFold cross-validation.\n",
    "    X : pd.DataFrame\n",
    "        Feature data.\n",
    "    y : pd.DataFrame\n",
    "        Target data.\n",
    "    axis1_params : mdo.AxisParams\n",
    "        Parameter grid for the first axis.\n",
    "    axis2_params : mdo.AxisParams\n",
    "        Parameter grid for the second axis.\n",
    "    train_model_callback : callable\n",
    "        Callback function to train the model.\n",
    "    kfold_random_state : int\n",
    "        Random state for KFold shuffling.\n",
    "    plot_title : str, optional\n",
    "        Title for the plot (default is \"\").\n",
    "    **kwargs : dict\n",
    "        Additional keyword arguments for the model training.\n",
    "    Returns:\n",
    "    --------\n",
    "    avg_best_param1 : float\n",
    "        Average best parameter value for the first axis over all folds.\n",
    "    avg_best_param2 : float\n",
    "        Average best parameter value for the second axis over all folds.\"\"\"\n",
    "\n",
    "    # Create KFold object for inner-fold cross-validation\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    # Store best parameters (param1, param2) for each fold\n",
    "    best_params = pd.DataFrame(columns=['param1', 'param2'], index=range(n_splits))\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        \n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train a grid of models with every combination of parameters\n",
    "        model_grid = bmo.train_model_grid(X_train, y_train, axis1_params, axis2_params, train_model_callback, **kwargs)\n",
    "\n",
    "        # Use trained models to predict test set labels, and store in 2D array with each cell corresponding to a model with a specific combination of parameters\n",
    "        y_preds_grid = bmo.grid_predict(X_test, model_grid)\n",
    "\n",
    "        # Create 2D array of identical dataframes containing actual labels to compare against predictions\n",
    "        y_test_grid = cdt.np_array_of_dfs(y_test, y_preds_grid.shape)\n",
    "\n",
    "        # Evaluate predictions by comparing to actuals, calculating 2D array of Pearson coefficients\n",
    "        pearson_grid = bmo.calculate_pearson_coefficients(y_preds_grid, y_test_grid)\n",
    "\n",
    "        # Find index of best Pearson coefficient in the 2D array of Pearson coefficients\n",
    "        best_row, best_col = np.unravel_index(np.argmax(pearson_grid), pearson_grid.shape)\n",
    "        \n",
    "        # Store hyperparameters of the most accurate model for this inner fold\n",
    "        best_params.loc[i] = [axis1_params.values[best_row], axis2_params.values[best_col]]\n",
    "\n",
    "        # Create grid of scatter plots with predictions vs actuals, colored by Pearson coefficient for each model\n",
    "        scatter_grid = plot_shaded_scatter_grids(y_preds_grid, y_test_grid, axis1_params, axis2_params, pearson_grid, f'{plot_title} | Inner Fold {i}')        \n",
    "        plt.savefig(f'{storage_dir}\\\\Model R {train_model_callback.__name__}, ({plot_title}, Inner Fold {i}).svg', format=\"svg\")\n",
    "        plt.show(scatter_grid)\n",
    "        plt.close(scatter_grid)\n",
    "\n",
    "    # Calculate average best parameters over all inner folds to return to outer CV\n",
    "    avg_best_param1 = best_params['param1'].mean()\n",
    "    avg_best_param2 = best_params['param2'].mean()\n",
    "\n",
    "    return avg_best_param1, avg_best_param2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c111e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_CV_R(n_outer_splits: int, n_inner_splits: int, X : pd.DataFrame, y : pd.DataFrame, \n",
    "               axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, \n",
    "               train_model_callback : callable, random_state: int, top_boundary_val : float,\n",
    "               smogn_preprocess = False, undersamp_ratio = 1, oversamp_ratio = 1, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform nested cross-validation with an outer and inner loop to evaluate model performance.\n",
    "    Created: 2024/12/03\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_outer_splits : int\n",
    "        Number of splits for the outer cross-validation loop.\n",
    "    n_inner_splits : int\n",
    "        Number of splits for the inner cross-validation loop.\n",
    "    X : pd.DataFrame\n",
    "        Feature data.\n",
    "    y : pd.DataFrame\n",
    "        Target data.\n",
    "    axis1_params : mdo.AxisParams\n",
    "        Object containing parameter list for the first hyperparameter axis (horizontal).\n",
    "    axis2_params : mdo.AxisParams\n",
    "        Object containing parameter list for the second hyperparameter axis (vertical).\n",
    "    train_model_callback : callable\n",
    "        Function to train the model. Should accept X, y, and hyperparameters as arguments.\n",
    "    random_state : int\n",
    "        Random state for reproducibility in KFold splitting.\n",
    "    top_boundary_val : float\n",
    "        Threshold to classify predictions as top or not top.\n",
    "    smogn_preprocess : bool, optional\n",
    "        Whether to apply SMOGN preprocessing to the data. Default is False.\n",
    "    undersamp_ratio : float, optional\n",
    "        Proportion of the majority class to keep after undersampling. Default is 1.\n",
    "    oversamp_ratio : float, optional\n",
    "        Proportion of augmented data for the minority class to keep after oversampling. Default is 1.\n",
    "    **kwargs\n",
    "        Additional arguments to pass to the train_model_callback function.\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing 5 metrics (Pearson, F1 Score, Sensitivity, Specificity, Kappa) for each outer fold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create KFold object for outer loop to split data into train and test sets\n",
    "    kfold = KFold(n_splits=n_outer_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Store metrics for each fold\n",
    "    kfold_metrics = pd.DataFrame(columns=['Pearson', 'F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "\n",
    "    # Create arrays to store outer-fold final \"super model\"'s predictions and actuals\n",
    "    super_model_preds = [None] * n_outer_splits\n",
    "    super_model_actuals = [None] * n_outer_splits \n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Display the training and test data\n",
    "        print(f\"Outer Fold {i} Training and Test Data:\")\n",
    "        print(\"X_train:\")\n",
    "        display(X_train)\n",
    "        print(\"y_train:\")\n",
    "        display(y_train)\n",
    "        print(\"X_test:\")\n",
    "        display(X_test)\n",
    "        print(\"y_test:\")\n",
    "        display(y_test)\n",
    "\n",
    "        if smogn_preprocess:\n",
    "            top_quant_train = percentileofscore(y_train.to_numpy().flatten(), top_boundary_val, kind='mean') / 100\n",
    "            print(f\"Top quantile for training data in outer fold {i}: {top_quant_train}\")\n",
    "\n",
    "            X_train_top_smog, y_train_top_smog = smogn_prep(X_train, y_train, top_quant_train, False) # We won't use SMOGN's built-in undersampling because we will do it manually later\n",
    "            print(\"After SMOGN prep:\")\n",
    "            print(\"X_train_top_smog:\")\n",
    "            display(X_train_top_smog)\n",
    "            print(\"y_train_top_smog:\")\n",
    "            display(y_train_top_smog)\n",
    "\n",
    "            # Split the augmented and original top line data into separate columns for plotting\n",
    "            y_train_top_smog_orig = pra.intersection(y_train, y_train_top_smog)\n",
    "            X_train_top_smog_orig = X_train_top_smog.loc[y_train_top_smog_orig.index]\n",
    "            y_train_top_smog_aug = pra.difference(y_train_top_smog, y_train_top_smog_orig)\n",
    "            X_train_top_smog_aug = X_train_top_smog.loc[y_train_top_smog_aug.index]\n",
    "            print(\"After splitting augmented and original top line data:\")\n",
    "            print(\"X_train_top_smog_orig:\")\n",
    "            display(X_train_top_smog_orig)\n",
    "            print(\"y_train_top_smog_orig:\")\n",
    "            display(y_train_top_smog_orig)\n",
    "            print(\"X_train_top_smog_aug:\")\n",
    "            display(X_train_top_smog_aug)\n",
    "            print(\"y_train_top_smog_aug:\")\n",
    "            display(y_train_top_smog_aug)\n",
    "\n",
    "            # Randomly undersample the augmented data\n",
    "            X_train_top_smog_aug_us, y_train_top_smog_aug_us = cdt.random_subset(X_train_top_smog_aug, y_train_top_smog_aug, p=oversamp_ratio, random_state=random_state)\n",
    "            print(\"After undersampling augmented data:\")\n",
    "            print(\"X_train_top_smog_aug_us:\")\n",
    "            display(X_train_top_smog_aug_us)\n",
    "            print(\"y_train_top_smog_aug_us:\")\n",
    "            display(y_train_top_smog_aug_us)\n",
    "\n",
    "            # Plot histograms of original and augmented GY values stacked\n",
    "            orig_aug_data = pd.concat([y_train_top_smog_orig, y_train_top_smog_aug_us], axis=1)\n",
    "            orig_aug_data.columns = ['Original GY', 'Augmented GY']\n",
    "            histogram(orig_aug_data, f'Model R SMOGN-Augmented GY Histogram, Outer Fold {i}', vline_value=top_boundary_val)\n",
    "\n",
    "            # Re-combine the original and augmented top line data\n",
    "            X_train_top_final = pd.concat([X_train_top_smog_orig, X_train_top_smog_aug_us], axis=0)\n",
    "            y_train_top_final = pd.concat([y_train_top_smog_orig, y_train_top_smog_aug_us], axis=0)\n",
    "            print(\"After recombining original and augmented top line data:\")\n",
    "            print(\"X_train_top_final:\")\n",
    "            display(X_train_top_final)\n",
    "            print(\"y_train_top_final:\")\n",
    "            display(y_train_top_final)\n",
    "\n",
    "            # Undersample the majority class so that it is a certain proportion of its original size\n",
    "            X_train_maj, y_train_maj = X_train.loc[y_train[y_train < top_boundary_val].index], y_train.loc[y_train[y_train < top_boundary_val].index]\n",
    "            X_train_maj_us, y_train_maj_us = cdt.random_subset(X_train_maj, y_train_maj, p=undersamp_ratio, random_state=random_state)\n",
    "            print(\"After undersampling majority class:\")\n",
    "            print(\"X_train_maj_us:\")\n",
    "            display(X_train_maj_us)\n",
    "            print(\"y_train_maj_us:\")\n",
    "            display(y_train_maj_us)\n",
    "\n",
    "            X_train_final = pd.concat([X_train_top_final, X_train_maj_us], axis=0)\n",
    "            y_train_final = pd.concat([y_train_top_final, y_train_maj_us], axis=0)\n",
    "            print(\"Final training data after combining top and majority class data:\")\n",
    "            print(\"X_train_final:\")\n",
    "            display(X_train_final)\n",
    "            print(\"y_train_final:\")\n",
    "            display(y_train_final)\n",
    "\n",
    "        else:\n",
    "            histogram(y_train, f'Model R Histogram, Outer Fold {i}', vline_value=top_boundary_val)\n",
    "\n",
    "        # Display summary statistics of y_train\n",
    "        print(\"Summary statistics of y_train_final:\")\n",
    "        display(y_train_final.describe())\n",
    "\n",
    "        # Scale features and target\n",
    "        X_train_final, y_train_final, X_scaler, y_scaler = scale_features_and_target(X_train_final, y_train_final)\n",
    "        top_boundary_val_scaled = y_scaler.transform([[top_boundary_val]])[0, 0]\n",
    "        X_test = pd.DataFrame(X_scaler.transform(X_test))\n",
    "        y_test = pd.DataFrame(y_scaler.transform(y_test))\n",
    "            \n",
    "        # Find mean best hyperparameter values based on prediction accuracy using inner-fold CV\n",
    "        best_param1, best_param2 = inner_CV_R(n_inner_splits, X_train_final, y_train_final, axis1_params, axis2_params, train_model_callback, random_state, plot_title=f\"Outer Fold {i}\", **kwargs)\n",
    "\n",
    "        # Train model with all training and CV data of outer fold using mean best hyperparameters\n",
    "        super_model = train_model_callback(X_train_final, np.ravel(y_train_final), **dict(zip([axis1_params.name, axis2_params.name], [best_param1, best_param2])), **kwargs)\n",
    "\n",
    "        # Use trained \"super-model\" to predict test set\n",
    "        X_test.columns = X.columns\n",
    "        y_pred = pd.DataFrame(super_model.predict(X_test), index=y_test.index, columns=y_test.columns)\n",
    "        histogram(y_pred, f'Model R Predicted GY Histogram, {train_model_callback.__name__}, Outer Fold {i}')\n",
    "\n",
    "        # Calculate Pearson coefficient of continuous predictions\n",
    "        pearson, _ = pearsonr(np.ravel(y_pred), np.ravel(y_test))\n",
    "\n",
    "        # Classify predictions and actuals of super_model as top or not top (boolean)\n",
    "        y_pred_top = bmo.continuous_to_binary_absolute(y_pred, top_boundary_val_scaled)\n",
    "        super_model_preds[i] = y_pred_top\n",
    "        y_test_top = bmo.continuous_to_binary_absolute(y_test, top_boundary_val_scaled)\n",
    "        super_model_actuals[i] = y_test_top\n",
    "\n",
    "        # Plot super model predictions vs actuals scatterplot\n",
    "        cmp.plot_classification_results(y_pred, y_test, y_pred_top, y_test_top, \n",
    "                                        [f\"Model R Predicted vs Actual GY, {train_model_callback.__name__}, Outer Fold {i}\"],\n",
    "                                        save_path=f'{storage_dir}\\\\Model R Super Model Predicted vs Actual GY, {train_model_callback.__name__}, Outer Fold {i}.svg')\n",
    "\n",
    "        # Calculate classification metrics and add new row to kfold_metrics\n",
    "        classification_metrics = cdt.classification_metrics(y_pred_top, y_test_top)\n",
    "        pearson_df = pd.DataFrame([pearson], columns=['Pearson'])\n",
    "        metrics_row = pd.concat([pearson_df, classification_metrics], axis=1)\n",
    "        kfold_metrics = pd.concat([kfold_metrics, metrics_row], axis=0)\n",
    "\n",
    "    # Label each row of kfold_metrics with the fold number \n",
    "    kfold_metrics.index = range(n_outer_splits)\n",
    "    \n",
    "    return kfold_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40ce7c",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a31a94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold 0 Training and Test Data:\n",
      "X_train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID6569128</th>\n",
       "      <th>GID6688880</th>\n",
       "      <th>GID6688916</th>\n",
       "      <th>GID6688933</th>\n",
       "      <th>GID6688934</th>\n",
       "      <th>GID6688949</th>\n",
       "      <th>GID6689407</th>\n",
       "      <th>GID6689482</th>\n",
       "      <th>GID6689550</th>\n",
       "      <th>GID6738288</th>\n",
       "      <th>...</th>\n",
       "      <th>GID6939899</th>\n",
       "      <th>GID6939900</th>\n",
       "      <th>GID6939902</th>\n",
       "      <th>GID6939903</th>\n",
       "      <th>GID6939904</th>\n",
       "      <th>GID6939917</th>\n",
       "      <th>GID6939919</th>\n",
       "      <th>GID6939938</th>\n",
       "      <th>GID6939941</th>\n",
       "      <th>GID6939945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>-0.004776</td>\n",
       "      <td>0.171068</td>\n",
       "      <td>0.044530</td>\n",
       "      <td>-0.135819</td>\n",
       "      <td>-0.208459</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>-0.187181</td>\n",
       "      <td>0.211761</td>\n",
       "      <td>0.109432</td>\n",
       "      <td>-0.103757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059841</td>\n",
       "      <td>-0.065622</td>\n",
       "      <td>-0.061719</td>\n",
       "      <td>-0.060266</td>\n",
       "      <td>-0.053595</td>\n",
       "      <td>0.130102</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>0.093145</td>\n",
       "      <td>0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.028073</td>\n",
       "      <td>0.096045</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>-0.114325</td>\n",
       "      <td>-0.145915</td>\n",
       "      <td>0.138552</td>\n",
       "      <td>-0.190540</td>\n",
       "      <td>0.231643</td>\n",
       "      <td>0.057803</td>\n",
       "      <td>-0.093047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049262</td>\n",
       "      <td>-0.045041</td>\n",
       "      <td>-0.044414</td>\n",
       "      <td>-0.045026</td>\n",
       "      <td>-0.030542</td>\n",
       "      <td>0.146985</td>\n",
       "      <td>0.054929</td>\n",
       "      <td>0.015672</td>\n",
       "      <td>0.059418</td>\n",
       "      <td>0.034531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.199877</td>\n",
       "      <td>-0.048239</td>\n",
       "      <td>-0.111412</td>\n",
       "      <td>-0.154402</td>\n",
       "      <td>-0.210150</td>\n",
       "      <td>0.041593</td>\n",
       "      <td>-0.173204</td>\n",
       "      <td>-0.037298</td>\n",
       "      <td>-0.095530</td>\n",
       "      <td>-0.035351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.013796</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>-0.044321</td>\n",
       "      <td>-0.148727</td>\n",
       "      <td>-0.024698</td>\n",
       "      <td>-0.127360</td>\n",
       "      <td>0.016249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.072097</td>\n",
       "      <td>-0.024102</td>\n",
       "      <td>-0.064676</td>\n",
       "      <td>0.178711</td>\n",
       "      <td>0.209842</td>\n",
       "      <td>-0.022932</td>\n",
       "      <td>0.167128</td>\n",
       "      <td>-0.111594</td>\n",
       "      <td>-0.050906</td>\n",
       "      <td>-0.023959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057959</td>\n",
       "      <td>-0.068093</td>\n",
       "      <td>-0.058871</td>\n",
       "      <td>-0.060123</td>\n",
       "      <td>-0.063864</td>\n",
       "      <td>0.029866</td>\n",
       "      <td>-0.085868</td>\n",
       "      <td>-0.049257</td>\n",
       "      <td>-0.050660</td>\n",
       "      <td>-0.103773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0.066207</td>\n",
       "      <td>0.101028</td>\n",
       "      <td>0.133376</td>\n",
       "      <td>-0.168064</td>\n",
       "      <td>-0.249350</td>\n",
       "      <td>0.061883</td>\n",
       "      <td>-0.258948</td>\n",
       "      <td>0.254711</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>-0.085440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277748</td>\n",
       "      <td>0.283144</td>\n",
       "      <td>0.272966</td>\n",
       "      <td>0.270166</td>\n",
       "      <td>0.254486</td>\n",
       "      <td>0.084954</td>\n",
       "      <td>0.161791</td>\n",
       "      <td>0.207099</td>\n",
       "      <td>0.485994</td>\n",
       "      <td>0.210648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>-0.029413</td>\n",
       "      <td>0.149851</td>\n",
       "      <td>0.125294</td>\n",
       "      <td>-0.127413</td>\n",
       "      <td>-0.012841</td>\n",
       "      <td>0.021683</td>\n",
       "      <td>-0.085402</td>\n",
       "      <td>0.122947</td>\n",
       "      <td>0.018955</td>\n",
       "      <td>0.068041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022694</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>0.032012</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.055551</td>\n",
       "      <td>0.094124</td>\n",
       "      <td>0.060668</td>\n",
       "      <td>-0.005110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>0.017694</td>\n",
       "      <td>0.106354</td>\n",
       "      <td>0.636458</td>\n",
       "      <td>-0.085727</td>\n",
       "      <td>-0.039868</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>-0.240585</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.014380</td>\n",
       "      <td>0.147012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500549</td>\n",
       "      <td>0.499108</td>\n",
       "      <td>0.491203</td>\n",
       "      <td>0.484019</td>\n",
       "      <td>0.498074</td>\n",
       "      <td>0.049416</td>\n",
       "      <td>0.197739</td>\n",
       "      <td>0.323722</td>\n",
       "      <td>0.295250</td>\n",
       "      <td>0.183096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>-0.131179</td>\n",
       "      <td>0.031558</td>\n",
       "      <td>-0.058717</td>\n",
       "      <td>0.231769</td>\n",
       "      <td>0.270395</td>\n",
       "      <td>-0.099324</td>\n",
       "      <td>0.216658</td>\n",
       "      <td>-0.132588</td>\n",
       "      <td>0.051240</td>\n",
       "      <td>0.019843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149854</td>\n",
       "      <td>-0.134235</td>\n",
       "      <td>-0.148288</td>\n",
       "      <td>-0.135099</td>\n",
       "      <td>-0.146702</td>\n",
       "      <td>-0.107900</td>\n",
       "      <td>-0.010022</td>\n",
       "      <td>-0.035559</td>\n",
       "      <td>-0.046681</td>\n",
       "      <td>-0.170806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.100688</td>\n",
       "      <td>-0.024868</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-0.102867</td>\n",
       "      <td>-0.139393</td>\n",
       "      <td>0.201165</td>\n",
       "      <td>-0.177973</td>\n",
       "      <td>0.141686</td>\n",
       "      <td>0.075284</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347353</td>\n",
       "      <td>0.336067</td>\n",
       "      <td>0.352745</td>\n",
       "      <td>0.337077</td>\n",
       "      <td>0.328565</td>\n",
       "      <td>0.106239</td>\n",
       "      <td>0.211546</td>\n",
       "      <td>0.163309</td>\n",
       "      <td>0.238714</td>\n",
       "      <td>0.203457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.159151</td>\n",
       "      <td>-0.025363</td>\n",
       "      <td>0.339005</td>\n",
       "      <td>-0.100481</td>\n",
       "      <td>-0.147644</td>\n",
       "      <td>0.131448</td>\n",
       "      <td>-0.165830</td>\n",
       "      <td>0.096148</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.040360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876694</td>\n",
       "      <td>0.889393</td>\n",
       "      <td>0.864300</td>\n",
       "      <td>0.847516</td>\n",
       "      <td>0.855128</td>\n",
       "      <td>0.068687</td>\n",
       "      <td>0.242398</td>\n",
       "      <td>0.505865</td>\n",
       "      <td>0.333481</td>\n",
       "      <td>0.585294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.065175</td>\n",
       "      <td>0.080083</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>-0.130694</td>\n",
       "      <td>-0.205924</td>\n",
       "      <td>0.132232</td>\n",
       "      <td>-0.152645</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.165367</td>\n",
       "      <td>-0.091276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.017010</td>\n",
       "      <td>-0.001881</td>\n",
       "      <td>-0.006795</td>\n",
       "      <td>-0.007432</td>\n",
       "      <td>0.103085</td>\n",
       "      <td>0.138323</td>\n",
       "      <td>0.031083</td>\n",
       "      <td>0.186535</td>\n",
       "      <td>0.068227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>-0.046065</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>-0.082567</td>\n",
       "      <td>0.124645</td>\n",
       "      <td>0.186837</td>\n",
       "      <td>-0.050340</td>\n",
       "      <td>0.192305</td>\n",
       "      <td>-0.097391</td>\n",
       "      <td>-0.110945</td>\n",
       "      <td>-0.046877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114846</td>\n",
       "      <td>-0.106830</td>\n",
       "      <td>-0.116041</td>\n",
       "      <td>-0.104458</td>\n",
       "      <td>-0.103144</td>\n",
       "      <td>0.031791</td>\n",
       "      <td>-0.093128</td>\n",
       "      <td>-0.053729</td>\n",
       "      <td>-0.066326</td>\n",
       "      <td>-0.122058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GID6569128  GID6688880  GID6688916  GID6688933  GID6688934  GID6688949  \\\n",
       "659   -0.004776    0.171068    0.044530   -0.135819   -0.208459    0.039600   \n",
       "350   -0.028073    0.096045   -0.001709   -0.114325   -0.145915    0.138552   \n",
       "571    0.199877   -0.048239   -0.111412   -0.154402   -0.210150    0.041593   \n",
       "336   -0.072097   -0.024102   -0.064676    0.178711    0.209842   -0.022932   \n",
       "752    0.066207    0.101028    0.133376   -0.168064   -0.249350    0.061883   \n",
       "479   -0.029413    0.149851    0.125294   -0.127413   -0.012841    0.021683   \n",
       "690    0.017694    0.106354    0.636458   -0.085727   -0.039868    0.104421   \n",
       "394   -0.131179    0.031558   -0.058717    0.231769    0.270395   -0.099324   \n",
       "196    0.100688   -0.024868    0.330083   -0.102867   -0.139393    0.201165   \n",
       "704    0.159151   -0.025363    0.339005   -0.100481   -0.147644    0.131448   \n",
       "77    -0.065175    0.080083    0.043021   -0.130694   -0.205924    0.132232   \n",
       "494   -0.046065    0.030433   -0.082567    0.124645    0.186837   -0.050340   \n",
       "\n",
       "     GID6689407  GID6689482  GID6689550  GID6738288  ...  GID6939899  \\\n",
       "659   -0.187181    0.211761    0.109432   -0.103757  ...   -0.059841   \n",
       "350   -0.190540    0.231643    0.057803   -0.093047  ...   -0.049262   \n",
       "571   -0.173204   -0.037298   -0.095530   -0.035351  ...    0.003590   \n",
       "336    0.167128   -0.111594   -0.050906   -0.023959  ...   -0.057959   \n",
       "752   -0.258948    0.254711    0.004110   -0.085440  ...    0.277748   \n",
       "479   -0.085402    0.122947    0.018955    0.068041  ...    0.022694   \n",
       "690   -0.240585    0.076054    0.014380    0.147012  ...    0.500549   \n",
       "394    0.216658   -0.132588    0.051240    0.019843  ...   -0.149854   \n",
       "196   -0.177973    0.141686    0.075284    0.027967  ...    0.347353   \n",
       "704   -0.165830    0.096148    0.003449    0.040360  ...    0.876694   \n",
       "77    -0.152645    0.320600    0.165367   -0.091276  ...   -0.000016   \n",
       "494    0.192305   -0.097391   -0.110945   -0.046877  ...   -0.114846   \n",
       "\n",
       "     GID6939900  GID6939902  GID6939903  GID6939904  GID6939917  GID6939919  \\\n",
       "659   -0.065622   -0.061719   -0.060266   -0.053595    0.130102    0.139344   \n",
       "350   -0.045041   -0.044414   -0.045026   -0.030542    0.146985    0.054929   \n",
       "571    0.013796    0.018200    0.009935    0.009367   -0.044321   -0.148727   \n",
       "336   -0.068093   -0.058871   -0.060123   -0.063864    0.029866   -0.085868   \n",
       "752    0.283144    0.272966    0.270166    0.254486    0.084954    0.161791   \n",
       "479    0.028347    0.032012    0.020305    0.023039    0.067370    0.055551   \n",
       "690    0.499108    0.491203    0.484019    0.498074    0.049416    0.197739   \n",
       "394   -0.134235   -0.148288   -0.135099   -0.146702   -0.107900   -0.010022   \n",
       "196    0.336067    0.352745    0.337077    0.328565    0.106239    0.211546   \n",
       "704    0.889393    0.864300    0.847516    0.855128    0.068687    0.242398   \n",
       "77    -0.017010   -0.001881   -0.006795   -0.007432    0.103085    0.138323   \n",
       "494   -0.106830   -0.116041   -0.104458   -0.103144    0.031791   -0.093128   \n",
       "\n",
       "     GID6939938  GID6939941  GID6939945  \n",
       "659    0.010878    0.093145    0.002047  \n",
       "350    0.015672    0.059418    0.034531  \n",
       "571   -0.024698   -0.127360    0.016249  \n",
       "336   -0.049257   -0.050660   -0.103773  \n",
       "752    0.207099    0.485994    0.210648  \n",
       "479    0.094124    0.060668   -0.005110  \n",
       "690    0.323722    0.295250    0.183096  \n",
       "394   -0.035559   -0.046681   -0.170806  \n",
       "196    0.163309    0.238714    0.203457  \n",
       "704    0.505865    0.333481    0.585294  \n",
       "77     0.031083    0.186535    0.068227  \n",
       "494   -0.053729   -0.066326   -0.122058  \n",
       "\n",
       "[12 rows x 766 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>5.742917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>5.058952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>5.460984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>5.665271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>5.189311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>5.337074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>5.580040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>5.907013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5.627525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>6.067034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5.716176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>5.325479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           GY\n",
       "659  5.742917\n",
       "350  5.058952\n",
       "571  5.460984\n",
       "336  5.665271\n",
       "752  5.189311\n",
       "479  5.337074\n",
       "690  5.580040\n",
       "394  5.907013\n",
       "196  5.627525\n",
       "704  6.067034\n",
       "77   5.716176\n",
       "494  5.325479"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID6569128</th>\n",
       "      <th>GID6688880</th>\n",
       "      <th>GID6688916</th>\n",
       "      <th>GID6688933</th>\n",
       "      <th>GID6688934</th>\n",
       "      <th>GID6688949</th>\n",
       "      <th>GID6689407</th>\n",
       "      <th>GID6689482</th>\n",
       "      <th>GID6689550</th>\n",
       "      <th>GID6738288</th>\n",
       "      <th>...</th>\n",
       "      <th>GID6939899</th>\n",
       "      <th>GID6939900</th>\n",
       "      <th>GID6939902</th>\n",
       "      <th>GID6939903</th>\n",
       "      <th>GID6939904</th>\n",
       "      <th>GID6939917</th>\n",
       "      <th>GID6939919</th>\n",
       "      <th>GID6939938</th>\n",
       "      <th>GID6939941</th>\n",
       "      <th>GID6939945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.030535</td>\n",
       "      <td>0.135234</td>\n",
       "      <td>0.094152</td>\n",
       "      <td>-0.112610</td>\n",
       "      <td>-0.068206</td>\n",
       "      <td>0.036517</td>\n",
       "      <td>-0.163059</td>\n",
       "      <td>0.097997</td>\n",
       "      <td>0.034517</td>\n",
       "      <td>0.085091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347458</td>\n",
       "      <td>0.361085</td>\n",
       "      <td>0.358784</td>\n",
       "      <td>0.353436</td>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.595881</td>\n",
       "      <td>0.179615</td>\n",
       "      <td>0.271616</td>\n",
       "      <td>0.308483</td>\n",
       "      <td>0.162423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.031273</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.483295</td>\n",
       "      <td>-0.033660</td>\n",
       "      <td>-0.006678</td>\n",
       "      <td>0.094425</td>\n",
       "      <td>-0.066210</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>-0.040033</td>\n",
       "      <td>0.144250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359140</td>\n",
       "      <td>0.345925</td>\n",
       "      <td>0.353554</td>\n",
       "      <td>0.344136</td>\n",
       "      <td>0.339048</td>\n",
       "      <td>0.068862</td>\n",
       "      <td>0.074883</td>\n",
       "      <td>0.200964</td>\n",
       "      <td>0.152227</td>\n",
       "      <td>0.169607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.058018</td>\n",
       "      <td>0.129619</td>\n",
       "      <td>0.062738</td>\n",
       "      <td>-0.085977</td>\n",
       "      <td>-0.043822</td>\n",
       "      <td>0.135519</td>\n",
       "      <td>-0.121920</td>\n",
       "      <td>-0.090719</td>\n",
       "      <td>-0.005124</td>\n",
       "      <td>0.123743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130053</td>\n",
       "      <td>0.140651</td>\n",
       "      <td>0.142530</td>\n",
       "      <td>0.137539</td>\n",
       "      <td>0.142441</td>\n",
       "      <td>0.085226</td>\n",
       "      <td>0.101906</td>\n",
       "      <td>0.101935</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>0.095265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GID6569128  GID6688880  GID6688916  GID6688933  GID6688934  GID6688949  \\\n",
       "428    0.030535    0.135234    0.094152   -0.112610   -0.068206    0.036517   \n",
       "199    0.031273    0.065200    0.483295   -0.033660   -0.006678    0.094425   \n",
       "148    0.058018    0.129619    0.062738   -0.085977   -0.043822    0.135519   \n",
       "\n",
       "     GID6689407  GID6689482  GID6689550  GID6738288  ...  GID6939899  \\\n",
       "428   -0.163059    0.097997    0.034517    0.085091  ...    0.347458   \n",
       "199   -0.066210    0.005385   -0.040033    0.144250  ...    0.359140   \n",
       "148   -0.121920   -0.090719   -0.005124    0.123743  ...    0.130053   \n",
       "\n",
       "     GID6939900  GID6939902  GID6939903  GID6939904  GID6939917  GID6939919  \\\n",
       "428    0.361085    0.358784    0.353436    0.344047    0.595881    0.179615   \n",
       "199    0.345925    0.353554    0.344136    0.339048    0.068862    0.074883   \n",
       "148    0.140651    0.142530    0.137539    0.142441    0.085226    0.101906   \n",
       "\n",
       "     GID6939938  GID6939941  GID6939945  \n",
       "428    0.271616    0.308483    0.162423  \n",
       "199    0.200964    0.152227    0.169607  \n",
       "148    0.101935    0.132056    0.095265  \n",
       "\n",
       "[3 rows x 766 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>5.973795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>5.130786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.157570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           GY\n",
       "428  5.973795\n",
       "199  5.130786\n",
       "148  5.157570"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top quantile for training data in outer fold 0: 0.8333333333333335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID6569128</th>\n",
       "      <th>GID6688880</th>\n",
       "      <th>GID6688916</th>\n",
       "      <th>GID6688933</th>\n",
       "      <th>GID6688934</th>\n",
       "      <th>GID6688949</th>\n",
       "      <th>GID6689407</th>\n",
       "      <th>GID6689482</th>\n",
       "      <th>GID6689550</th>\n",
       "      <th>GID6738288</th>\n",
       "      <th>...</th>\n",
       "      <th>GID6939900</th>\n",
       "      <th>GID6939902</th>\n",
       "      <th>GID6939903</th>\n",
       "      <th>GID6939904</th>\n",
       "      <th>GID6939917</th>\n",
       "      <th>GID6939919</th>\n",
       "      <th>GID6939938</th>\n",
       "      <th>GID6939941</th>\n",
       "      <th>GID6939945</th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004776</td>\n",
       "      <td>0.171068</td>\n",
       "      <td>0.044530</td>\n",
       "      <td>-0.135819</td>\n",
       "      <td>-0.208459</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>-0.187181</td>\n",
       "      <td>0.211761</td>\n",
       "      <td>0.109432</td>\n",
       "      <td>-0.103757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065622</td>\n",
       "      <td>-0.061719</td>\n",
       "      <td>-0.060266</td>\n",
       "      <td>-0.053595</td>\n",
       "      <td>0.130102</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>0.093145</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>5.742917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.028073</td>\n",
       "      <td>0.096045</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>-0.114325</td>\n",
       "      <td>-0.145915</td>\n",
       "      <td>0.138552</td>\n",
       "      <td>-0.190540</td>\n",
       "      <td>0.231643</td>\n",
       "      <td>0.057803</td>\n",
       "      <td>-0.093047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045041</td>\n",
       "      <td>-0.044414</td>\n",
       "      <td>-0.045026</td>\n",
       "      <td>-0.030542</td>\n",
       "      <td>0.146985</td>\n",
       "      <td>0.054929</td>\n",
       "      <td>0.015672</td>\n",
       "      <td>0.059418</td>\n",
       "      <td>0.034531</td>\n",
       "      <td>5.058952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.199877</td>\n",
       "      <td>-0.048239</td>\n",
       "      <td>-0.111412</td>\n",
       "      <td>-0.154402</td>\n",
       "      <td>-0.210150</td>\n",
       "      <td>0.041593</td>\n",
       "      <td>-0.173204</td>\n",
       "      <td>-0.037298</td>\n",
       "      <td>-0.095530</td>\n",
       "      <td>-0.035351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013796</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>-0.044321</td>\n",
       "      <td>-0.148727</td>\n",
       "      <td>-0.024698</td>\n",
       "      <td>-0.127360</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>5.460984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.072097</td>\n",
       "      <td>-0.024102</td>\n",
       "      <td>-0.064676</td>\n",
       "      <td>0.178711</td>\n",
       "      <td>0.209842</td>\n",
       "      <td>-0.022932</td>\n",
       "      <td>0.167128</td>\n",
       "      <td>-0.111594</td>\n",
       "      <td>-0.050906</td>\n",
       "      <td>-0.023959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068093</td>\n",
       "      <td>-0.058871</td>\n",
       "      <td>-0.060123</td>\n",
       "      <td>-0.063864</td>\n",
       "      <td>0.029866</td>\n",
       "      <td>-0.085868</td>\n",
       "      <td>-0.049257</td>\n",
       "      <td>-0.050660</td>\n",
       "      <td>-0.103773</td>\n",
       "      <td>5.665271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.066207</td>\n",
       "      <td>0.101028</td>\n",
       "      <td>0.133376</td>\n",
       "      <td>-0.168064</td>\n",
       "      <td>-0.249350</td>\n",
       "      <td>0.061883</td>\n",
       "      <td>-0.258948</td>\n",
       "      <td>0.254711</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>-0.085440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283144</td>\n",
       "      <td>0.272966</td>\n",
       "      <td>0.270166</td>\n",
       "      <td>0.254486</td>\n",
       "      <td>0.084954</td>\n",
       "      <td>0.161791</td>\n",
       "      <td>0.207099</td>\n",
       "      <td>0.485994</td>\n",
       "      <td>0.210648</td>\n",
       "      <td>5.189311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.029413</td>\n",
       "      <td>0.149851</td>\n",
       "      <td>0.125294</td>\n",
       "      <td>-0.127413</td>\n",
       "      <td>-0.012841</td>\n",
       "      <td>0.021683</td>\n",
       "      <td>-0.085402</td>\n",
       "      <td>0.122947</td>\n",
       "      <td>0.018955</td>\n",
       "      <td>0.068041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>0.032012</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.055551</td>\n",
       "      <td>0.094124</td>\n",
       "      <td>0.060668</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>5.337074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017694</td>\n",
       "      <td>0.106354</td>\n",
       "      <td>0.636458</td>\n",
       "      <td>-0.085727</td>\n",
       "      <td>-0.039868</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>-0.240585</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.014380</td>\n",
       "      <td>0.147012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499108</td>\n",
       "      <td>0.491203</td>\n",
       "      <td>0.484019</td>\n",
       "      <td>0.498074</td>\n",
       "      <td>0.049416</td>\n",
       "      <td>0.197739</td>\n",
       "      <td>0.323722</td>\n",
       "      <td>0.295250</td>\n",
       "      <td>0.183096</td>\n",
       "      <td>5.580040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.131179</td>\n",
       "      <td>0.031558</td>\n",
       "      <td>-0.058717</td>\n",
       "      <td>0.231769</td>\n",
       "      <td>0.270395</td>\n",
       "      <td>-0.099324</td>\n",
       "      <td>0.216658</td>\n",
       "      <td>-0.132588</td>\n",
       "      <td>0.051240</td>\n",
       "      <td>0.019843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134235</td>\n",
       "      <td>-0.148288</td>\n",
       "      <td>-0.135099</td>\n",
       "      <td>-0.146702</td>\n",
       "      <td>-0.107900</td>\n",
       "      <td>-0.010022</td>\n",
       "      <td>-0.035559</td>\n",
       "      <td>-0.046681</td>\n",
       "      <td>-0.170806</td>\n",
       "      <td>5.907013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100688</td>\n",
       "      <td>-0.024868</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-0.102867</td>\n",
       "      <td>-0.139393</td>\n",
       "      <td>0.201165</td>\n",
       "      <td>-0.177973</td>\n",
       "      <td>0.141686</td>\n",
       "      <td>0.075284</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336067</td>\n",
       "      <td>0.352745</td>\n",
       "      <td>0.337077</td>\n",
       "      <td>0.328565</td>\n",
       "      <td>0.106239</td>\n",
       "      <td>0.211546</td>\n",
       "      <td>0.163309</td>\n",
       "      <td>0.238714</td>\n",
       "      <td>0.203457</td>\n",
       "      <td>5.627525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.159151</td>\n",
       "      <td>-0.025363</td>\n",
       "      <td>0.339005</td>\n",
       "      <td>-0.100481</td>\n",
       "      <td>-0.147644</td>\n",
       "      <td>0.131448</td>\n",
       "      <td>-0.165830</td>\n",
       "      <td>0.096148</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.040360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889393</td>\n",
       "      <td>0.864300</td>\n",
       "      <td>0.847516</td>\n",
       "      <td>0.855128</td>\n",
       "      <td>0.068687</td>\n",
       "      <td>0.242398</td>\n",
       "      <td>0.505865</td>\n",
       "      <td>0.333481</td>\n",
       "      <td>0.585294</td>\n",
       "      <td>6.067034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.065175</td>\n",
       "      <td>0.080083</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>-0.130694</td>\n",
       "      <td>-0.205924</td>\n",
       "      <td>0.132232</td>\n",
       "      <td>-0.152645</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.165367</td>\n",
       "      <td>-0.091276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017010</td>\n",
       "      <td>-0.001881</td>\n",
       "      <td>-0.006795</td>\n",
       "      <td>-0.007432</td>\n",
       "      <td>0.103085</td>\n",
       "      <td>0.138323</td>\n",
       "      <td>0.031083</td>\n",
       "      <td>0.186535</td>\n",
       "      <td>0.068227</td>\n",
       "      <td>5.716176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.046065</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>-0.082567</td>\n",
       "      <td>0.124645</td>\n",
       "      <td>0.186837</td>\n",
       "      <td>-0.050340</td>\n",
       "      <td>0.192305</td>\n",
       "      <td>-0.097391</td>\n",
       "      <td>-0.110945</td>\n",
       "      <td>-0.046877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106830</td>\n",
       "      <td>-0.116041</td>\n",
       "      <td>-0.104458</td>\n",
       "      <td>-0.103144</td>\n",
       "      <td>0.031791</td>\n",
       "      <td>-0.093128</td>\n",
       "      <td>-0.053729</td>\n",
       "      <td>-0.066326</td>\n",
       "      <td>-0.122058</td>\n",
       "      <td>5.325479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    GID6569128  GID6688880  GID6688916  GID6688933  GID6688934  GID6688949  \\\n",
       "0    -0.004776    0.171068    0.044530   -0.135819   -0.208459    0.039600   \n",
       "1    -0.028073    0.096045   -0.001709   -0.114325   -0.145915    0.138552   \n",
       "2     0.199877   -0.048239   -0.111412   -0.154402   -0.210150    0.041593   \n",
       "3    -0.072097   -0.024102   -0.064676    0.178711    0.209842   -0.022932   \n",
       "4     0.066207    0.101028    0.133376   -0.168064   -0.249350    0.061883   \n",
       "5    -0.029413    0.149851    0.125294   -0.127413   -0.012841    0.021683   \n",
       "6     0.017694    0.106354    0.636458   -0.085727   -0.039868    0.104421   \n",
       "7    -0.131179    0.031558   -0.058717    0.231769    0.270395   -0.099324   \n",
       "8     0.100688   -0.024868    0.330083   -0.102867   -0.139393    0.201165   \n",
       "9     0.159151   -0.025363    0.339005   -0.100481   -0.147644    0.131448   \n",
       "10   -0.065175    0.080083    0.043021   -0.130694   -0.205924    0.132232   \n",
       "11   -0.046065    0.030433   -0.082567    0.124645    0.186837   -0.050340   \n",
       "\n",
       "    GID6689407  GID6689482  GID6689550  GID6738288  ...  GID6939900  \\\n",
       "0    -0.187181    0.211761    0.109432   -0.103757  ...   -0.065622   \n",
       "1    -0.190540    0.231643    0.057803   -0.093047  ...   -0.045041   \n",
       "2    -0.173204   -0.037298   -0.095530   -0.035351  ...    0.013796   \n",
       "3     0.167128   -0.111594   -0.050906   -0.023959  ...   -0.068093   \n",
       "4    -0.258948    0.254711    0.004110   -0.085440  ...    0.283144   \n",
       "5    -0.085402    0.122947    0.018955    0.068041  ...    0.028347   \n",
       "6    -0.240585    0.076054    0.014380    0.147012  ...    0.499108   \n",
       "7     0.216658   -0.132588    0.051240    0.019843  ...   -0.134235   \n",
       "8    -0.177973    0.141686    0.075284    0.027967  ...    0.336067   \n",
       "9    -0.165830    0.096148    0.003449    0.040360  ...    0.889393   \n",
       "10   -0.152645    0.320600    0.165367   -0.091276  ...   -0.017010   \n",
       "11    0.192305   -0.097391   -0.110945   -0.046877  ...   -0.106830   \n",
       "\n",
       "    GID6939902  GID6939903  GID6939904  GID6939917  GID6939919  GID6939938  \\\n",
       "0    -0.061719   -0.060266   -0.053595    0.130102    0.139344    0.010878   \n",
       "1    -0.044414   -0.045026   -0.030542    0.146985    0.054929    0.015672   \n",
       "2     0.018200    0.009935    0.009367   -0.044321   -0.148727   -0.024698   \n",
       "3    -0.058871   -0.060123   -0.063864    0.029866   -0.085868   -0.049257   \n",
       "4     0.272966    0.270166    0.254486    0.084954    0.161791    0.207099   \n",
       "5     0.032012    0.020305    0.023039    0.067370    0.055551    0.094124   \n",
       "6     0.491203    0.484019    0.498074    0.049416    0.197739    0.323722   \n",
       "7    -0.148288   -0.135099   -0.146702   -0.107900   -0.010022   -0.035559   \n",
       "8     0.352745    0.337077    0.328565    0.106239    0.211546    0.163309   \n",
       "9     0.864300    0.847516    0.855128    0.068687    0.242398    0.505865   \n",
       "10   -0.001881   -0.006795   -0.007432    0.103085    0.138323    0.031083   \n",
       "11   -0.116041   -0.104458   -0.103144    0.031791   -0.093128   -0.053729   \n",
       "\n",
       "    GID6939941  GID6939945        GY  \n",
       "0     0.093145    0.002047  5.742917  \n",
       "1     0.059418    0.034531  5.058952  \n",
       "2    -0.127360    0.016249  5.460984  \n",
       "3    -0.050660   -0.103773  5.665271  \n",
       "4     0.485994    0.210648  5.189311  \n",
       "5     0.060668   -0.005110  5.337074  \n",
       "6     0.295250    0.183096  5.580040  \n",
       "7    -0.046681   -0.170806  5.907013  \n",
       "8     0.238714    0.203457  5.627525  \n",
       "9     0.333481    0.585294  6.067034  \n",
       "10    0.186535    0.068227  5.716176  \n",
       "11   -0.066326   -0.122058  5.325479  \n",
       "\n",
       "[12 rows x 767 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_matrix: 100%|##########| 2/2 [00:00<00:00, 92.97it/s]\n",
      "synth_matrix: 100%|##########| 2/2 [00:00<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOGN prep:\n",
      "X_train_top_smog:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID6569128</th>\n",
       "      <th>GID6688880</th>\n",
       "      <th>GID6688916</th>\n",
       "      <th>GID6688933</th>\n",
       "      <th>GID6688934</th>\n",
       "      <th>GID6688949</th>\n",
       "      <th>GID6689407</th>\n",
       "      <th>GID6689482</th>\n",
       "      <th>GID6689550</th>\n",
       "      <th>GID6738288</th>\n",
       "      <th>...</th>\n",
       "      <th>GID6939899</th>\n",
       "      <th>GID6939900</th>\n",
       "      <th>GID6939902</th>\n",
       "      <th>GID6939903</th>\n",
       "      <th>GID6939904</th>\n",
       "      <th>GID6939917</th>\n",
       "      <th>GID6939919</th>\n",
       "      <th>GID6939938</th>\n",
       "      <th>GID6939941</th>\n",
       "      <th>GID6939945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229971</td>\n",
       "      <td>0.266903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050161</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235451</td>\n",
       "      <td>0.263178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050971</td>\n",
       "      <td>0.019646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097157</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.040431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894954</td>\n",
       "      <td>0.892752</td>\n",
       "      <td>0.878516</td>\n",
       "      <td>0.838107</td>\n",
       "      <td>0.842036</td>\n",
       "      <td>0.067288</td>\n",
       "      <td>0.245286</td>\n",
       "      <td>0.507845</td>\n",
       "      <td>0.336892</td>\n",
       "      <td>0.591777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095368</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.040034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854050</td>\n",
       "      <td>0.872537</td>\n",
       "      <td>0.867948</td>\n",
       "      <td>0.866145</td>\n",
       "      <td>0.859947</td>\n",
       "      <td>0.069269</td>\n",
       "      <td>0.240844</td>\n",
       "      <td>0.506899</td>\n",
       "      <td>0.330434</td>\n",
       "      <td>0.590189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GID6569128  GID6688880  GID6688916  GID6688933  GID6688934  GID6688949  \\\n",
       "0    0.000000    0.031192    0.000000    0.229971    0.266903    0.000000   \n",
       "1    0.000000    0.031007    0.000000    0.235451    0.263178    0.000000   \n",
       "2    0.160683    0.000000    0.342964    0.000000    0.000000    0.135301   \n",
       "3    0.159308    0.000000    0.337087    0.000000    0.000000    0.132190   \n",
       "\n",
       "   GID6689407  GID6689482  GID6689550  GID6738288  ...  GID6939899  \\\n",
       "0    0.219217    0.000000    0.050161    0.019814  ...    0.000000   \n",
       "1    0.215467    0.000000    0.050971    0.019646  ...    0.000000   \n",
       "2    0.000000    0.097157    0.003281    0.040431  ...    0.894954   \n",
       "3    0.000000    0.095368    0.003389    0.040034  ...    0.854050   \n",
       "\n",
       "   GID6939900  GID6939902  GID6939903  GID6939904  GID6939917  GID6939919  \\\n",
       "0    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2    0.892752    0.878516    0.838107    0.842036    0.067288    0.245286   \n",
       "3    0.872537    0.867948    0.866145    0.859947    0.069269    0.240844   \n",
       "\n",
       "   GID6939938  GID6939941  GID6939945  \n",
       "0    0.000000    0.000000    0.000000  \n",
       "1    0.000000    0.000000    0.000000  \n",
       "2    0.507845    0.336892    0.591777  \n",
       "3    0.506899    0.330434    0.590189  \n",
       "\n",
       "[4 rows x 766 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_top_smog:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.906201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.906514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.065679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.062448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GY\n",
       "0  5.906201\n",
       "1  5.906514\n",
       "2  6.065679\n",
       "3  6.062448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After splitting augmented and original top line data:\n",
      "X_train_top_smog_orig:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID6569128</th>\n",
       "      <th>GID6688880</th>\n",
       "      <th>GID6688916</th>\n",
       "      <th>GID6688933</th>\n",
       "      <th>GID6688934</th>\n",
       "      <th>GID6688949</th>\n",
       "      <th>GID6689407</th>\n",
       "      <th>GID6689482</th>\n",
       "      <th>GID6689550</th>\n",
       "      <th>GID6738288</th>\n",
       "      <th>...</th>\n",
       "      <th>GID6939899</th>\n",
       "      <th>GID6939900</th>\n",
       "      <th>GID6939902</th>\n",
       "      <th>GID6939903</th>\n",
       "      <th>GID6939904</th>\n",
       "      <th>GID6939917</th>\n",
       "      <th>GID6939919</th>\n",
       "      <th>GID6939938</th>\n",
       "      <th>GID6939941</th>\n",
       "      <th>GID6939945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [GID6569128, GID6688880, GID6688916, GID6688933, GID6688934, GID6688949, GID6689407, GID6689482, GID6689550, GID6738288, GID6861263, GID6861485, GID6861531, GID6861690, GID6861779, GID6861787, GID6861813, GID6861823, GID6861833, GID6861890, GID6861897, GID6861915, GID6861919, GID6861967, GID6862002, GID6862015, GID6862021, GID6862028, GID6862058, GID6862260, GID6862303, GID6862314, GID6862365, GID6862370, GID6862387, GID6862407, GID6862457, GID6862474, GID6862745, GID6862771, GID6862787, GID6862797, GID6862975, GID6863145, GID6863290, GID6863300, GID6863318, GID6863371, GID6863396, GID6863412, GID6863491, GID6863500, GID6863517, GID6863532, GID6863533, GID6863544, GID6931277, GID6931281, GID6931300, GID6931301, GID6931304, GID6931305, GID6931327, GID6931343, GID6931346, GID6931368, GID6931369, GID6931374, GID6931420, GID6931426, GID6931427, GID6931430, GID6931437, GID6931449, GID6931453, GID6931463, GID6931471, GID6931476, GID6931482, GID6931494, GID6931506, GID6931509, GID6931512, GID6931515, GID6931516, GID6931517, GID6931519, GID6931531, GID6931560, GID6931587, GID6931590, GID6931593, GID6931606, GID6931608, GID6931630, GID6931632, GID6931644, GID6931655, GID6931663, GID6931677, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 766 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_top_smog_orig:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [GY]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_top_smog_aug:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID6569128</th>\n",
       "      <th>GID6688880</th>\n",
       "      <th>GID6688916</th>\n",
       "      <th>GID6688933</th>\n",
       "      <th>GID6688934</th>\n",
       "      <th>GID6688949</th>\n",
       "      <th>GID6689407</th>\n",
       "      <th>GID6689482</th>\n",
       "      <th>GID6689550</th>\n",
       "      <th>GID6738288</th>\n",
       "      <th>...</th>\n",
       "      <th>GID6939899</th>\n",
       "      <th>GID6939900</th>\n",
       "      <th>GID6939902</th>\n",
       "      <th>GID6939903</th>\n",
       "      <th>GID6939904</th>\n",
       "      <th>GID6939917</th>\n",
       "      <th>GID6939919</th>\n",
       "      <th>GID6939938</th>\n",
       "      <th>GID6939941</th>\n",
       "      <th>GID6939945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229971</td>\n",
       "      <td>0.266903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050161</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235451</td>\n",
       "      <td>0.263178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050971</td>\n",
       "      <td>0.019646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097157</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.040431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894954</td>\n",
       "      <td>0.892752</td>\n",
       "      <td>0.878516</td>\n",
       "      <td>0.838107</td>\n",
       "      <td>0.842036</td>\n",
       "      <td>0.067288</td>\n",
       "      <td>0.245286</td>\n",
       "      <td>0.507845</td>\n",
       "      <td>0.336892</td>\n",
       "      <td>0.591777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095368</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.040034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854050</td>\n",
       "      <td>0.872537</td>\n",
       "      <td>0.867948</td>\n",
       "      <td>0.866145</td>\n",
       "      <td>0.859947</td>\n",
       "      <td>0.069269</td>\n",
       "      <td>0.240844</td>\n",
       "      <td>0.506899</td>\n",
       "      <td>0.330434</td>\n",
       "      <td>0.590189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GID6569128  GID6688880  GID6688916  GID6688933  GID6688934  GID6688949  \\\n",
       "0    0.000000    0.031192    0.000000    0.229971    0.266903    0.000000   \n",
       "1    0.000000    0.031007    0.000000    0.235451    0.263178    0.000000   \n",
       "2    0.160683    0.000000    0.342964    0.000000    0.000000    0.135301   \n",
       "3    0.159308    0.000000    0.337087    0.000000    0.000000    0.132190   \n",
       "\n",
       "   GID6689407  GID6689482  GID6689550  GID6738288  ...  GID6939899  \\\n",
       "0    0.219217    0.000000    0.050161    0.019814  ...    0.000000   \n",
       "1    0.215467    0.000000    0.050971    0.019646  ...    0.000000   \n",
       "2    0.000000    0.097157    0.003281    0.040431  ...    0.894954   \n",
       "3    0.000000    0.095368    0.003389    0.040034  ...    0.854050   \n",
       "\n",
       "   GID6939900  GID6939902  GID6939903  GID6939904  GID6939917  GID6939919  \\\n",
       "0    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2    0.892752    0.878516    0.838107    0.842036    0.067288    0.245286   \n",
       "3    0.872537    0.867948    0.866145    0.859947    0.069269    0.240844   \n",
       "\n",
       "   GID6939938  GID6939941  GID6939945  \n",
       "0    0.000000    0.000000    0.000000  \n",
       "1    0.000000    0.000000    0.000000  \n",
       "2    0.507845    0.336892    0.591777  \n",
       "3    0.506899    0.330434    0.590189  \n",
       "\n",
       "[4 rows x 766 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_top_smog_aug:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.906201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.906514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.065679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.062448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GY\n",
       "0  5.906201\n",
       "1  5.906514\n",
       "2  6.065679\n",
       "3  6.062448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling augmented data:\n",
      "X_train_top_smog_aug_us:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID6569128</th>\n",
       "      <th>GID6688880</th>\n",
       "      <th>GID6688916</th>\n",
       "      <th>GID6688933</th>\n",
       "      <th>GID6688934</th>\n",
       "      <th>GID6688949</th>\n",
       "      <th>GID6689407</th>\n",
       "      <th>GID6689482</th>\n",
       "      <th>GID6689550</th>\n",
       "      <th>GID6738288</th>\n",
       "      <th>...</th>\n",
       "      <th>GID6939899</th>\n",
       "      <th>GID6939900</th>\n",
       "      <th>GID6939902</th>\n",
       "      <th>GID6939903</th>\n",
       "      <th>GID6939904</th>\n",
       "      <th>GID6939917</th>\n",
       "      <th>GID6939919</th>\n",
       "      <th>GID6939938</th>\n",
       "      <th>GID6939941</th>\n",
       "      <th>GID6939945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235451</td>\n",
       "      <td>0.263178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050971</td>\n",
       "      <td>0.019646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095368</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.040034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854050</td>\n",
       "      <td>0.872537</td>\n",
       "      <td>0.867948</td>\n",
       "      <td>0.866145</td>\n",
       "      <td>0.859947</td>\n",
       "      <td>0.069269</td>\n",
       "      <td>0.240844</td>\n",
       "      <td>0.506899</td>\n",
       "      <td>0.330434</td>\n",
       "      <td>0.590189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229971</td>\n",
       "      <td>0.266903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050161</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097157</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.040431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894954</td>\n",
       "      <td>0.892752</td>\n",
       "      <td>0.878516</td>\n",
       "      <td>0.838107</td>\n",
       "      <td>0.842036</td>\n",
       "      <td>0.067288</td>\n",
       "      <td>0.245286</td>\n",
       "      <td>0.507845</td>\n",
       "      <td>0.336892</td>\n",
       "      <td>0.591777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GID6569128  GID6688880  GID6688916  GID6688933  GID6688934  GID6688949  \\\n",
       "1    0.000000    0.031007    0.000000    0.235451    0.263178    0.000000   \n",
       "3    0.159308    0.000000    0.337087    0.000000    0.000000    0.132190   \n",
       "0    0.000000    0.031192    0.000000    0.229971    0.266903    0.000000   \n",
       "2    0.160683    0.000000    0.342964    0.000000    0.000000    0.135301   \n",
       "\n",
       "   GID6689407  GID6689482  GID6689550  GID6738288  ...  GID6939899  \\\n",
       "1    0.215467    0.000000    0.050971    0.019646  ...    0.000000   \n",
       "3    0.000000    0.095368    0.003389    0.040034  ...    0.854050   \n",
       "0    0.219217    0.000000    0.050161    0.019814  ...    0.000000   \n",
       "2    0.000000    0.097157    0.003281    0.040431  ...    0.894954   \n",
       "\n",
       "   GID6939900  GID6939902  GID6939903  GID6939904  GID6939917  GID6939919  \\\n",
       "1    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3    0.872537    0.867948    0.866145    0.859947    0.069269    0.240844   \n",
       "0    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2    0.892752    0.878516    0.838107    0.842036    0.067288    0.245286   \n",
       "\n",
       "   GID6939938  GID6939941  GID6939945  \n",
       "1    0.000000    0.000000    0.000000  \n",
       "3    0.506899    0.330434    0.590189  \n",
       "0    0.000000    0.000000    0.000000  \n",
       "2    0.507845    0.336892    0.591777  \n",
       "\n",
       "[4 rows x 766 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_top_smog_aug_us:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.906514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.062448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.906201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.065679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GY\n",
       "1  5.906514\n",
       "3  6.062448\n",
       "0  5.906201\n",
       "2  6.065679"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After recombining original and augmented top line data:\n",
      "X_train_top_final:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_37772\\3995637799.py:111: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  y_train_top_final = pd.concat([y_train_top_smog_orig, y_train_top_smog_aug_us], axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID6569128</th>\n",
       "      <th>GID6688880</th>\n",
       "      <th>GID6688916</th>\n",
       "      <th>GID6688933</th>\n",
       "      <th>GID6688934</th>\n",
       "      <th>GID6688949</th>\n",
       "      <th>GID6689407</th>\n",
       "      <th>GID6689482</th>\n",
       "      <th>GID6689550</th>\n",
       "      <th>GID6738288</th>\n",
       "      <th>...</th>\n",
       "      <th>GID6939899</th>\n",
       "      <th>GID6939900</th>\n",
       "      <th>GID6939902</th>\n",
       "      <th>GID6939903</th>\n",
       "      <th>GID6939904</th>\n",
       "      <th>GID6939917</th>\n",
       "      <th>GID6939919</th>\n",
       "      <th>GID6939938</th>\n",
       "      <th>GID6939941</th>\n",
       "      <th>GID6939945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235451</td>\n",
       "      <td>0.263178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050971</td>\n",
       "      <td>0.019646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095368</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.040034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854050</td>\n",
       "      <td>0.872537</td>\n",
       "      <td>0.867948</td>\n",
       "      <td>0.866145</td>\n",
       "      <td>0.859947</td>\n",
       "      <td>0.069269</td>\n",
       "      <td>0.240844</td>\n",
       "      <td>0.506899</td>\n",
       "      <td>0.330434</td>\n",
       "      <td>0.590189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229971</td>\n",
       "      <td>0.266903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050161</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097157</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.040431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894954</td>\n",
       "      <td>0.892752</td>\n",
       "      <td>0.878516</td>\n",
       "      <td>0.838107</td>\n",
       "      <td>0.842036</td>\n",
       "      <td>0.067288</td>\n",
       "      <td>0.245286</td>\n",
       "      <td>0.507845</td>\n",
       "      <td>0.336892</td>\n",
       "      <td>0.591777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GID6569128  GID6688880  GID6688916  GID6688933  GID6688934  GID6688949  \\\n",
       "1    0.000000    0.031007    0.000000    0.235451    0.263178    0.000000   \n",
       "3    0.159308    0.000000    0.337087    0.000000    0.000000    0.132190   \n",
       "0    0.000000    0.031192    0.000000    0.229971    0.266903    0.000000   \n",
       "2    0.160683    0.000000    0.342964    0.000000    0.000000    0.135301   \n",
       "\n",
       "   GID6689407  GID6689482  GID6689550  GID6738288  ...  GID6939899  \\\n",
       "1    0.215467    0.000000    0.050971    0.019646  ...    0.000000   \n",
       "3    0.000000    0.095368    0.003389    0.040034  ...    0.854050   \n",
       "0    0.219217    0.000000    0.050161    0.019814  ...    0.000000   \n",
       "2    0.000000    0.097157    0.003281    0.040431  ...    0.894954   \n",
       "\n",
       "   GID6939900  GID6939902  GID6939903  GID6939904  GID6939917  GID6939919  \\\n",
       "1    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3    0.872537    0.867948    0.866145    0.859947    0.069269    0.240844   \n",
       "0    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2    0.892752    0.878516    0.838107    0.842036    0.067288    0.245286   \n",
       "\n",
       "   GID6939938  GID6939941  GID6939945  \n",
       "1    0.000000    0.000000    0.000000  \n",
       "3    0.506899    0.330434    0.590189  \n",
       "0    0.000000    0.000000    0.000000  \n",
       "2    0.507845    0.336892    0.591777  \n",
       "\n",
       "[4 rows x 766 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_top_final:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.906514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.062448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.906201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.065679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GY\n",
       "1  5.906514\n",
       "3  6.062448\n",
       "0  5.906201\n",
       "2  6.065679"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling majority class:\n",
      "X_train_maj_us:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID6569128</th>\n",
       "      <th>GID6688880</th>\n",
       "      <th>GID6688916</th>\n",
       "      <th>GID6688933</th>\n",
       "      <th>GID6688934</th>\n",
       "      <th>GID6688949</th>\n",
       "      <th>GID6689407</th>\n",
       "      <th>GID6689482</th>\n",
       "      <th>GID6689550</th>\n",
       "      <th>GID6738288</th>\n",
       "      <th>...</th>\n",
       "      <th>GID6939899</th>\n",
       "      <th>GID6939900</th>\n",
       "      <th>GID6939902</th>\n",
       "      <th>GID6939903</th>\n",
       "      <th>GID6939904</th>\n",
       "      <th>GID6939917</th>\n",
       "      <th>GID6939919</th>\n",
       "      <th>GID6939938</th>\n",
       "      <th>GID6939941</th>\n",
       "      <th>GID6939945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.065175</td>\n",
       "      <td>0.080083</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>-0.130694</td>\n",
       "      <td>-0.205924</td>\n",
       "      <td>0.132232</td>\n",
       "      <td>-0.152645</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.165367</td>\n",
       "      <td>-0.091276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.017010</td>\n",
       "      <td>-0.001881</td>\n",
       "      <td>-0.006795</td>\n",
       "      <td>-0.007432</td>\n",
       "      <td>0.103085</td>\n",
       "      <td>0.138323</td>\n",
       "      <td>0.031083</td>\n",
       "      <td>0.186535</td>\n",
       "      <td>0.068227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.159151</td>\n",
       "      <td>-0.025363</td>\n",
       "      <td>0.339005</td>\n",
       "      <td>-0.100481</td>\n",
       "      <td>-0.147644</td>\n",
       "      <td>0.131448</td>\n",
       "      <td>-0.165830</td>\n",
       "      <td>0.096148</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.040360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876694</td>\n",
       "      <td>0.889393</td>\n",
       "      <td>0.864300</td>\n",
       "      <td>0.847516</td>\n",
       "      <td>0.855128</td>\n",
       "      <td>0.068687</td>\n",
       "      <td>0.242398</td>\n",
       "      <td>0.505865</td>\n",
       "      <td>0.333481</td>\n",
       "      <td>0.585294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>-0.004776</td>\n",
       "      <td>0.171068</td>\n",
       "      <td>0.044530</td>\n",
       "      <td>-0.135819</td>\n",
       "      <td>-0.208459</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>-0.187181</td>\n",
       "      <td>0.211761</td>\n",
       "      <td>0.109432</td>\n",
       "      <td>-0.103757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059841</td>\n",
       "      <td>-0.065622</td>\n",
       "      <td>-0.061719</td>\n",
       "      <td>-0.060266</td>\n",
       "      <td>-0.053595</td>\n",
       "      <td>0.130102</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>0.093145</td>\n",
       "      <td>0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.100688</td>\n",
       "      <td>-0.024868</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-0.102867</td>\n",
       "      <td>-0.139393</td>\n",
       "      <td>0.201165</td>\n",
       "      <td>-0.177973</td>\n",
       "      <td>0.141686</td>\n",
       "      <td>0.075284</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347353</td>\n",
       "      <td>0.336067</td>\n",
       "      <td>0.352745</td>\n",
       "      <td>0.337077</td>\n",
       "      <td>0.328565</td>\n",
       "      <td>0.106239</td>\n",
       "      <td>0.211546</td>\n",
       "      <td>0.163309</td>\n",
       "      <td>0.238714</td>\n",
       "      <td>0.203457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>-0.029413</td>\n",
       "      <td>0.149851</td>\n",
       "      <td>0.125294</td>\n",
       "      <td>-0.127413</td>\n",
       "      <td>-0.012841</td>\n",
       "      <td>0.021683</td>\n",
       "      <td>-0.085402</td>\n",
       "      <td>0.122947</td>\n",
       "      <td>0.018955</td>\n",
       "      <td>0.068041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022694</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>0.032012</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.055551</td>\n",
       "      <td>0.094124</td>\n",
       "      <td>0.060668</td>\n",
       "      <td>-0.005110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.199877</td>\n",
       "      <td>-0.048239</td>\n",
       "      <td>-0.111412</td>\n",
       "      <td>-0.154402</td>\n",
       "      <td>-0.210150</td>\n",
       "      <td>0.041593</td>\n",
       "      <td>-0.173204</td>\n",
       "      <td>-0.037298</td>\n",
       "      <td>-0.095530</td>\n",
       "      <td>-0.035351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.013796</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>-0.044321</td>\n",
       "      <td>-0.148727</td>\n",
       "      <td>-0.024698</td>\n",
       "      <td>-0.127360</td>\n",
       "      <td>0.016249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GID6569128  GID6688880  GID6688916  GID6688933  GID6688934  GID6688949  \\\n",
       "77    -0.065175    0.080083    0.043021   -0.130694   -0.205924    0.132232   \n",
       "704    0.159151   -0.025363    0.339005   -0.100481   -0.147644    0.131448   \n",
       "659   -0.004776    0.171068    0.044530   -0.135819   -0.208459    0.039600   \n",
       "196    0.100688   -0.024868    0.330083   -0.102867   -0.139393    0.201165   \n",
       "479   -0.029413    0.149851    0.125294   -0.127413   -0.012841    0.021683   \n",
       "571    0.199877   -0.048239   -0.111412   -0.154402   -0.210150    0.041593   \n",
       "\n",
       "     GID6689407  GID6689482  GID6689550  GID6738288  ...  GID6939899  \\\n",
       "77    -0.152645    0.320600    0.165367   -0.091276  ...   -0.000016   \n",
       "704   -0.165830    0.096148    0.003449    0.040360  ...    0.876694   \n",
       "659   -0.187181    0.211761    0.109432   -0.103757  ...   -0.059841   \n",
       "196   -0.177973    0.141686    0.075284    0.027967  ...    0.347353   \n",
       "479   -0.085402    0.122947    0.018955    0.068041  ...    0.022694   \n",
       "571   -0.173204   -0.037298   -0.095530   -0.035351  ...    0.003590   \n",
       "\n",
       "     GID6939900  GID6939902  GID6939903  GID6939904  GID6939917  GID6939919  \\\n",
       "77    -0.017010   -0.001881   -0.006795   -0.007432    0.103085    0.138323   \n",
       "704    0.889393    0.864300    0.847516    0.855128    0.068687    0.242398   \n",
       "659   -0.065622   -0.061719   -0.060266   -0.053595    0.130102    0.139344   \n",
       "196    0.336067    0.352745    0.337077    0.328565    0.106239    0.211546   \n",
       "479    0.028347    0.032012    0.020305    0.023039    0.067370    0.055551   \n",
       "571    0.013796    0.018200    0.009935    0.009367   -0.044321   -0.148727   \n",
       "\n",
       "     GID6939938  GID6939941  GID6939945  \n",
       "77     0.031083    0.186535    0.068227  \n",
       "704    0.505865    0.333481    0.585294  \n",
       "659    0.010878    0.093145    0.002047  \n",
       "196    0.163309    0.238714    0.203457  \n",
       "479    0.094124    0.060668   -0.005110  \n",
       "571   -0.024698   -0.127360    0.016249  \n",
       "\n",
       "[6 rows x 766 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_maj_us:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5.716176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>6.067034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>5.742917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5.627525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>5.337074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>5.460984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           GY\n",
       "77   5.716176\n",
       "704  6.067034\n",
       "659  5.742917\n",
       "196  5.627525\n",
       "479  5.337074\n",
       "571  5.460984"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training data after combining top and majority class data:\n",
      "X_train_final:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID6569128</th>\n",
       "      <th>GID6688880</th>\n",
       "      <th>GID6688916</th>\n",
       "      <th>GID6688933</th>\n",
       "      <th>GID6688934</th>\n",
       "      <th>GID6688949</th>\n",
       "      <th>GID6689407</th>\n",
       "      <th>GID6689482</th>\n",
       "      <th>GID6689550</th>\n",
       "      <th>GID6738288</th>\n",
       "      <th>...</th>\n",
       "      <th>GID6939899</th>\n",
       "      <th>GID6939900</th>\n",
       "      <th>GID6939902</th>\n",
       "      <th>GID6939903</th>\n",
       "      <th>GID6939904</th>\n",
       "      <th>GID6939917</th>\n",
       "      <th>GID6939919</th>\n",
       "      <th>GID6939938</th>\n",
       "      <th>GID6939941</th>\n",
       "      <th>GID6939945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235451</td>\n",
       "      <td>0.263178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050971</td>\n",
       "      <td>0.019646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095368</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.040034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854050</td>\n",
       "      <td>0.872537</td>\n",
       "      <td>0.867948</td>\n",
       "      <td>0.866145</td>\n",
       "      <td>0.859947</td>\n",
       "      <td>0.069269</td>\n",
       "      <td>0.240844</td>\n",
       "      <td>0.506899</td>\n",
       "      <td>0.330434</td>\n",
       "      <td>0.590189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229971</td>\n",
       "      <td>0.266903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050161</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097157</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.040431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894954</td>\n",
       "      <td>0.892752</td>\n",
       "      <td>0.878516</td>\n",
       "      <td>0.838107</td>\n",
       "      <td>0.842036</td>\n",
       "      <td>0.067288</td>\n",
       "      <td>0.245286</td>\n",
       "      <td>0.507845</td>\n",
       "      <td>0.336892</td>\n",
       "      <td>0.591777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.065175</td>\n",
       "      <td>0.080083</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>-0.130694</td>\n",
       "      <td>-0.205924</td>\n",
       "      <td>0.132232</td>\n",
       "      <td>-0.152645</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.165367</td>\n",
       "      <td>-0.091276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.017010</td>\n",
       "      <td>-0.001881</td>\n",
       "      <td>-0.006795</td>\n",
       "      <td>-0.007432</td>\n",
       "      <td>0.103085</td>\n",
       "      <td>0.138323</td>\n",
       "      <td>0.031083</td>\n",
       "      <td>0.186535</td>\n",
       "      <td>0.068227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.159151</td>\n",
       "      <td>-0.025363</td>\n",
       "      <td>0.339005</td>\n",
       "      <td>-0.100481</td>\n",
       "      <td>-0.147644</td>\n",
       "      <td>0.131448</td>\n",
       "      <td>-0.165830</td>\n",
       "      <td>0.096148</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.040360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876694</td>\n",
       "      <td>0.889393</td>\n",
       "      <td>0.864300</td>\n",
       "      <td>0.847516</td>\n",
       "      <td>0.855128</td>\n",
       "      <td>0.068687</td>\n",
       "      <td>0.242398</td>\n",
       "      <td>0.505865</td>\n",
       "      <td>0.333481</td>\n",
       "      <td>0.585294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>-0.004776</td>\n",
       "      <td>0.171068</td>\n",
       "      <td>0.044530</td>\n",
       "      <td>-0.135819</td>\n",
       "      <td>-0.208459</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>-0.187181</td>\n",
       "      <td>0.211761</td>\n",
       "      <td>0.109432</td>\n",
       "      <td>-0.103757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059841</td>\n",
       "      <td>-0.065622</td>\n",
       "      <td>-0.061719</td>\n",
       "      <td>-0.060266</td>\n",
       "      <td>-0.053595</td>\n",
       "      <td>0.130102</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>0.093145</td>\n",
       "      <td>0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.100688</td>\n",
       "      <td>-0.024868</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-0.102867</td>\n",
       "      <td>-0.139393</td>\n",
       "      <td>0.201165</td>\n",
       "      <td>-0.177973</td>\n",
       "      <td>0.141686</td>\n",
       "      <td>0.075284</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347353</td>\n",
       "      <td>0.336067</td>\n",
       "      <td>0.352745</td>\n",
       "      <td>0.337077</td>\n",
       "      <td>0.328565</td>\n",
       "      <td>0.106239</td>\n",
       "      <td>0.211546</td>\n",
       "      <td>0.163309</td>\n",
       "      <td>0.238714</td>\n",
       "      <td>0.203457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>-0.029413</td>\n",
       "      <td>0.149851</td>\n",
       "      <td>0.125294</td>\n",
       "      <td>-0.127413</td>\n",
       "      <td>-0.012841</td>\n",
       "      <td>0.021683</td>\n",
       "      <td>-0.085402</td>\n",
       "      <td>0.122947</td>\n",
       "      <td>0.018955</td>\n",
       "      <td>0.068041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022694</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>0.032012</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.055551</td>\n",
       "      <td>0.094124</td>\n",
       "      <td>0.060668</td>\n",
       "      <td>-0.005110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.199877</td>\n",
       "      <td>-0.048239</td>\n",
       "      <td>-0.111412</td>\n",
       "      <td>-0.154402</td>\n",
       "      <td>-0.210150</td>\n",
       "      <td>0.041593</td>\n",
       "      <td>-0.173204</td>\n",
       "      <td>-0.037298</td>\n",
       "      <td>-0.095530</td>\n",
       "      <td>-0.035351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.013796</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>-0.044321</td>\n",
       "      <td>-0.148727</td>\n",
       "      <td>-0.024698</td>\n",
       "      <td>-0.127360</td>\n",
       "      <td>0.016249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GID6569128  GID6688880  GID6688916  GID6688933  GID6688934  GID6688949  \\\n",
       "1      0.000000    0.031007    0.000000    0.235451    0.263178    0.000000   \n",
       "3      0.159308    0.000000    0.337087    0.000000    0.000000    0.132190   \n",
       "0      0.000000    0.031192    0.000000    0.229971    0.266903    0.000000   \n",
       "2      0.160683    0.000000    0.342964    0.000000    0.000000    0.135301   \n",
       "77    -0.065175    0.080083    0.043021   -0.130694   -0.205924    0.132232   \n",
       "704    0.159151   -0.025363    0.339005   -0.100481   -0.147644    0.131448   \n",
       "659   -0.004776    0.171068    0.044530   -0.135819   -0.208459    0.039600   \n",
       "196    0.100688   -0.024868    0.330083   -0.102867   -0.139393    0.201165   \n",
       "479   -0.029413    0.149851    0.125294   -0.127413   -0.012841    0.021683   \n",
       "571    0.199877   -0.048239   -0.111412   -0.154402   -0.210150    0.041593   \n",
       "\n",
       "     GID6689407  GID6689482  GID6689550  GID6738288  ...  GID6939899  \\\n",
       "1      0.215467    0.000000    0.050971    0.019646  ...    0.000000   \n",
       "3      0.000000    0.095368    0.003389    0.040034  ...    0.854050   \n",
       "0      0.219217    0.000000    0.050161    0.019814  ...    0.000000   \n",
       "2      0.000000    0.097157    0.003281    0.040431  ...    0.894954   \n",
       "77    -0.152645    0.320600    0.165367   -0.091276  ...   -0.000016   \n",
       "704   -0.165830    0.096148    0.003449    0.040360  ...    0.876694   \n",
       "659   -0.187181    0.211761    0.109432   -0.103757  ...   -0.059841   \n",
       "196   -0.177973    0.141686    0.075284    0.027967  ...    0.347353   \n",
       "479   -0.085402    0.122947    0.018955    0.068041  ...    0.022694   \n",
       "571   -0.173204   -0.037298   -0.095530   -0.035351  ...    0.003590   \n",
       "\n",
       "     GID6939900  GID6939902  GID6939903  GID6939904  GID6939917  GID6939919  \\\n",
       "1      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3      0.872537    0.867948    0.866145    0.859947    0.069269    0.240844   \n",
       "0      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2      0.892752    0.878516    0.838107    0.842036    0.067288    0.245286   \n",
       "77    -0.017010   -0.001881   -0.006795   -0.007432    0.103085    0.138323   \n",
       "704    0.889393    0.864300    0.847516    0.855128    0.068687    0.242398   \n",
       "659   -0.065622   -0.061719   -0.060266   -0.053595    0.130102    0.139344   \n",
       "196    0.336067    0.352745    0.337077    0.328565    0.106239    0.211546   \n",
       "479    0.028347    0.032012    0.020305    0.023039    0.067370    0.055551   \n",
       "571    0.013796    0.018200    0.009935    0.009367   -0.044321   -0.148727   \n",
       "\n",
       "     GID6939938  GID6939941  GID6939945  \n",
       "1      0.000000    0.000000    0.000000  \n",
       "3      0.506899    0.330434    0.590189  \n",
       "0      0.000000    0.000000    0.000000  \n",
       "2      0.507845    0.336892    0.591777  \n",
       "77     0.031083    0.186535    0.068227  \n",
       "704    0.505865    0.333481    0.585294  \n",
       "659    0.010878    0.093145    0.002047  \n",
       "196    0.163309    0.238714    0.203457  \n",
       "479    0.094124    0.060668   -0.005110  \n",
       "571   -0.024698   -0.127360    0.016249  \n",
       "\n",
       "[10 rows x 766 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_final:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.906514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.062448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.906201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.065679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5.716176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>6.067034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>5.742917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5.627525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>5.337074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>5.460984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           GY\n",
       "1    5.906514\n",
       "3    6.062448\n",
       "0    5.906201\n",
       "2    6.065679\n",
       "77   5.716176\n",
       "704  6.067034\n",
       "659  5.742917\n",
       "196  5.627525\n",
       "479  5.337074\n",
       "571  5.460984"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics of y_train_final:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.789255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.258523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.337074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.649688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.824559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.023464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.067034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              GY\n",
       "count  10.000000\n",
       "mean    5.789255\n",
       "std     0.258523\n",
       "min     5.337074\n",
       "25%     5.649688\n",
       "50%     5.824559\n",
       "75%     6.023464\n",
       "max     6.067034"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kevin\\dev\\ml_research\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`x` and `y` must have length at least 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37772\\3318881109.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Define hyperparameter grids for SVM regression model and conduct 2-dimensional cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mx_params_SVM_R\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAxisParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gamma'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbmo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_params_SVM_R\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAxisParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbmo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m metrics_SVM_R = outer_CV_R(n_outer_splits=5, \n\u001b[0m\u001b[0;32m      9\u001b[0m                            \u001b[0mn_inner_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                            \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                            \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37772\\3995637799.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(n_outer_splits, n_inner_splits, X, y, axis1_params, axis2_params, train_model_callback, random_state, top_boundary_val, smogn_preprocess, undersamp_ratio, oversamp_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# Find mean best hyperparameter values based on prediction accuracy using inner-fold CV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mbest_param1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_param2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner_CV_R\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_inner_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis1_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis2_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_model_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_title\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf\"Outer Fold {i}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;31m# Train model with all training and CV data of outer fold using mean best hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0msuper_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis1_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis2_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_param1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_param2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37772\\1276105468.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(n_splits, X, y, axis1_params, axis2_params, train_model_callback, kfold_random_state, plot_title, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m# Create 2D array of identical dataframes containing actual labels to compare against predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0my_test_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_array_of_dfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_preds_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m# Evaluate predictions by comparing to actuals, calculating 2D array of Pearson coefficients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mpearson_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbmo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_pearson_coefficients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_preds_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# Find index of best Pearson coefficient in the 2D array of Pearson coefficients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mbest_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpearson_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpearson_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\dev\\ml_research\\basic_ml_operations.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(preds_grid, actuals_grid)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds_grid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[0my_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactuals_grid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m             \u001b[0mpearson_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m             \u001b[0mpearson_coeffs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpearson_coef\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpearson_coeffs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\dev\\ml_research\\venv\\Lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y, alternative, method, axis)\u001b[0m\n\u001b[0;32m   4812\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4813\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`x` and `y` must have the same length along `axis`.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4815\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4816\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`x` and `y` must have length at least 2.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4818\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4819\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `x` and `y` must have length at least 2."
     ]
    }
   ],
   "source": [
    "# reduce dataset to 2% of original size for quick debugging\n",
    "X = X.sample(frac=0.02, random_state=RANDOM_STATE)\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Define hyperparameter grids for SVM regression model and conduct 2-dimensional cross-validation\n",
    "x_params_SVM_R = mdo.AxisParams('gamma', bmo.power_list(2, -14, -6))\n",
    "y_params_SVM_R = mdo.AxisParams('C', bmo.power_list(2, -2, 6))\n",
    "metrics_SVM_R = outer_CV_R(n_outer_splits=5, \n",
    "                           n_inner_splits=10, \n",
    "                           X=X, \n",
    "                           y=y,\n",
    "                           axis1_params=x_params_SVM_R, \n",
    "                           axis2_params=y_params_SVM_R, \n",
    "                           train_model_callback=bmo.train_SVM_regressor, \n",
    "                           smogn_preprocess=SMOGN_PREPROCESS,\n",
    "                           random_state=RANDOM_STATE, \n",
    "                           top_boundary_val=top_boundary_val, \n",
    "                           undersamp_ratio=0.5,\n",
    "                           oversamp_ratio=1,\n",
    "                           kernel='rbf')\n",
    "\n",
    "\"\"\"\n",
    "# Dummy values - Uncomment for quick debugging tests  \n",
    "x_params_SVM_R = mdo.AxisParams('gamma', bmo.power_list(2, -1, 0))  \n",
    "y_params_SVM_R = mdo.AxisParams('C', bmo.power_list(2, 1, 2))  \n",
    "metrics_SVM_R = outer_CV_R(n_outer_splits=2,   \n",
    "                           n_inner_splits=2,   \n",
    "                           X=X, \n",
    "                           y=y,\n",
    "                           axis1_params=x_params_SVM_R, \n",
    "                           axis2_params=y_params_SVM_R, \n",
    "                           train_model_callback=bmo.train_SVM_regressor, \n",
    "                           smogn_preprocess=SMOGN_PREPROCESS,\n",
    "                           undersample=UNDERSAMPLE,\n",
    "                           kfold_random_state=RANDOM_STATE, \n",
    "                           top_boundary_val=top_boundary_val, \n",
    "                           kernel='rbf')  \n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec953e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification metrics for best model from each outer fold\n",
    "display(metrics_SVM_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save average of each metric\n",
    "metrics_SVM_R_mean = metrics_SVM_R.mean().to_frame().T\n",
    "R_average_metrics.loc['SVM'] = metrics_SVM_R_mean.iloc[0]\n",
    "display(metrics_SVM_R_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddd5e6",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3dd110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test values\n",
    "x_params_XGB_R = mdo.AxisParams('n_estimators', [13, 25, 50, 100, 200])\n",
    "y_params_XGB_R = mdo.AxisParams('max_depth', [1, 2, 3, 4, 6, 10, 16])\n",
    "metrics_XGB_R = outer_CV_R(n_outer_splits=5, \n",
    "                           n_inner_splits=10, \n",
    "                           X=X, \n",
    "                           y=y,  \n",
    "                           axis1_params=x_params_XGB_R, \n",
    "                           axis2_params=y_params_XGB_R, \n",
    "                           train_model_callback=bmo.train_XGB_regressor, \n",
    "                           smogn_preprocess=SMOGN_PREPROCESS,\n",
    "                           undersample_ratio=UNDERSAMPLE,\n",
    "                           random_state=RANDOM_STATE, \n",
    "                           top_boundary_val=top_boundary_val, \n",
    "                           objective=\"reg:squarederror\", eval_metric=\"rmse\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Dummy values for quick debugging tests\n",
    "x_params_XGB_R = mdo.AxisParams('n_estimators', [1, 2])\n",
    "y_params_XGB_R = mdo.AxisParams('max_depth', [1, 2])\n",
    "metrics_XGB_R = outer_CV_R(2, 2,  \n",
    "                           X=X, \n",
    "                           y=y,  \n",
    "                           axis1_params=x_params_XGB_R, \n",
    "                           axis2_params=y_params_XGB_R, \n",
    "                           train_model_callback=bmo.train_XGB_regressor, \n",
    "                           smogn_preprocess=SMOGN_PREPROCESS,\n",
    "                           undersample=UNDERSAMPLE,\n",
    "                           kfold_random_state=RANDOM_STATE, \n",
    "                           top_boundary_val=top_boundary_val, \n",
    "                           objective=\"reg:squarederror\", eval_metric=\"rmse\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification metrics for best model from each outer fold\n",
    "display(metrics_XGB_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f701d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric and store results for analysis\n",
    "metrics_XGB_R_mean = metrics_XGB_R.mean().to_frame().T\n",
    "display(metrics_XGB_R_mean)\n",
    "R_average_metrics.loc['XGB'] = metrics_XGB_R_mean.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save serialized session variables and models to disk for later use\n",
    "dill.dump_session(f'{storage_dir}\\\\project_ipynb_env_R.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b59b6d",
   "metadata": {},
   "source": [
    "# Model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV_B(n_splits: int, X : pd.DataFrame, y_bin : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, \n",
    "               train_model_callback, kfold_random_state: int, classification_col : int, plot_title: str = \"\", \n",
    "               **kwargs):\n",
    "    \"\"\"\n",
    "    Perform inner cross-validation to tune model hyperparameters and find the optimal classification threshold.\n",
    "    Created: 2024/12/04\n",
    "    Parameters:\n",
    "    n_splits (int): Number of splits for KFold cross-validation.\n",
    "    X (pd.DataFrame): Feature data.\n",
    "    y (pd.DataFrame): Target data.\n",
    "    axis1_params (mdo.AxisParams): Object containing hyperparameter values for the first (horizontal) axis.\n",
    "    axis2_params (mdo.AxisParams): Object containing hyperparameter values for the second (vertical) axis.\n",
    "    train_model_callback (function): Callback function to train the model.\n",
    "    kfold_random_state (int): Random state for KFold shuffling.\n",
    "    classification_col (int): Column index to pull classification probabilities from - 0 for not top, 1 for top.\n",
    "    top_thresh_quantile (float): Threshold to classify predictions as top or not top.\n",
    "    plot_title (str, optional): Title for the ROC plot. Defaults to \"\".\n",
    "    **kwargs: Additional arguments for the train_model_callback function.\n",
    "    Returns:\n",
    "    tuple: Average best parameters (param1, param2) and the best classification threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    # Arrays to store parameters and binary classification thresholds of the most accurate model for each inner fold\n",
    "    best_params = pd.DataFrame(columns=['param1', 'param2'], index=range(n_splits))\n",
    "    best_thresholds = pd.DataFrame(columns=['threshold'], index=range(n_splits))\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_bin_train, y_bin_test = y_bin.iloc[train_index], y_bin.iloc[test_index]\n",
    "\n",
    "        # Train a grid of models with every combination of parameters\n",
    "        model_grid = bmo.train_model_grid(X_train, y_bin_train, axis1_params, axis2_params, train_model_callback, **kwargs)\n",
    "        \n",
    "        # Use trained models to predict test set probabilities, and store in a 2D array with each cell corresponding to a model with a specific combination of parameters\n",
    "        y_proba_preds_grid = bmo.grid_predict_proba(X_test, model_grid, classification_col)\n",
    "\n",
    "        # Use probabilities to classify predictions as top or not top. This isn't the final classification, \n",
    "        # but a step towards finding the optimal threshold, so we just use the default 0.5 threshold for now.\n",
    "        y_binary_preds_grid = bmo.continuous_to_binary_absolute_grid(y_proba_preds_grid, 0.5)\n",
    "\n",
    "        # Create a 2D array of identical dataframes containing actual labels to compare against predictions\n",
    "        y_bin_test_grid = cdt.np_array_of_dfs(y_bin_test, y_proba_preds_grid.shape)\n",
    "\n",
    "        # Evaluate predictions by comparing to actuals, calculating a 2D array of F1 scores.\n",
    "        f1_grid = bmo.calculate_f1_scores(y_binary_preds_grid, y_bin_test_grid)\n",
    "\n",
    "        # Find the index of the best F1 score in the 2D array of F1 scores\n",
    "        best_row, best_col = np.unravel_index(np.argmax(f1_grid), f1_grid.shape)\n",
    "\n",
    "        # Store hyperparameters of the most accurate model for this inner fold\n",
    "        best_params.loc[i] = [axis1_params.values[best_row], axis2_params.values[best_col]]\n",
    "\n",
    "        # Find the classification probability threshold between zero and one that yields the lowest squared difference between sensitivity and \n",
    "        # specificity using this optimal model. To do this, we feed find_optimal_threshold() the probabilities predicted by the model, not the binary predictions.\n",
    "        best_model_proba_preds = y_proba_preds_grid[best_row, best_col]\n",
    "        best_thresholds.iloc[i, 0] = bmo.find_optimal_threshold_absolute(y_bin_test, best_model_proba_preds)\n",
    "\n",
    "        # Create a grid of ROC plots with predictions vs actuals, colored by F1 score for each model\n",
    "        roc_grid = plot_shaded_roc_grids(y_proba_preds_grid, y_bin_test_grid, axis1_params, axis2_params, f1_grid, f'{plot_title} | Inner Fold {i}')        \n",
    "        plt.savefig(f'{storage_dir}\\\\model_B, {train_model_callback.__name__}, ({plot_title}, Inner Fold {i}).svg', format=\"svg\")\n",
    "\n",
    "        plt.show(roc_grid)\n",
    "        plt.close(roc_grid)\n",
    "\n",
    "    # Calculate average best parameters over all inner folds to return to outer CV\n",
    "    avg_best_param1 = best_params['param1'].mean()\n",
    "    avg_best_param2 = best_params['param2'].mean()\n",
    "\n",
    "    # Calculate average best threshold over all folds\n",
    "    best_threshold = best_thresholds['threshold'].mean()\n",
    "\n",
    "    return avg_best_param1, avg_best_param2, best_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fba289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_CV_B(n_outer_splits: int, n_inner_splits: int, X : pd.DataFrame, y : pd.DataFrame, \n",
    "               axis1_params: mdo.AxisParams, \n",
    "               axis2_params: mdo.AxisParams, train_model_callback : callable, random_state: int, \n",
    "               classification_col : int, top_boundary_val : float, smote_preprocess = False, undersamp_ratio=1, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform nested cross-validation with an outer and inner loop to evaluate model B performance.\n",
    "    Created: 2024/12/29\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_outer_splits : int\n",
    "        Number of splits for the outer cross-validation.\n",
    "    n_inner_splits : int\n",
    "        Number of splits for the inner cross-validation.\n",
    "    X : pd.DataFrame\n",
    "        Feature data.\n",
    "    y : pd.DataFrame\n",
    "        Target data.\n",
    "    axis1_params : mdo.AxisParams\n",
    "        Object representing hyperparameter search space for the first axis.\n",
    "    axis2_params : mdo.AxisParams\n",
    "        Object representing hyperparameter search space for the second axis.\n",
    "    train_model_callback : callable\n",
    "        Function to train the model.\n",
    "    kfold_random_state : int\n",
    "        Random state for reproducibility in KFold.\n",
    "    classification_col : int\n",
    "        Column index to pull classification probabilities from - 0 for not top, 1 for top.\n",
    "    top_line_thresh : float\n",
    "        Threshold to classify predictions as top or not top.\n",
    "    **kwargs : dict\n",
    "        Additional parameters for the model training function.\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing the metrics for each outer fold, including F1 Score, Sensitivity, Specificity, and Kappa.\n",
    "    \"\"\"\n",
    "    \n",
    "    kfold = KFold(n_splits=n_outer_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Store metrics of best model for each fold\n",
    "    kfold_metrics = pd.DataFrame(columns=['F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        y_train_bin = bmo.continuous_to_binary_absolute(y_train, top_boundary_val)\n",
    "        y_test_bin = bmo.continuous_to_binary_absolute(y_test, top_boundary_val)\n",
    "\n",
    "        if smote_preprocess:\n",
    "            sm = SMOTE(random_state=random_state)\n",
    "            X_train, y_train_bin = sm.fit_resample(X_train, y_train_bin)\n",
    "\n",
    "            # Split the top and not top lines into seperate dataframes\n",
    "            y_train_top = y_train_bin[y_train_bin == 1]\n",
    "            X_train_top = X_train.loc[y_train_top.index]\n",
    "            y_train_not_top = y_train_bin[y_train_bin == 0]\n",
    "            X_train_not_top = X_train.loc[y_train_not_top.index]\n",
    "\n",
    "            # Undersample the majority class so that it is a certain proportion of its original size\n",
    "            X_train_not_top_us, y_train_not_top_us = cdt.random_subset(X_train_not_top, y_train_not_top, p=undersamp_ratio, random_state=random_state)\n",
    "\n",
    "            # Re-combine the top and not top line data\n",
    "            X_train = pd.concat([X_train_top, X_train_not_top_us], axis=0)\n",
    "            y_train = pd.concat([y_train_top, y_train_not_top_us], axis=0)\n",
    "        \n",
    "        X_train, _, X_scaler, _ = scale_features_and_target(X_train, None)\n",
    "        X_test = X_scaler.transform(X_test)\n",
    "\n",
    "        # Find average best parameters and threshold based on F1 score using inner-fold CV\n",
    "        best_param1, best_param2, best_threshold = inner_CV_B(n_inner_splits, X_train, y_train_bin, axis1_params, axis2_params, train_model_callback, random_state, classification_col, plot_title=f\"Outer Fold {i}\", **kwargs)\n",
    "\n",
    "        # Train model with all training and CV data of outer fold using mean best hyperparameters\n",
    "        super_model = train_model_callback(X_train, np.ravel(y_train_bin), **dict(zip([axis1_params.name, axis2_params.name], [best_param1, best_param2])), **kwargs)\n",
    "\n",
    "        # Use trained \"super-model\" to predict test set probabilities\n",
    "        y_pred_proba = pd.DataFrame(super_model.predict_proba(X_test)[:, classification_col], index=y_test_bin.index, columns=y_test_bin.columns)\n",
    "        histogram(y_pred_proba, f'Top Line Probability Histogram, {train_model_callback.__name__}, Outer Fold {i}', x_ax_label='Top Line Probability')\n",
    "\n",
    "        # Classify predictions and actuals of super_model as top or not top (boolean) using the best threshold as determined by inner CV\n",
    "        y_pred_bin = bmo.continuous_to_binary_absolute(y_pred_proba, best_threshold)\n",
    "\n",
    "        # Plot ROC and PR curves using seaborn\n",
    "        cmp.sns_plot_roc_curve(pd.DataFrame(y_test_bin), pd.DataFrame(y_pred_proba), f'Model B ROC Curve, {train_model_callback.__name__}, Outer Fold {i}')\n",
    "        plt.savefig(f'{storage_dir}\\\\Model B ROC Curve, {train_model_callback.__name__}, Outer Fold {i}.svg', format=\"svg\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        cmp.sns_plot_pr_curve(pd.DataFrame(y_test_bin), pd.DataFrame(y_pred_proba), f'Model B PR Curve, {train_model_callback.__name__}, Outer Fold {i}')\n",
    "        plt.savefig(f'{storage_dir}\\\\Model B PR Curve, {train_model_callback.__name__}, Outer Fold {i}.svg', format=\"svg\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "        # Calculate classification metrics and add new row to kfold_metrics   \n",
    "        classification_metrics = cdt.classification_metrics(y_pred_bin, y_test_bin)   \n",
    "        kfold_metrics = pd.concat([kfold_metrics, classification_metrics], axis=0)   \n",
    "\n",
    "    # Label each row of kfold_metrics with the fold number\n",
    "    kfold_metrics.index = range(n_outer_splits)\n",
    "    return kfold_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7457c6",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define hyperparameter grids for SVM classification model and conduct 2-dimensional cross-validation\n",
    "x_params_SVM_B = mdo.AxisParams('gamma', bmo.power_list(2, -18, -8))\n",
    "y_params_SVM_B = mdo.AxisParams('C', bmo.power_list(2, 2, 16))\n",
    "metrics_SVM_B = outer_CV_B(5, 10, X, y, x_params_SVM_B, y_params_SVM_B, bmo.train_SVM_classifier, \n",
    "                           random_state=RANDOM_STATE, classification_col=1, top_boundary_val=top_boundary_val, \n",
    "                           smote_preprocess=SMOGN_PREPROCESS, probability=True, kernel='rbf')\n",
    "\n",
    "\"\"\"\n",
    "# Dummy values for tests\n",
    "x_params_SVM_B = mdo.AxisParams('gamma', bmo.power_list(2, -10, -9))\n",
    "y_params_SVM_B = mdo.AxisParams('C', bmo.power_list(2, 0, 1))\n",
    "metrics_SVM_B = outer_CV_B(2, 2, X, y, x_params_SVM_B, y_params_SVM_B, bmo.train_SVM_classifier, kfold_random_state=RANDOM_STATE, kernel='rbf', classification_col=1, top_boundary_val=top_boundary_val, probability=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7219ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification metrics for super-model trained on all data from each outer fold\n",
    "display(metrics_SVM_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc3995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "metrics_SVM_B_mean = metrics_SVM_B.mean().to_frame().T\n",
    "B_average_metrics.loc['SVM'] = metrics_SVM_B_mean.iloc[0]\n",
    "display(metrics_SVM_B_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf6cd8",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aeca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids for XGB classification model and conduct 2-dimensional cross-validation\n",
    "x_params_XGB_B = mdo.AxisParams('n_estimators', [3, 7, 13, 25, 50, 100, 200, 400])\n",
    "y_params_XGB_B = mdo.AxisParams('max_depth', [1, 2, 3, 4, 6, 10, 16, 32, 64])\n",
    "metrics_XGB_B = outer_CV_B(5, 10, X, y, x_params_XGB_B, y_params_XGB_B, bmo.train_XGB_classifier, random_state=RANDOM_STATE, \n",
    "                           classification_col=1, top_boundary_val=top_boundary_val, smote_preprocess=SMOGN_PREPROCESS, \n",
    "                           objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "\n",
    "\"\"\"\n",
    "# Dummy values for quick tests\n",
    "x_params_XGB_B = mdo.AxisParams('n_estimators', [1, 2])\n",
    "y_params_XGB_B = mdo.AxisParams('max_depth', [1, 2])\n",
    "metrics_XGB_B = outer_CV_B(2, 2, X, y, x_params_XGB_B, y_params_XGB_B, bmo.train_XGB_classifier, random_state=RANDOM_STATE, \n",
    "                           classification_col=1, top_boundary_val=top_boundary_val, smote_preprocess=SMOGN_PREPROCESS, \n",
    "                           objective=\"binary:logistic\", eval_metric=\"logloss\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(metrics_XGB_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "metrics_XGB_B_mean = metrics_XGB_B.mean().to_frame().T\n",
    "B_average_metrics.loc['XGB'] = metrics_XGB_B_mean.iloc[0]\n",
    "display(metrics_XGB_B_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc98a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save serialized session variables and models to disk for later use\n",
    "dill.dump_session(f'{storage_dir}\\\\project_ipynb_env_B.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de75da",
   "metadata": {},
   "source": [
    "# Model RO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82681b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV_RO(n_splits: int, X : pd.DataFrame, y : pd.DataFrame, y_top_bound : float, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback, \n",
    "                kfold_random_state: int, plot_title: str = \"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Perform inner cross-validation (RO) to find the best model parameters and classification threshold.\n",
    "    Created: 2024/12/21\n",
    "    Parameters:\n",
    "    n_splits (int): Number of splits for K-Fold cross-validation.\n",
    "    X (pd.DataFrame): Feature data.\n",
    "    y (pd.DataFrame): Target data.\n",
    "    axis1_params (mdo.AxisParams): Hyperparameters to explore for the horizontal axis.\n",
    "    axis2_params (mdo.AxisParams): Hyperparameters to explore for the vertical axis.\n",
    "    train_model_callback (callable): Callback function to train the model.\n",
    "    kfold_random_state (int): Random state for K-Fold shuffling.\n",
    "    top_line_threshold (float): Threshold to classify top values during intermediate step in inner CV.\n",
    "    plot_title (str, optional): Title for the plot. Defaults to \"\".\n",
    "    **kwargs: Additional keyword arguments for the model training callback.\n",
    "    Returns:\n",
    "    tuple: Average best parameters for axis1 and axis2, and the best classification threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create KFold object for inner-fold cross-validation\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    # Store best parameters (param1, param2) for each fold\n",
    "    best_params = pd.DataFrame(columns=['param1', 'param2'], index=range(n_splits))\n",
    "    best_thresholds = pd.DataFrame(columns=['threshold'], index=range(n_splits))\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train a grid of models with every combination of parameters\n",
    "        model_grid = bmo.train_model_grid(X_train, y_train, axis1_params, axis2_params, train_model_callback, **kwargs)\n",
    "\n",
    "        # Use trained models to predict test set labels, and store in a 2D array with each cell corresponding to a model with a specific combination of parameters\n",
    "        y_preds_grid = bmo.grid_predict(X_test, model_grid)\n",
    "\n",
    "        # Create a 2D array of identical dataframes containing actual labels to compare against predictions\n",
    "        y_test_grid = cdt.np_array_of_dfs(y_test, y_preds_grid.shape)\n",
    "\n",
    "        # Evaluate predictions by comparing to actuals, calculating a 2D array of Pearson coefficients\n",
    "        pearson_grid = bmo.calculate_pearson_coefficients(y_preds_grid, y_test_grid)\n",
    "\n",
    "        # Find the index of the best Pearson coefficient in the 2D array of Pearson coefficients\n",
    "        best_row, best_col = np.unravel_index(np.argmax(pearson_grid), pearson_grid.shape)\n",
    "        \n",
    "        # Store hyperparameters of the most accurate model for this inner fold\n",
    "        best_params.loc[i] = [axis1_params.values[best_row], axis2_params.values[best_col]]\n",
    "\n",
    "        # Extract best model's continuous predictions\n",
    "        best_model_y_preds = y_preds_grid[best_row, best_col]\n",
    "\n",
    "        # Classify labels as top or not top (boolean)\n",
    "        y_test_binary = bmo.continuous_to_binary_absolute(y_test, y_top_bound)\n",
    "        \n",
    "        # Find classification threshold that yields the lowest squared difference between sensitivity and specificity using this optimal model\n",
    "        best_absolute_thresh = bmo.find_optimal_threshold_absolute(y_test_binary, best_model_y_preds)\n",
    "        best_thresholds.iloc[i, 0] = best_absolute_thresh\n",
    "\n",
    "        # Create a grid of scatter plots with predictions vs actuals, colored by Pearson coefficient for each model\n",
    "        scatter_grid = plot_shaded_scatter_grids(y_preds_grid, y_test_grid, axis1_params, axis2_params, pearson_grid, f'{plot_title} | Inner Fold {i}')        \n",
    "        plt.savefig(f'{storage_dir}\\\\model_RO, {train_model_callback.__name__}, ({plot_title}, Inner Fold {i}).svg', format=\"svg\")\n",
    "        plt.show(scatter_grid)\n",
    "        plt.close(scatter_grid)\n",
    "\n",
    "    # Calculate average best parameters over all folds\n",
    "    avg_best_param1 = best_params['param1'].mean()\n",
    "    avg_best_param2 = best_params['param2'].mean()\n",
    "\n",
    "    # Calculate average best threshold over all folds\n",
    "    best_threshold = best_thresholds['threshold'].mean()\n",
    "\n",
    "    return avg_best_param1, avg_best_param2, best_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_CV_RO(n_outer_splits: int, n_inner_splits: int, X : pd.DataFrame, y : pd.DataFrame, \n",
    "                axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback : callable, \n",
    "                kfold_random_state: int, top_boundary_val : float, smogn_preprocess : bool = False, undersample : bool = True,\n",
    "                **kwargs) -> (pd.DataFrame, list):\n",
    "    \"\"\"\n",
    "    Perform outer cross-validation with nested inner cross-validation for model RO selection and evaluation.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_outer_splits : int\n",
    "        Number of splits for the outer cross-validation.\n",
    "    n_inner_splits : int\n",
    "        Number of splits for the inner cross-validation.\n",
    "    X : pd.DataFrame\n",
    "        Feature data.\n",
    "    y : pd.DataFrame\n",
    "        Target data.\n",
    "    axis1_params : mdo.AxisParams\n",
    "        Object representing hyperparameter search space for the first axis.\n",
    "    axis2_params : mdo.AxisParams\n",
    "        Object representing hyperparameter search space for the second axis.\n",
    "    train_model_callback : callable\n",
    "        Callback function to train the model.\n",
    "    kfold_random_state : int\n",
    "        Random state for reproducibility in KFold splitting.\n",
    "    top_line_threshold : float\n",
    "        Threshold for classifying top predictions during intermediate step in inner CV.\n",
    "    **kwargs : dict\n",
    "        Additional parameters for the model training callback.\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing the evaluation metrics for each outer fold, including Pearson correlation, F1 Score, Sensitivity, Specificity, and Kappa.\n",
    "    list\n",
    "        List of trained super_models for each outer fold.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create KFold object for outer loop to split data into train and test sets\n",
    "    kfold = KFold(n_splits=n_outer_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    # Initialize DataFrame to store evaluation metrics for each outer fold\n",
    "    kfold_metrics = pd.DataFrame(columns=['Pearson', 'F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "    \n",
    "    # Initialize list to store super_models for each outer fold\n",
    "    super_models = []\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        if smogn_preprocess:\n",
    "            top_boundary_quantile_in_train_set = percentileofscore(y_train.to_numpy().flatten(), top_boundary_val, kind='mean') / 100\n",
    "\n",
    "            # Store pre-SMOGN data for later use\n",
    "            X_train_pre_smogn = X_train.copy()\n",
    "            y_train_pre_smogn = y_train.copy()\n",
    "            X_train, y_train = smogn_prep(X_train, y_train, top_boundary_quantile_in_train_set, undersample)\n",
    "\n",
    "            if not undersample:\n",
    "                # Manually concatenate the original data below the augmentation threshold with the augmented data\n",
    "                non_augmented_indices = y_train_pre_smogn[y_train_pre_smogn < top_boundary_val].index\n",
    "                X_train_non_augmented = X_train_pre_smogn.loc[non_augmented_indices]\n",
    "                y_train_non_augmented = y_train_pre_smogn.loc[non_augmented_indices]\n",
    "                X_train = pd.concat([X_train, X_train_non_augmented], axis=0)\n",
    "                y_train = pd.concat([y_train, y_train_non_augmented], axis=0)\n",
    "\n",
    "            # Split the augmented and original data into seperate columns for plotting\n",
    "            original_data = pra.intersection(y_train_pre_smogn, y_train)\n",
    "            augmented_data = pra.difference(y_train, original_data)\n",
    "            orig_aug_data = pd.concat([original_data, augmented_data], axis=1)\n",
    "            orig_aug_data.columns = ['Original GY', 'Augmented GY']\n",
    "\n",
    "            histogram(orig_aug_data, f'Model RO SMOGN-Augmented GY Histogram, Outer Fold {i}', vline_value=top_boundary_val)\n",
    "        else:\n",
    "            histogram(y_train, f'Model RO Histogram, Outer Fold {i}', vline_value=top_boundary_val)\n",
    "\n",
    "\n",
    "        # Scale features and target for the training data\n",
    "        X_train, y_train, X_scaler, y_scaler = scale_features_and_target(X_train, y_train)\n",
    "        # Scale the top boundary value\n",
    "        top_boundary_val_scaled = y_scaler.transform([[top_boundary_val]])[0, 0]\n",
    "        # Scale the test data using the same scaler as the training data\n",
    "        X_test = pd.DataFrame(X_scaler.transform(X_test))\n",
    "        X_test.columns = X.columns\n",
    "        y_test = pd.DataFrame(y_scaler.transform(y_test))\n",
    "\n",
    "        # Find average best parameters and threshold based on Pearson score using inner-fold CV\n",
    "        best_param1, best_param2, best_threshold_fixed = inner_CV_RO(n_inner_splits, X_train, y_train, top_boundary_val_scaled, axis1_params, axis2_params, train_model_callback, kfold_random_state, plot_title=f\"Outer Fold {i}\", **kwargs)\n",
    "\n",
    "        # Train model with all training and CV data of outer fold using mean best hyperparameters\n",
    "        super_model = train_model_callback(X_train, np.ravel(y_train), **dict(zip([axis1_params.name, axis2_params.name], [best_param1, best_param2])), **kwargs)\n",
    "        \n",
    "        # Append the trained super_model to the list\n",
    "        super_models.append(super_model)\n",
    "\n",
    "        # Use trained \"super-model\" to predict test set\n",
    "        y_pred = pd.DataFrame(super_model.predict(X_test).reshape(-1, 1), index=y_test.index, columns=y_test.columns)\n",
    "        # Plot histogram of the predicted values\n",
    "        histogram(y_pred, f'Predicted GY Histogram, {train_model_callback.__name__}, Outer Fold {i}')\n",
    "\n",
    "        # Calculate Pearson coefficient of continuous predictions\n",
    "        pearson, _ = pearsonr(np.ravel(y_pred), np.ravel(y_test))\n",
    "\n",
    "        # Classify predictions and actuals of super_model as top or not top (boolean)\n",
    "        y_pred_top = bmo.continuous_to_binary_absolute(y_pred, best_threshold_fixed)\n",
    "        y_test_top = bmo.continuous_to_binary_absolute(y_test, top_boundary_val_scaled)\n",
    "\n",
    "        # Plot classification results\n",
    "        cmp.plot_classification_results(y_pred, y_test, y_pred_top, y_test_top, \n",
    "                                [f\"Model RO Predicted vs Actual GY, {train_model_callback.__name__}, Outer Fold {i}\"],\n",
    "                                save_path=f'{storage_dir}\\\\Model RO Super Model Predicted vs Actual GY, {train_model_callback.__name__}, Outer Fold {i}.svg')\n",
    "\n",
    "        # Calculate classification metrics and add new row to kfold_metrics\n",
    "        classification_metrics = cdt.classification_metrics(y_pred_top, y_test_top)\n",
    "        pearson_df = pd.DataFrame([pearson], columns=['Pearson'])\n",
    "        metrics_row = pd.concat([pearson_df, classification_metrics], axis=1)\n",
    "        kfold_metrics = pd.concat([kfold_metrics, metrics_row], axis=0)\n",
    "    \n",
    "    # Reset index of the metrics DataFrame\n",
    "\n",
    "    kfold_metrics.index = range(n_outer_splits)\n",
    "    return kfold_metrics, super_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac635306",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e7c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set hyperparameter grids for SVM regression model and conduct 2-dimensional cross-validation\n",
    "x_params_SVM_RO = mdo.AxisParams('gamma', bmo.power_list(2, -14, -6))\n",
    "y_params_SVM_RO = mdo.AxisParams('C', bmo.power_list(2, -2, 6))\n",
    "metrics_SVM_RO, RO_SVM_models = outer_CV_RO(5, 10, X, y, x_params_SVM_RO, y_params_SVM_RO, bmo.train_SVM_regressor, \n",
    "                             kfold_random_state=RANDOM_STATE, top_boundary_val=top_boundary_val, smogn_preprocess=SMOGN_PREPROCESS, \n",
    "                            undersample=UNDERSAMPLE, kernel='rbf')\n",
    "\n",
    "\"\"\"\n",
    "# Quick test values\n",
    "x_params_SVM_RO = mdo.AxisParams('gamma', bmo.power_list(2, -8, -7))\n",
    "y_params_SVM_RO = mdo.AxisParams('C', bmo.power_list(2, 0, 1))\n",
    "metrics_SVM_RO, RO_SVM_models = outer_CV_RO(2, 2, X, y, x_params_SVM_RO, y_params_SVM_RO, bmo.train_SVM_regressor, \n",
    "                             kfold_random_state=RANDOM_STATE, top_boundary_val=top_boundary_val, smogn_preprocess=SMOGN_PREPROCESS, \n",
    "                             undersample=UNDERSAMPLE, kernel='rbf')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP:\n",
    "    # Create a background dataset (using ~25% of data)\n",
    "    n_background = 200  # 25% of 800 points\n",
    "    background_data = shap.sample(X, n_background, random_state=42)  # Using random sampling for better representation\n",
    "\n",
    "    # Create the SHAP explainer with the correct parameters\n",
    "    explainer = shap.KernelExplainer(RO_SVM_models[0].predict, background_data)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "    # Create the summary plot\n",
    "    shap.summary_plot(shap_values, X, plot_type=\"bar\", show=False)\n",
    "    plt.savefig(f'{storage_dir}\\\\SHAP Summary Plot, SVM, Outer Fold 0.svg', format=\"svg\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975314ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(metrics_SVM_RO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb307e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "metrics_SVM_RO_mean = metrics_SVM_RO.mean().to_frame().T\n",
    "RO_average_metrics.loc['SVM'] = metrics_SVM_RO_mean.iloc[0]\n",
    "display(metrics_SVM_RO_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2313db",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids for XGB regression model and conduct 2-dimensional cross-validation\n",
    "x_params_XGB_RO = mdo.AxisParams('n_estimators', [3, 7, 13, 25, 50, 100, 200])\n",
    "y_params_XGB_RO = mdo.AxisParams('max_depth', [1, 2, 3, 4, 6, 10, 16, 32, 64])\n",
    "metrics_XGB_RO, RO_XGB_models = outer_CV_RO(5, 10, X, y, x_params_XGB_RO, y_params_XGB_RO, bmo.train_XGB_regressor, \n",
    "                             kfold_random_state=RANDOM_STATE, random_state=RANDOM_STATE, top_boundary_val=top_boundary_val, \n",
    "                             smogn_preprocess=SMOGN_PREPROCESS, undersample=UNDERSAMPLE, objective=\"reg:squarederror\", \n",
    "                             eval_metric=\"rmse\")\n",
    "\"\"\"\n",
    "# Quick test values\n",
    "x_params_XGB_RO = mdo.AxisParams('n_estimators', [1, 2])\n",
    "y_params_XGB_RO = mdo.AxisParams('max_depth', [1, 2])\n",
    "metrics_XGB_RO, RO_XGB_models = outer_CV_RO(2, 2, X, y, x_params_XGB_RO, y_params_XGB_RO, bmo.train_XGB_regressor, \n",
    "                                kfold_random_state=RANDOM_STATE, random_state=RANDOM_STATE, top_boundary_val=top_boundary_val, \n",
    "                                smogn_preprocess=SMOGN_PREPROCESS, undersample=UNDERSAMPLE, objective=\"reg:squarederror\", \n",
    "                                eval_metric=\"rmse\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3774b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP:\n",
    "    # Create a background dataset (using ~25% of data)\n",
    "    n_background = 200  # 25% of 800 points\n",
    "    background_data = shap.sample(X, n_background, random_state=42)\n",
    "\n",
    "    # Create a wrapper function for the model's predict method\n",
    "    def model_predict(x):\n",
    "        return RO_XGB_models[0].predict(x)\n",
    "\n",
    "    # Create the SHAP explainer with the wrapper function\n",
    "    explainer = shap.KernelExplainer(model_predict, background_data)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "    # Create the summary plot\n",
    "    shap.summary_plot(shap_values, X, plot_type=\"bar\", show=False)\n",
    "    plt.savefig(f'{storage_dir}\\\\SHAP Summary Plot, SVM, Outer Fold 0.svg', format=\"svg\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37545449",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(metrics_XGB_RO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521925c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "metrics_XGB_RO_mean = metrics_XGB_RO.mean().to_frame().T\n",
    "RO_average_metrics.loc['XGB'] = metrics_XGB_RO_mean.iloc[0]\n",
    "display(metrics_XGB_RO_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save serialized session variables and models to disk for later use\n",
    "dill.dump_session(f'{storage_dir}\\\\project_ipynb_env_RO.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cdc2c5",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3691a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average metrics for each model to compare GBLUP, SVM, and XGB\n",
    "R_avg_metrics_plot = cmp.plot_model_metrics(R_average_metrics, \"R\")\n",
    "R_avg_metrics_plot.savefig(f'{storage_dir}\\\\R_avg_metrics_plot.svg', format='svg')\n",
    "plt.show(R_avg_metrics_plot)\n",
    "plt.close(R_avg_metrics_plot)\n",
    "\n",
    "B_avg_metrics_plot = cmp.plot_model_metrics(B_average_metrics, \"B\")\n",
    "B_avg_metrics_plot.savefig(f'{storage_dir}\\\\B_avg_metrics_plot.svg', format='svg')\n",
    "plt.show(B_avg_metrics_plot)\n",
    "plt.close(B_avg_metrics_plot)\n",
    "\n",
    "RO_avg_metrics_plot = cmp.plot_model_metrics(RO_average_metrics, \"RO\")\n",
    "RO_avg_metrics_plot.savefig(f'{storage_dir}\\\\RO_avg_metrics_plot.svg', format='svg')\n",
    "plt.show(RO_avg_metrics_plot)\n",
    "plt.close(RO_avg_metrics_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
