{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5e364c",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a6cbc7-e77d-47fa-b099-e0f911c53168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library to check function types of imported modules\n",
    "from typeguard import install_import_hook\n",
    "\n",
    "# custom functions for plotting, etc.\n",
    "with install_import_hook('custom_ml_plots'):\n",
    "    import custom_ml_plots as cmp\n",
    "with install_import_hook('custom_dataset_tools'):\n",
    "    import custom_dataset_tools as cdt\n",
    "with install_import_hook('basic_ml_operations'):\n",
    "    import basic_ml_operations as bmo\n",
    "with install_import_hook('ml_data_objects'):\n",
    "    import ml_data_objects as mdo\n",
    "\n",
    "# data import\n",
    "import pyreadr\n",
    "\n",
    "# data storage libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# k-fold cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# global parameters\n",
    "RANDOM_STATE = 42\n",
    "TEST_SET_PORTION = 0.15\n",
    "CV_SET_PORTION = 0.15\n",
    "TOP_LINE_THRESH = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3df08d",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06ae33-23b5-42a2-a4c1-e063428c27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "eyt1 = pyreadr.read_r('./data/eyt1.RData')\n",
    "\n",
    "# extract training example labels\n",
    "y = eyt1['Pheno_Disc_Env1']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[['GY']].set_index(y['GID'])\n",
    "\n",
    "# sort by index\n",
    "y = y.sort_index()\n",
    "\n",
    "# check missing values\n",
    "cdt.assert_no_bad_values(y)\n",
    "\n",
    "# each seed was planted in 4 different environments, but we don't care about environmental differences\n",
    "# so we take the average of every group of four rows to reduce the dataset to 1/4 its original size\n",
    "y = cdt.avg_rows(y, 4)\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a9b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature matrix\n",
    "X = eyt1['Geno_Env1']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c222e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale feature matrix\n",
    "X_scaler = StandardScaler()\n",
    "X_sc = pd.DataFrame(X_scaler.fit_transform(X), index=X.index, columns=X.columns)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_sc = pd.DataFrame(y_scaler.fit_transform(y), index=y.index, columns=y.columns)\n",
    "\n",
    "y_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a676e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_shaded_scatter_grids(y_preds_grid: np.ndarray, y_test_grid: np.ndarray, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, pearson_grid: np.ndarray, plot_title: str, i: int):\n",
    "    \"\"\"\n",
    "    Plot predictions vs actuals and colour by pearson coefficient and add best fit\n",
    "    Created: 2024/11/30\n",
    "    \"\"\"\n",
    "    # create plot of predictions vs actuals\n",
    "    fig, axs = cmp.create_scatter_grid(y_preds_grid, y_test_grid, axis1_params, axis2_params, f\"{plot_title} | Inner Fold {i}\")\n",
    "\n",
    "    # colour by pearson coefficient and add best fit and title\n",
    "    cmp.color_spectrum(fig, axs, pearson_grid, label=\"Pearson Coefficient\")\n",
    "    cmp.add_best_fit(axs)\n",
    "    plt.show(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3560fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_shaded_roc_grids(y_preds_grid: np.ndarray, y_test_grid: np.ndarray, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, f1_grid: np.ndarray, plot_title: str, i: int):\n",
    "    \"\"\"\n",
    "    Plot predictions vs actuals and colour by pearson coefficient and add best fit\n",
    "    Created: 2024/12/22\n",
    "    \"\"\"\n",
    "    # create plot of predictions vs actuals\n",
    "    fig, axs = cmp.create_roc_grid(y_preds_grid, y_test_grid, axis1_params, axis2_params, f\"{plot_title} | Inner Fold {i}\")\n",
    "\n",
    "    # colour by pearson coefficient and add best fit and title\n",
    "    cmp.color_spectrum(fig, axs, f1_grid, label=\"f1 Score\")\n",
    "    cmp.add_best_fit(axs)\n",
    "    plt.show(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713f8edf",
   "metadata": {},
   "source": [
    "# Model R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08cbb868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV_R(n_splits: int, X : pd.DataFrame, y : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback, kfold_random_state: int, plot_title: str = \"\", **kwargs):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    # arrays to store best parameters for each fold\n",
    "    best_params = pd.DataFrame(columns=['param1', 'param2'], index=range(n_splits))\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        \"\"\"\n",
    "        # For debugging\n",
    "        print(f'Fold {i}')\n",
    "        \"\"\"\n",
    "        \n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        \"\"\"\n",
    "        # For debugging\n",
    "        print('Training data:')\n",
    "        print(f'X: {X_train}')\n",
    "        print(f'y: {y_train}')\n",
    "        \"\"\"\n",
    "        \n",
    "        # train model grid\n",
    "        model_grid = bmo.train_model_grid(X_train, y_train, axis1_params, axis2_params, train_model_callback, **kwargs)\n",
    "\n",
    "        # use trained models to predict test set\n",
    "        y_preds_grid = bmo.grid_predict(X_test, model_grid)\n",
    "\n",
    "        # create grid of actuals to compare against predictions\n",
    "        y_test_grid = cdt.np_array_of_dfs(y_test, y_preds_grid.shape)\n",
    "\n",
    "        # evaluate predictions by comparing to actuals, calculating pearson coefficient\n",
    "        pearson_grid = bmo.calculate_pearson_coefficients(y_preds_grid, y_test_grid)\n",
    "\n",
    "        \"\"\"\n",
    "        # For debugging\n",
    "        print(f'Model grid:')\n",
    "        # print each model's tree count and depth\n",
    "        for row in range(model_grid.shape[0]):\n",
    "            for col in range(model_grid.shape[1]):\n",
    "                model = model_grid[row, col]\n",
    "                print(f'Model at row {row}, col {col}:')\n",
    "                # print based on whether model is svm or xgb\n",
    "                if hasattr(model, 'n_estimators'):\n",
    "                    print(f'n_estimators: {model.get_params()[\"n_estimators\"]}, max_depth: {model.get_params()[\"max_depth\"]}')\n",
    "                else:    \n",
    "                    # SVM, print gamma and C\n",
    "                    print(f'gamma: {model.get_params()[\"gamma\"]}, C: {model.get_params()[\"C\"]}')\n",
    "        print('Actuals:')\n",
    "        cdt.pretty_print_np_array_of_dfs(y_test_grid, rows_per_df=6)\n",
    "        print('Predictions:')\n",
    "        cdt.pretty_print_np_array_of_dfs(y_preds_grid, rows_per_df=6)\n",
    "        \"\"\"\n",
    "\n",
    "        # find index of best pearson coefficient in the 2d array of pearson coefficients\n",
    "        best_row, best_col = np.unravel_index(np.argmax(pearson_grid), pearson_grid.shape)\n",
    "        \n",
    "        # store best parameters for this fold\n",
    "        best_params.loc[i] = [axis1_params.values[best_row], axis2_params.values[best_col]]\n",
    "\n",
    "        plot_shaded_scatter_grids(y_preds_grid, y_test_grid, axis1_params, axis2_params, pearson_grid, plot_title, i)        \n",
    "\n",
    "    # calculate average best parameters over all folds\n",
    "    avg_best_param1 = best_params['param1'].mean()\n",
    "    avg_best_param2 = best_params['param2'].mean()\n",
    "\n",
    "    return avg_best_param1, avg_best_param2\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c111e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_CV_R(n_outer_splits: int, n_inner_splits: int, X : pd.DataFrame, y : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback, kfold_random_state: int, **kwargs) -> pd.DataFrame:\n",
    "    kfold = KFold(n_splits=n_outer_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    kfold_metrics = pd.DataFrame(columns=['Pearson', 'F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # find average best values using inner fold CV\n",
    "        best_param1, best_param2 = inner_CV_R(n_inner_splits, X_train, y_train, axis1_params, axis2_params, train_model_callback, kfold_random_state, plot_title=f\"Outer Fold {i}\", **kwargs)\n",
    "\n",
    "        # train model with all training data of outer fold using average best parameters\n",
    "        super_model = train_model_callback(X_train, np.ravel(y_train), **dict(zip([axis1_params.name, axis2_params.name], [best_param1, best_param2])), **kwargs)\n",
    "\n",
    "        # use trained model to predict test set\n",
    "        y_pred = pd.DataFrame(super_model.predict(X_test), index=y_test.index, columns=y_test.columns)\n",
    "\n",
    "        # calculate pearson coefficient\n",
    "        pearson, _ = pearsonr(np.ravel(y_pred), np.ravel(y_test))\n",
    "\n",
    "        # classify predictions and actuals as top or not top\n",
    "        y_pred_top = cdt.classify_top(y_pred, TOP_LINE_THRESH)\n",
    "        y_test_top = cdt.classify_top(y_test, TOP_LINE_THRESH)\n",
    "\n",
    "        # calculate classification metrics\n",
    "        classification_metrics = cdt.classification_metrics(y_pred_top, y_test_top)\n",
    "\n",
    "        # combine pearson and classification metrics into one dataframe side by side, then add them to kfold_metrics\n",
    "        pearson_df = pd.DataFrame([pearson], columns=['Pearson'])\n",
    "        metrics_row = pd.concat([pearson_df, classification_metrics], axis=1)\n",
    "        kfold_metrics = pd.concat([kfold_metrics, metrics_row], axis=0)        \n",
    "    \n",
    "    kfold_metrics.index = range(n_outer_splits)\n",
    "    return kfold_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40ce7c",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Real values\n",
    "x_params_SVM_R = mdo.AxisParams('gamma', bmo.power_list(2, -14, -6))\n",
    "y_params_SVM_R = mdo.AxisParams('C', bmo.power_list(2, -2, 6))\n",
    "metrics_SVM_R = outer_CV_R(10, 5, X_sc, y_sc, x_params_SVM_R, y_params_SVM_R, bmo.train_SVM_regressor, kfold_random_state=RANDOM_STATE, kernel='rbf')\n",
    "\"\"\"\n",
    "# Dummy values for quick training tests\n",
    "x_params_SVM_R = mdo.AxisParams('gamma', bmo.power_list(2, -8, -7))\n",
    "y_params_SVM_R = mdo.AxisParams('C', bmo.power_list(2, 0, 1))\n",
    "metrics_SVM_R = outer_CV_R(2, 2, X_sc, y_sc, x_params_SVM_R, y_params_SVM_R, bmo.train_SVM_regressor, kfold_random_state=RANDOM_STATE, kernel='rbf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec953e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display metrics\n",
    "display(metrics_SVM_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "display(metrics_SVM_R.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddd5e6",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3dd110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# proper values\n",
    "x_params_XGB_R = mdo.AxisParams('n_estimators', [13, 25, 50, 100, 200])\n",
    "y_params_XGB_R = mdo.AxisParams('max_depth', [1, 2, 3, 4, 6, 10, 16])\n",
    "# Perform grid search with XGBoost models\n",
    "metrics_XGB_R = outer_CV_R(10, 5, X_sc, y_sc, x_params_XGB_R, y_params_XGB_R, bmo.train_XGB_regressor, kfold_random_state=RANDOM_STATE, random_state=RANDOM_STATE, objective=\"reg:squarederror\", eval_metric=\"rmse\")\n",
    "\"\"\"\n",
    "# dummy values\n",
    "x_params_XGB_R = mdo.AxisParams('n_estimators', [1, 2])\n",
    "y_params_XGB_R = mdo.AxisParams('max_depth', [1, 2])\n",
    "metrics_XGB_R = outer_CV_R(2, 2, X_sc, y_sc, x_params_XGB_R, y_params_XGB_R, bmo.train_XGB_regressor, kfold_random_state=RANDOM_STATE, random_state=RANDOM_STATE, objective=\"reg:squarederror\", eval_metric=\"rmse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display metrics\n",
    "display(metrics_XGB_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f701d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "display(metrics_XGB_R.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b59b6d",
   "metadata": {},
   "source": [
    "# Model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8001b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV_B(n_splits: int, X : pd.DataFrame, y : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback, kfold_random_state: int, classification_col : int, plot_title: str = \"\", **kwargs):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    # arrays to store best parameters for each fold\n",
    "    best_params = pd.DataFrame(columns=['param1', 'param2'], index=range(n_splits))\n",
    "    best_thresholds = pd.DataFrame(columns=['threshold'], index=range(n_splits))\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # train model grid\n",
    "        model_grid = bmo.train_model_grid(X_train, y_train, axis1_params, axis2_params, train_model_callback, **kwargs)\n",
    "\n",
    "        # use trained models to predict test set classification\n",
    "        y_binary_preds_grid = bmo.grid_predict(X_test, model_grid)\n",
    "        \n",
    "        # also predict probabilities\n",
    "        y_proba_preds_grid = bmo.grid_predict_proba(X_test, model_grid, classification_col)\n",
    "\n",
    "        # create grid of actuals to compare against predictions\n",
    "        y_test_grid = cdt.np_array_of_dfs(y_test, y_proba_preds_grid.shape)\n",
    "\n",
    "        # evaluate predictions by comparing to actuals, calculating f1 scores\n",
    "        f1_grid = bmo.calculate_f1_scores(y_binary_preds_grid, y_test_grid)\n",
    "\n",
    "        # find index of best f1 score in the 2d array of f1 scores\n",
    "        best_row, best_col = np.unravel_index(np.argmax(f1_grid), f1_grid.shape)\n",
    "        \n",
    "        # store best parameters for this fold\n",
    "        best_params.loc[i] = [axis1_params.values[best_row], axis2_params.values[best_col]]\n",
    "\n",
    "        # find classification threshold that yields lowest squared difference between sensitivity and specificity using this optimal model\n",
    "        best_model_y_preds = y_proba_preds_grid[best_row, best_col]\n",
    "        best_thresholds.iloc[i, 0] = bmo.find_optimal_threshold(y_test, best_model_y_preds)\n",
    "\n",
    "        plot_shaded_roc_grids(y_proba_preds_grid, y_test_grid, axis1_params, axis2_params, f1_grid, plot_title, i)        \n",
    "\n",
    "    # calculate average best parameters over all folds\n",
    "    avg_best_param1 = best_params['param1'].mean()\n",
    "    avg_best_param2 = best_params['param2'].mean()\n",
    "\n",
    "    # calculate average best threshold over all folds\n",
    "    best_threshold = best_thresholds['threshold'].mean()\n",
    "\n",
    "    return avg_best_param1, avg_best_param2, best_threshold\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1fba289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_CV_B(n_outer_splits: int, n_inner_splits: int, X : pd.DataFrame, y : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback, kfold_random_state: int, classification_col : int, **kwargs) -> pd.DataFrame:\n",
    "    \n",
    "    kfold = KFold(n_splits=n_outer_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    kfold_metrics = pd.DataFrame(columns=['Pearson', 'F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # find average best values using inner fold CV\n",
    "        best_param1, best_param2, best_threshold = inner_CV_B(n_inner_splits, X_train, y_train, axis1_params, axis2_params, train_model_callback, kfold_random_state, classification_col, plot_title=f\"Outer Fold {i}\", **kwargs)\n",
    "\n",
    "        # train model with all training data of outer fold using average best parameters\n",
    "        super_model = train_model_callback(X_train, np.ravel(y_train), **dict(zip([axis1_params.name, axis2_params.name], [best_param1, best_param2])), **kwargs)\n",
    "\n",
    "        # use trained model to predict test set\n",
    "        y_pred = pd.DataFrame(super_model.predict_proba(X_test)[:, classification_col], index=y_test.index, columns=y_test.columns)\n",
    "\n",
    "        # calculate pearson coefficient\n",
    "        pearson, _ = pearsonr(np.ravel(y_pred), np.ravel(y_test))\n",
    "        pearson = float(pearson)  # Convert numpy.float32 to Python float\n",
    "\n",
    "        # classify predictions as top or not top\n",
    "        y_pred_top = cdt.classify_top(y_pred, best_threshold)\n",
    "\n",
    "        # calculate classification metrics\n",
    "        classification_metrics = cdt.classification_metrics(y_pred_top, y_test)\n",
    "\n",
    "        # combine pearson and classification metrics into one dataframe side by side, then add them to kfold_metrics\n",
    "        pearson_df = pd.DataFrame([pearson], columns=['Pearson'])\n",
    "        metrics_row = pd.concat([pearson_df, classification_metrics], axis=1)\n",
    "        kfold_metrics = pd.concat([kfold_metrics, metrics_row], axis=0)        \n",
    "    \n",
    "    kfold_metrics.index = range(n_outer_splits)\n",
    "    return kfold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace range of labels with binary variable representing whether the gene line is top or not\n",
    "y_sc_binary = cdt.classify_top(y_sc, TOP_LINE_THRESH) # .5, .6. .7\n",
    "display(y_sc_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7457c6",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy values for tests\n",
    "x_params_SVM_B = mdo.AxisParams('gamma', bmo.power_list(2, -10, -9))\n",
    "y_params_SVM_B = mdo.AxisParams('C', bmo.power_list(2, 0, 1))\n",
    "metrics_SVM_B = outer_CV_B(2, 2, X_sc, y_sc_binary, x_params_SVM_B, y_params_SVM_B, bmo.train_SVM_classifier, kfold_random_state=RANDOM_STATE, kernel='rbf', probability=True, classification_col=1)\n",
    "\n",
    "\"\"\"\n",
    "# Real values\n",
    "x_params_SVM_B = mdo.AxisParams('gamma', bmo.power_list(2, -14, -6))\n",
    "y_params_SVM_B = mdo.AxisParams('C', bmo.power_list(2, -2, 6))\n",
    "metrics_SVM_B = outer_CV_B(10, 5, X_sc, y_sc_binary, x_params_SVM_B, y_params_SVM_B, bmo.train_SVM_classifier, kfold_random_state=RANDOM_STATE, kernel='rbf', probability=True, classification_col=1)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7219ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display metrics\n",
    "display(metrics_SVM_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc3995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "display(metrics_SVM_B.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf6cd8",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aeca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x_params_XGB_B = mdo.AxisParams('n_estimators', [13, 25, 50, 100, 200])\n",
    "y_params_XGB_B = mdo.AxisParams('max_depth', [1, 2, 3, 4, 6, 10, 16])\n",
    "metrics_XGB_B = outer_CV_B(10, 5, X_sc, y_sc_binary, x_params_XGB_B, y_params_XGB_B, bmo.train_XGB_classifier, kfold_random_state=RANDOM_STATE, random_state=RANDOM_STATE, classification_col=1, objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# dummy values for quick tests\n",
    "x_params_XGB_B = mdo.AxisParams('n_estimators', [1, 2])\n",
    "y_params_XGB_B = mdo.AxisParams('max_depth', [1, 2])\n",
    "\n",
    "metrics_XGB_B = outer_CV_B(2, 2, X_sc, y_sc_binary, x_params_XGB_B, y_params_XGB_B, bmo.train_XGB_classifier, kfold_random_state=RANDOM_STATE, random_state=RANDOM_STATE, classification_col=1, objective=\"binary:logistic\", eval_metric=\"logloss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display metrics\n",
    "display(metrics_XGB_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "display(metrics_XGB_B.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de75da",
   "metadata": {},
   "source": [
    "# Model RO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82681b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV_RO(n_splits: int, X : pd.DataFrame, y : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback, kfold_random_state: int, plot_title: str = \"\", **kwargs):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    # arrays to store best parameters for each fold\n",
    "    best_params = pd.DataFrame(columns=['param1', 'param2'], index=range(n_splits))\n",
    "    best_thresholds = pd.DataFrame(columns=['threshold'], index=range(n_splits))\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # train model grid\n",
    "        model_grid = bmo.train_model_grid(X_train, y_train, axis1_params, axis2_params, train_model_callback, **kwargs)\n",
    "\n",
    "        # use trained models to predict test set\n",
    "        y_preds_grid = bmo.grid_predict(X_test, model_grid)\n",
    "\n",
    "        # create grid of actuals to compare against predictions\n",
    "        y_test_grid = cdt.np_array_of_dfs(y_test, y_preds_grid.shape)\n",
    "\n",
    "        # evaluate predictions by comparing to actuals, calculating pearson coefficient\n",
    "        pearson_grid = bmo.calculate_pearson_coefficients(y_preds_grid, y_test_grid)\n",
    "\n",
    "        # find index of best pearson coefficient in the 2d array of pearson coefficients\n",
    "        best_row, best_col = np.unravel_index(np.argmax(pearson_grid), pearson_grid.shape)\n",
    "        \n",
    "        # store best parameters for this fold\n",
    "        best_params.loc[i] = [axis1_params.values[best_row], axis2_params.values[best_col]]\n",
    "\n",
    "        # find classification threshold that yields lowest squared difference between sensitivity and specificity using this optimal model\n",
    "        best_model_y_preds = y_preds_grid[best_row, best_col]\n",
    "        best_thresholds.iloc[i, 0] = bmo.find_optimal_threshold(y_test, best_model_y_preds)\n",
    "\n",
    "        plot_shaded_scatter_grids(y_preds_grid, y_test_grid, axis1_params, axis2_params, pearson_grid, plot_title, i)        \n",
    "\n",
    "    # calculate average best parameters over all folds\n",
    "    avg_best_param1 = best_params['param1'].mean()\n",
    "    avg_best_param2 = best_params['param2'].mean()\n",
    "\n",
    "    # calculate average best threshold over all folds\n",
    "    best_threshold = best_thresholds['threshold'].mean()\n",
    "\n",
    "    return avg_best_param1, avg_best_param2, best_threshold\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02c7b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_CV_RO(n_outer_splits: int, n_inner_splits: int, X : pd.DataFrame, y : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback, kfold_random_state: int, **kwargs) -> pd.DataFrame:\n",
    "    \n",
    "    kfold = KFold(n_splits=n_outer_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    kfold_metrics = pd.DataFrame(columns=['Pearson', 'F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # find average best values using inner fold CV\n",
    "        best_param1, best_param2, best_threshold = inner_CV_RO(n_inner_splits, X_train, y_train, axis1_params, axis2_params, train_model_callback, kfold_random_state, plot_title=f\"Outer Fold {i}\", **kwargs)\n",
    "\n",
    "        # train model with all training data of outer fold using average best parameters\n",
    "        super_model = train_model_callback(X_train, np.ravel(y_train), **dict(zip([axis1_params.name, axis2_params.name], [best_param1, best_param2])), **kwargs)\n",
    "\n",
    "        # use trained model to predict test set\n",
    "        y_pred = pd.DataFrame(super_model.predict(X_test), index=y_test.index, columns=y_test.columns)\n",
    "\n",
    "        # calculate pearson coefficient\n",
    "        pearson, _ = pearsonr(np.ravel(y_pred), np.ravel(y_test))\n",
    "\n",
    "        # classify predictions and actuals as top or not top\n",
    "        y_pred_top = cdt.classify_top(y_pred, best_threshold)\n",
    "        y_test_top = cdt.classify_top(y_test, best_threshold)\n",
    "\n",
    "        # calculate classification metrics\n",
    "        classification_metrics = cdt.classification_metrics(y_pred_top, y_test_top)\n",
    "\n",
    "        # combine pearson and classification metrics into one dataframe side by side, then add them to kfold_metrics\n",
    "        pearson_df = pd.DataFrame([pearson], columns=['Pearson'])\n",
    "        metrics_row = pd.concat([pearson_df, classification_metrics], axis=1)\n",
    "        kfold_metrics = pd.concat([kfold_metrics, metrics_row], axis=0)        \n",
    "    \n",
    "    kfold_metrics.index = range(n_outer_splits)\n",
    "    return kfold_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac635306",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e7c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_params_SVM_RO = mdo.AxisParams('gamma', bmo.power_list(2, -14, -6))\n",
    "y_params_SVM_RO = mdo.AxisParams('C', bmo.power_list(2, -2, 6))\n",
    "\n",
    "metrics_SVM_RO = outer_CV_RO(10, 5, X_sc, y_sc, x_params_SVM_RO, y_params_SVM_RO, bmo.train_SVM_regressor, kfold_random_state=RANDOM_STATE, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975314ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display metrics\n",
    "display(metrics_SVM_RO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb307e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "display(metrics_SVM_RO.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2313db",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_params_XGB_RO = mdo.AxisParams('n_estimators', [13, 25, 50, 100, 200])\n",
    "y_params_XGB_RO = mdo.AxisParams('max_depth', [1, 2, 3, 4, 6, 10, 16])\n",
    "metrics_XGB_RO = outer_CV_RO(10, 5, X_sc, y_sc, x_params_XGB_RO, y_params_XGB_RO, bmo.train_XGB_regressor, kfold_random_state=RANDOM_STATE, random_state=RANDOM_STATE, objective=\"reg:squarederror\", eval_metric=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37545449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display metrics\n",
    "display(metrics_XGB_RO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521925c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "display(metrics_XGB_RO.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_research_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
