{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5e364c",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c054d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dill in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (0.3.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadr in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pyreadr) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas>=1.2.0->pyreadr) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas>=1.2.0->pyreadr) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas>=1.2.0->pyreadr) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas>=1.2.0->pyreadr) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadr) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from scikit-learn) (2.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from xgboost) (2.2.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from xgboost) (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typeguard in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from typeguard) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyQt6 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (6.8.0)\n",
      "Requirement already satisfied: PyQt6-sip<14,>=13.8 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from PyQt6) (13.9.1)\n",
      "Requirement already satisfied: PyQt6-Qt6<6.9.0,>=6.8.0 in c:\\users\\kevin\\dev\\ml_research\\venv\\lib\\site-packages (from PyQt6) (6.8.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install dill\n",
    "%pip install pyreadr\n",
    "%pip install scikit-learn\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install xgboost\n",
    "%pip install -U matplotlib\n",
    "%pip install typeguard\n",
    "%pip install PyQt6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a6cbc7-e77d-47fa-b099-e0f911c53168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library to check function types of imported modules\n",
    "from typeguard import install_import_hook\n",
    "\n",
    "# custom functions for plotting, etc.\n",
    "with install_import_hook('custom_ml_plots'):\n",
    "    import custom_ml_plots as cmp\n",
    "with install_import_hook('custom_dataset_tools'):\n",
    "    import custom_dataset_tools as cdt\n",
    "with install_import_hook('basic_ml_operations'):\n",
    "    import basic_ml_operations as bmo\n",
    "with install_import_hook('ml_data_objects'):\n",
    "    import ml_data_objects as mdo\n",
    "\n",
    "# data import and export\n",
    "import pyreadr\n",
    "import dill\n",
    "\n",
    "# data management libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# plots\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# misc\n",
    "import os\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# k-fold cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# global parameters\n",
    "RANDOM_STATE = 42\n",
    "TOP_LINE_THRESH = 0.8 # values to test: 0.5, 0.6, 0.7, 0.8, 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3df08d",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e06ae33-23b5-42a2-a4c1-e063428c27b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID</th>\n",
       "      <th>Env</th>\n",
       "      <th>DTHD</th>\n",
       "      <th>DTMT</th>\n",
       "      <th>GY</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GID6569128</td>\n",
       "      <td>Bed5IR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.119272</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GID6688880</td>\n",
       "      <td>Bed5IR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.855879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GID6688916</td>\n",
       "      <td>Bed5IR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.434748</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GID6688933</td>\n",
       "      <td>Bed5IR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.350670</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GID6688934</td>\n",
       "      <td>Bed5IR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.523289</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GID     Env  DTHD  DTMT        GY  Height\n",
       "0  GID6569128  Bed5IR   1.0   1.0  6.119272     0.0\n",
       "1  GID6688880  Bed5IR   2.0   2.0  5.855879     0.0\n",
       "2  GID6688916  Bed5IR   2.0   2.0  6.434748     0.0\n",
       "3  GID6688933  Bed5IR   2.0   2.0  6.350670     0.0\n",
       "4  GID6688934  Bed5IR   1.0   2.0  6.523289     0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "eyt1 = pyreadr.read_r('./data/eyt1.RData')\n",
    "\n",
    "# extract training example labels\n",
    "y = eyt1['Pheno_Disc_Env1']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd36fe65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GID6569128</th>\n",
       "      <td>5.160521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688880</th>\n",
       "      <td>5.988963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688916</th>\n",
       "      <td>5.781745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688933</th>\n",
       "      <td>5.434369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688934</th>\n",
       "      <td>5.551610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GY\n",
       "GID                 \n",
       "GID6569128  5.160521\n",
       "GID6688880  5.988963\n",
       "GID6688916  5.781745\n",
       "GID6688933  5.434369\n",
       "GID6688934  5.551610"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y[['GY']].set_index(y['GID'])\n",
    "\n",
    "# sort by index\n",
    "y = y.sort_index()\n",
    "\n",
    "# check missing values\n",
    "cdt.assert_no_bad_values(y)\n",
    "\n",
    "# each seed was planted in 4 different environments, but we don't care about environmental differences\n",
    "# so we take the average of every group of four rows to reduce the dataset to 1/4 its original size\n",
    "y = cdt.avg_rows(y, 4)\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c6a9b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID6569128</th>\n",
       "      <th>GID6688880</th>\n",
       "      <th>GID6688916</th>\n",
       "      <th>GID6688933</th>\n",
       "      <th>GID6688934</th>\n",
       "      <th>GID6688949</th>\n",
       "      <th>GID6689407</th>\n",
       "      <th>GID6689482</th>\n",
       "      <th>GID6689550</th>\n",
       "      <th>GID6738288</th>\n",
       "      <th>...</th>\n",
       "      <th>GID6939899</th>\n",
       "      <th>GID6939900</th>\n",
       "      <th>GID6939902</th>\n",
       "      <th>GID6939903</th>\n",
       "      <th>GID6939904</th>\n",
       "      <th>GID6939917</th>\n",
       "      <th>GID6939919</th>\n",
       "      <th>GID6939938</th>\n",
       "      <th>GID6939941</th>\n",
       "      <th>GID6939945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GID6569128</th>\n",
       "      <td>0.788801</td>\n",
       "      <td>-0.006443</td>\n",
       "      <td>0.025987</td>\n",
       "      <td>-0.138795</td>\n",
       "      <td>-0.157880</td>\n",
       "      <td>0.096213</td>\n",
       "      <td>-0.110899</td>\n",
       "      <td>0.013069</td>\n",
       "      <td>-0.040445</td>\n",
       "      <td>0.007931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125612</td>\n",
       "      <td>0.133808</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>0.127674</td>\n",
       "      <td>0.130468</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.091188</td>\n",
       "      <td>0.074009</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.199459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688880</th>\n",
       "      <td>-0.006443</td>\n",
       "      <td>0.980542</td>\n",
       "      <td>0.064585</td>\n",
       "      <td>-0.168773</td>\n",
       "      <td>-0.081006</td>\n",
       "      <td>0.078890</td>\n",
       "      <td>-0.201346</td>\n",
       "      <td>0.124671</td>\n",
       "      <td>0.253505</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072171</td>\n",
       "      <td>0.061650</td>\n",
       "      <td>0.057898</td>\n",
       "      <td>0.079085</td>\n",
       "      <td>0.061086</td>\n",
       "      <td>0.104630</td>\n",
       "      <td>0.113878</td>\n",
       "      <td>0.108757</td>\n",
       "      <td>0.154718</td>\n",
       "      <td>0.004447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688916</th>\n",
       "      <td>0.025987</td>\n",
       "      <td>0.064585</td>\n",
       "      <td>1.170073</td>\n",
       "      <td>-0.021636</td>\n",
       "      <td>-0.031717</td>\n",
       "      <td>0.101532</td>\n",
       "      <td>-0.196780</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>-0.013459</td>\n",
       "      <td>0.126464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428609</td>\n",
       "      <td>0.423184</td>\n",
       "      <td>0.427788</td>\n",
       "      <td>0.408326</td>\n",
       "      <td>0.426844</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.209395</td>\n",
       "      <td>0.240468</td>\n",
       "      <td>0.255337</td>\n",
       "      <td>0.163524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688933</th>\n",
       "      <td>-0.138795</td>\n",
       "      <td>-0.168773</td>\n",
       "      <td>-0.021636</td>\n",
       "      <td>0.879004</td>\n",
       "      <td>0.443678</td>\n",
       "      <td>-0.080560</td>\n",
       "      <td>0.402479</td>\n",
       "      <td>-0.218803</td>\n",
       "      <td>-0.102718</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079312</td>\n",
       "      <td>-0.087824</td>\n",
       "      <td>-0.089912</td>\n",
       "      <td>-0.067028</td>\n",
       "      <td>-0.084206</td>\n",
       "      <td>-0.140529</td>\n",
       "      <td>-0.088961</td>\n",
       "      <td>-0.096740</td>\n",
       "      <td>-0.159136</td>\n",
       "      <td>-0.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688934</th>\n",
       "      <td>-0.157880</td>\n",
       "      <td>-0.081006</td>\n",
       "      <td>-0.031717</td>\n",
       "      <td>0.443678</td>\n",
       "      <td>0.996666</td>\n",
       "      <td>-0.140766</td>\n",
       "      <td>0.395843</td>\n",
       "      <td>-0.310471</td>\n",
       "      <td>-0.138902</td>\n",
       "      <td>0.088169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016690</td>\n",
       "      <td>-0.017375</td>\n",
       "      <td>-0.026372</td>\n",
       "      <td>-0.014478</td>\n",
       "      <td>-0.016350</td>\n",
       "      <td>-0.098509</td>\n",
       "      <td>-0.052304</td>\n",
       "      <td>-0.012778</td>\n",
       "      <td>-0.100318</td>\n",
       "      <td>-0.154557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            GID6569128  GID6688880  GID6688916  GID6688933  GID6688934  \\\n",
       "GID6569128    0.788801   -0.006443    0.025987   -0.138795   -0.157880   \n",
       "GID6688880   -0.006443    0.980542    0.064585   -0.168773   -0.081006   \n",
       "GID6688916    0.025987    0.064585    1.170073   -0.021636   -0.031717   \n",
       "GID6688933   -0.138795   -0.168773   -0.021636    0.879004    0.443678   \n",
       "GID6688934   -0.157880   -0.081006   -0.031717    0.443678    0.996666   \n",
       "\n",
       "            GID6688949  GID6689407  GID6689482  GID6689550  GID6738288  ...  \\\n",
       "GID6569128    0.096213   -0.110899    0.013069   -0.040445    0.007931  ...   \n",
       "GID6688880    0.078890   -0.201346    0.124671    0.253505    0.013636  ...   \n",
       "GID6688916    0.101532   -0.196780    0.041900   -0.013459    0.126464  ...   \n",
       "GID6688933   -0.080560    0.402479   -0.218803   -0.102718   -0.002303  ...   \n",
       "GID6688934   -0.140766    0.395843   -0.310471   -0.138902    0.088169  ...   \n",
       "\n",
       "            GID6939899  GID6939900  GID6939902  GID6939903  GID6939904  \\\n",
       "GID6569128    0.125612    0.133808    0.137456    0.127674    0.130468   \n",
       "GID6688880    0.072171    0.061650    0.057898    0.079085    0.061086   \n",
       "GID6688916    0.428609    0.423184    0.427788    0.408326    0.426844   \n",
       "GID6688933   -0.079312   -0.087824   -0.089912   -0.067028   -0.084206   \n",
       "GID6688934   -0.016690   -0.017375   -0.026372   -0.014478   -0.016350   \n",
       "\n",
       "            GID6939917  GID6939919  GID6939938  GID6939941  GID6939945  \n",
       "GID6569128    0.004096    0.091188    0.074009    0.032992    0.199459  \n",
       "GID6688880    0.104630    0.113878    0.108757    0.154718    0.004447  \n",
       "GID6688916    0.006038    0.209395    0.240468    0.255337    0.163524  \n",
       "GID6688933   -0.140529   -0.088961   -0.096740   -0.159136   -0.108800  \n",
       "GID6688934   -0.098509   -0.052304   -0.012778   -0.100318   -0.154557  \n",
       "\n",
       "[5 rows x 766 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract feature matrix\n",
    "X = eyt1['Geno_Env1']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1900d1c",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a24d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_numbered_subdir():\n",
    "    \"\"\"\n",
    "    Creates a new subdirectory within the 'saved_data_and_plots' directory, \n",
    "    with a name that is the next available number in sequence, formatted as a \n",
    "    three-digit number (e.g., '001', '002', etc.).\n",
    "    Created: 2024/01/01\n",
    "    Returns:\n",
    "        str: The path to the newly created numbered subdirectory.\n",
    "    \"\"\"\n",
    "    # Create parent directory if it doesn't exist\n",
    "    parent_dir = \"saved_data_and_plots\"\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    \n",
    "    # Find next available number\n",
    "    existing_dirs = [d for d in os.listdir(parent_dir) \n",
    "                    if os.path.isdir(os.path.join(parent_dir, d))]\n",
    "    existing_nums = [int(d) for d in existing_dirs if d.isdigit()]\n",
    "    next_num = max(existing_nums + [-1]) + 1\n",
    "    \n",
    "    # Create new numbered directory\n",
    "    new_dir = os.path.join(parent_dir, f\"{next_num:03d}\")\n",
    "    os.makedirs(new_dir)\n",
    "    return new_dir\n",
    "\n",
    "storage_dir = create_numbered_subdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c222e0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GID6569128</th>\n",
       "      <td>-1.069311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688880</th>\n",
       "      <td>1.412830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688916</th>\n",
       "      <td>0.791971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688933</th>\n",
       "      <td>-0.248819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GID6688934</th>\n",
       "      <td>0.102451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GY\n",
       "GID                 \n",
       "GID6569128 -1.069311\n",
       "GID6688880  1.412830\n",
       "GID6688916  0.791971\n",
       "GID6688933 -0.248819\n",
       "GID6688934  0.102451"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale feature matrix\n",
    "X_scaler = StandardScaler()\n",
    "X_sc = pd.DataFrame(X_scaler.fit_transform(X), index=X.index, columns=X.columns)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_sc = pd.DataFrame(y_scaler.fit_transform(y), index=y.index, columns=y.columns)\n",
    "\n",
    "y_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a676e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_shaded_scatter_grids(y_preds_grid: np.ndarray, y_test_grid: np.ndarray, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, pearson_grid: np.ndarray, plot_title: str, i: int) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot predictions vs actuals and colour by pearson coefficient and add best fit\n",
    "    Created: 2024/11/30\n",
    "    \"\"\"\n",
    "    # create plot of predictions vs actuals\n",
    "    fig, axs = cmp.create_scatter_grid(y_preds_grid, y_test_grid, axis1_params, axis2_params, f\"{plot_title} | Inner Fold {i}\")\n",
    "\n",
    "    # colour by pearson coefficient and add best fit and title\n",
    "    cmp.color_spectrum(fig, axs, pearson_grid, label=\"Pearson Coefficient\")\n",
    "    cmp.add_best_fit(axs)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3560fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_shaded_roc_grids(y_preds_grid: np.ndarray, y_test_grid: np.ndarray, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, f1_grid: np.ndarray, plot_title: str, i: int) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot predictions vs actuals and colour by pearson coefficient and add best fit\n",
    "    Created: 2024/12/22\n",
    "    \"\"\"\n",
    "    # create plot of predictions vs actuals\n",
    "    fig, axs = cmp.create_roc_grid(y_preds_grid, y_test_grid, axis1_params, axis2_params, f\"{plot_title} | Inner Fold {i}\")\n",
    "\n",
    "    # colour by pearson coefficient and add best fit and title\n",
    "    cmp.color_spectrum(fig, axs, f1_grid, label=\"f1 Score\")\n",
    "    cmp.add_best_fit(axs)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e9f897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_average_metrics = pd.DataFrame(columns=['F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "R_average_metrics = pd.DataFrame(columns=['Pearson', 'F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "RO_average_metrics = pd.DataFrame(columns=['Pearson', 'F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "\n",
    "# Add linear regression model metrics from research paper\n",
    "B_average_metrics.loc['GBLUP'] =  [0.411, 0.696, 0.577, 0.180]\n",
    "R_average_metrics.loc['GBLUP'] =  [None, 0.215, 0.128, 0.987, 0.164]\n",
    "RO_average_metrics.loc['GBLUP'] = [None, 0.487, 0.711, 0.699, 0.304]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713f8edf",
   "metadata": {},
   "source": [
    "# Model R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08cbb868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV_R(n_splits: int, X : pd.DataFrame, y : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback, kfold_random_state: int, plot_title: str = \"\", **kwargs):\n",
    "    \"\"\"Perform inner cross-validation with grid search to find the best model parameters.\n",
    "    Created: 2024/12/03\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_splits : int\n",
    "        Number of splits for KFold cross-validation.\n",
    "    X : pd.DataFrame\n",
    "        Feature data.\n",
    "    y : pd.DataFrame\n",
    "        Target data.\n",
    "    axis1_params : mdo.AxisParams\n",
    "        Parameter grid for the first axis.\n",
    "    axis2_params : mdo.AxisParams\n",
    "        Parameter grid for the second axis.\n",
    "    train_model_callback : callable\n",
    "        Callback function to train the model.\n",
    "    kfold_random_state : int\n",
    "        Random state for KFold shuffling.\n",
    "    plot_title : str, optional\n",
    "        Title for the plot (default is \"\").\n",
    "    **kwargs : dict\n",
    "        Additional keyword arguments for the model training.\n",
    "    Returns:\n",
    "    --------\n",
    "    avg_best_param1 : float\n",
    "        Average best parameter value for the first axis over all folds.\n",
    "    avg_best_param2 : float\n",
    "        Average best parameter value for the second axis over all folds.\"\"\"\n",
    "\n",
    "    # Create KFold object for inner-fold cross-validation\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    # Store best parameters (C, gamma) for each fold\n",
    "    best_params = pd.DataFrame(columns=['param1', 'param2'], index=range(n_splits))\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        \n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train numpy 2D array of models with every combination of parameters\n",
    "        model_grid = bmo.train_model_grid(X_train, y_train, axis1_params, axis2_params, train_model_callback, **kwargs)\n",
    "\n",
    "        # Use trained models to predict test set labels, and store in 2D array with each cell corresponding to a model with specific combination of parameters\n",
    "        y_preds_grid = bmo.grid_predict(X_test, model_grid)\n",
    "\n",
    "        # Create 2D array of identical dataframes containing actual labels to compare against predictions\n",
    "        y_test_grid = cdt.np_array_of_dfs(y_test, y_preds_grid.shape)\n",
    "\n",
    "        # Evaluate predictions by comparing to actuals, calculating 2D array of pearson coefficients\n",
    "        pearson_grid = bmo.calculate_pearson_coefficients(y_preds_grid, y_test_grid)\n",
    "\n",
    "        # Find index of best pearson coefficient in the 2d array of pearson coefficients\n",
    "        best_row, best_col = np.unravel_index(np.argmax(pearson_grid), pearson_grid.shape)\n",
    "        \n",
    "        # Store hyperparameters of most accurate model for this inner fold\n",
    "        best_params.loc[i] = [axis1_params.values[best_row], axis2_params.values[best_col]]\n",
    "\n",
    "        # Create grid of scatter plots with predictions vs actuals, coloured by pearson coefficient for each model\n",
    "        scatter_grid = plot_shaded_scatter_grids(y_preds_grid, y_test_grid, axis1_params, axis2_params, pearson_grid, plot_title, i)        \n",
    "        plt.savefig(f'{storage_dir}\\\\model_R, {train_model_callback.__name__}, ({plot_title}, Inner Fold {i}).svg', format=\"svg\")\n",
    "        plt.show(scatter_grid)\n",
    "        plt.close(scatter_grid)\n",
    "\n",
    "    # calculate average best parameters over all inner folds to return to outer CV\n",
    "    avg_best_param1 = best_params['param1'].mean()\n",
    "    avg_best_param2 = best_params['param2'].mean()\n",
    "\n",
    "    return avg_best_param1, avg_best_param2\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c111e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_CV_R(n_outer_splits: int, n_inner_splits: int, X : pd.DataFrame, y : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback : callable, kfold_random_state: int, top_line_thresh : float, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform nested cross-validation with an outer and inner loop to evaluate model performance.\n",
    "    Created: 2024/12/03\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_outer_splits : int\n",
    "        Number of splits for the outer cross-validation loop.\n",
    "    n_inner_splits : int\n",
    "        Number of splits for the inner cross-validation loop.\n",
    "    X : pd.DataFrame\n",
    "        Feature data.\n",
    "    y : pd.DataFrame\n",
    "        Target data.\n",
    "    axis1_params : mdo.AxisParams\n",
    "        Object containing parameter list for the first hyperparameter axis (horizontal).\n",
    "    axis2_params : mdo.AxisParams\n",
    "        Object containing parameter list for the first hyperparameter axis (vertical).\n",
    "    train_model_callback : callable\n",
    "        Function to train the model. Should accept X, y, and hyperparameters as arguments.\n",
    "    kfold_random_state : int\n",
    "        Random state for reproducibility in KFold splitting.\n",
    "    top_line_thresh : float\n",
    "        Threshold to classify predictions as top or not top.\n",
    "    **kwargs\n",
    "        Additional arguments to pass to the train_model_callback function.\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing 5 metrics (Pearson, F1 Score, Sensitivity, Specificity, Kappa) for each outer fold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create KFold object for outer loop to split data into train and test sets\n",
    "    kfold = KFold(n_splits=n_outer_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    # Store metrics for each fold\n",
    "    kfold_metrics = pd.DataFrame(columns=['Pearson', 'F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Find mean best hyperparameter values based on prediction accuracy using inner-fold CV\n",
    "        best_param1, best_param2 = inner_CV_R(n_inner_splits, X_train, y_train, axis1_params, axis2_params, train_model_callback, kfold_random_state, plot_title=f\"Outer Fold {i}\", **kwargs)\n",
    "\n",
    "        # Train model with all training and CV data of outer fold using mean best hyperparameters\n",
    "        super_model = train_model_callback(X_train, np.ravel(y_train), **dict(zip([axis1_params.name, axis2_params.name], [best_param1, best_param2])), **kwargs)\n",
    "\n",
    "        # Use trained \"super-model\" to predict test set\n",
    "        y_pred = pd.DataFrame(super_model.predict(X_test), index=y_test.index, columns=y_test.columns)\n",
    "\n",
    "        # Calculate pearson coefficient of continuous predictions\n",
    "        pearson, _ = pearsonr(np.ravel(y_pred), np.ravel(y_test))\n",
    "\n",
    "        # Classify predictions and actuals of super_model as top or not top (boolean)\n",
    "        y_pred_top = bmo.classify_top(y_pred, top_line_thresh)\n",
    "        y_test_top = bmo.classify_top(y_test, top_line_thresh)\n",
    "\n",
    "        # Calculate classification metrics and add new row to kfold_metrics\n",
    "        classification_metrics = cdt.classification_metrics(y_pred_top, y_test_top)\n",
    "        pearson_df = pd.DataFrame([pearson], columns=['Pearson'])\n",
    "        metrics_row = pd.concat([pearson_df, classification_metrics], axis=1)\n",
    "        kfold_metrics = pd.concat([kfold_metrics, metrics_row], axis=0)\n",
    "\n",
    "    # Label each row of kfold_metrics with the fold number \n",
    "    kfold_metrics.index = range(n_outer_splits)\n",
    "    \n",
    "    return kfold_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40ce7c",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Real values \n",
    "x_params_SVM_R = mdo.AxisParams('gamma', bmo.power_list(2, -14, -6))\n",
    "y_params_SVM_R = mdo.AxisParams('C', bmo.power_list(2, -2, 6))\n",
    "metrics_SVM_R = outer_CV_R(10, 5, X_sc, y_sc, x_params_SVM_R, y_params_SVM_R, bmo.train_SVM_regressor, kfold_random_state=RANDOM_STATE, kernel='rbf', top_line_thresh=TOP_LINE_THRESH)\n",
    "\"\"\"\n",
    "# Dummy values for quick debugging tests\n",
    "x_params_SVM_R = mdo.AxisParams('gamma', bmo.power_list(2, -8, -7))\n",
    "y_params_SVM_R = mdo.AxisParams('C', bmo.power_list(2, 0, 1))\n",
    "metrics_SVM_R = outer_CV_R(2, 2, X_sc, y_sc, x_params_SVM_R, y_params_SVM_R, bmo.train_SVM_regressor, kfold_random_state=RANDOM_STATE, kernel='rbf', top_line_thresh=TOP_LINE_THRESH)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec953e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification metrics for best model from each outer fold\n",
    "display(metrics_SVM_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save average of each metric\n",
    "metrics_SVM_R_mean = metrics_SVM_R.mean().to_frame().T\n",
    "R_average_metrics.loc['SVM'] = metrics_SVM_R_mean.iloc[0]\n",
    "display(metrics_SVM_R_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddd5e6",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3dd110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test values\n",
    "x_params_XGB_R = mdo.AxisParams('n_estimators', [13, 25, 50, 100, 200])\n",
    "y_params_XGB_R = mdo.AxisParams('max_depth', [1, 2, 3, 4, 6, 10, 16])\n",
    "metrics_XGB_R = outer_CV_R(10, 5, X_sc, y_sc, x_params_XGB_R, y_params_XGB_R, bmo.train_XGB_regressor, kfold_random_state=RANDOM_STATE, random_state=RANDOM_STATE, top_line_thresh=TOP_LINE_THRESH, objective=\"reg:squarederror\", eval_metric=\"rmse\")\n",
    "\n",
    "\"\"\"\n",
    "# Dummy values for quick debugging tests\n",
    "x_params_XGB_R = mdo.AxisParams('n_estimators', [1, 2])\n",
    "y_params_XGB_R = mdo.AxisParams('max_depth', [1, 2])\n",
    "metrics_XGB_R = outer_CV_R(2, 2, X_sc, y_sc, x_params_XGB_R, y_params_XGB_R, bmo.train_XGB_regressor, kfold_random_state=RANDOM_STATE, random_state=RANDOM_STATE, objective=\"reg:squarederror\", eval_metric=\"rmse\", top_line_thresh=TOP_LINE_THRESH)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification metrics for best model from each outer fold\n",
    "display(metrics_XGB_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f701d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric and store results for analysis\n",
    "metrics_XGB_R_mean = metrics_XGB_R.mean().to_frame().T\n",
    "display(metrics_XGB_R_mean)\n",
    "R_average_metrics.loc['XGB'] = metrics_XGB_R_mean.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d850952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save serialized session variables and models to disk for later use\n",
    "dill.dump_session(f'{storage_dir}\\\\project_ipynb_env_R.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b59b6d",
   "metadata": {},
   "source": [
    "# Model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8001b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV_B(n_splits: int, X : pd.DataFrame, y : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback, kfold_random_state: int, classification_col : int, top_line_thresh : float, plot_title: str = \"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Perform inner cross-validation to tune model hyperparameters and find the optimal classification threshold.\n",
    "    Created: 2024/12/04\n",
    "    Parameters:\n",
    "    n_splits (int): Number of splits for KFold cross-validation.\n",
    "    X (pd.DataFrame): Feature data.\n",
    "    y (pd.DataFrame): Target data.\n",
    "    axis1_params (mdo.AxisParams): Object containing hyperparameter values for the first (horizontal) axis.\n",
    "    axis2_params (mdo.AxisParams): Object containing hyperparameter values for the second (vertical) axis.\n",
    "    train_model_callback (function): Callback function to train the model.\n",
    "    kfold_random_state (int): Random state for KFold shuffling.\n",
    "    classification_col (int): Column index to pull classification proabibilities from - 0 for not top, 1 for top.\n",
    "    top_line_thresh (float): Threshold to classify predictions as top or not top.\n",
    "    plot_title (str, optional): Title for the ROC plot. Defaults to \"\".\n",
    "    **kwargs: Additional arguments for the train_model_callback function.\n",
    "    Returns:\n",
    "    tuple: Average best parameters (param1, param2) and the best classification threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    # Arrays to store parameters and binary classification thresholds of most accurate model for each inner fold\n",
    "    best_params = pd.DataFrame(columns=['param1', 'param2'], index=range(n_splits))\n",
    "    best_thresholds = pd.DataFrame(columns=['threshold'], index=range(n_splits))\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train numpy 2D array of models with every combination of parameters\n",
    "        model_grid = bmo.train_model_grid(X_train, y_train, axis1_params, axis2_params, train_model_callback, **kwargs)\n",
    "        \n",
    "        # Use trained models to predict test set probabilities, and store in 2D array with each cell corresponding to a model with specific combination of parameters\n",
    "        y_proba_preds_grid = bmo.grid_predict_proba(X_test, model_grid, classification_col)\n",
    "\n",
    "        # Use probabilities to classify predictions as top or not top. This isn't the final classification, \n",
    "        # but a step towards finding the optimal threshold, so we just use the same threshold as the original\n",
    "        # y binary classification.\n",
    "        y_binary_preds_grid = bmo.grid_classify_top(y_proba_preds_grid, top_line_thresh)\n",
    "\n",
    "        # Create 2D array of identical dataframes containing actual labels to compare against predictions\n",
    "        y_test_grid = cdt.np_array_of_dfs(y_test, y_proba_preds_grid.shape)\n",
    "\n",
    "        # Evaluate predictions by comparing to actuals, calculating 2D array of f1 scores. For now we use the default classification threshold of the bmo.grid_predict() method \n",
    "        f1_grid = bmo.calculate_f1_scores(y_binary_preds_grid, y_test_grid)\n",
    "\n",
    "        # Find index of best f1 score in the 2d array of f1 scores\n",
    "        best_row, best_col = np.unravel_index(np.argmax(f1_grid), f1_grid.shape)\n",
    "        \n",
    "        # Store hyperparameters of most accurate model for this inner fold\n",
    "        best_params.loc[i] = [axis1_params.values[best_row], axis2_params.values[best_col]]\n",
    "\n",
    "        # Find classification probability threshold between zero and one that yields lowest squared difference between sensitivity and \n",
    "        # specificity using this optimal model. To do this, we feed find_optimal_threshold() the probabilities predicted by the model, not the binary predictions.\n",
    "        best_model_y_preds = y_proba_preds_grid[best_row, best_col]\n",
    "        best_thresholds.iloc[i, 0] = bmo.find_optimal_threshold(y_test, best_model_y_preds)\n",
    "\n",
    "        # Create grid of ROC plots with predictions vs actuals, coloured by f1 score for each model\n",
    "        roc_grid = plot_shaded_roc_grids(y_proba_preds_grid, y_test_grid, axis1_params, axis2_params, f1_grid, plot_title, i)        \n",
    "        plt.savefig(f'{storage_dir}\\\\model_B, {train_model_callback.__name__}, ({plot_title}, Inner Fold {i}).svg', format=\"svg\")\n",
    "\n",
    "        plt.show(roc_grid)\n",
    "        plt.close(roc_grid)\n",
    "\n",
    "    # Calculate average best parameters over all inner folds to return to outer CV\n",
    "    avg_best_param1 = best_params['param1'].mean()\n",
    "    avg_best_param2 = best_params['param2'].mean()\n",
    "\n",
    "    # Calculate average best threshold over all folds\n",
    "    best_threshold = best_thresholds['threshold'].mean()\n",
    "\n",
    "    return avg_best_param1, avg_best_param2, best_threshold\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fba289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_CV_B(n_outer_splits: int, n_inner_splits: int, X : pd.DataFrame, y_cont : pd.DataFrame, axis1_params: mdo.AxisParams, \n",
    "               axis2_params: mdo.AxisParams, train_model_callback : callable, kfold_random_state: int, \n",
    "               classification_col : int, top_line_thresh : float, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform nested cross-validation with an outer and inner loop to evaluate model B performance.\n",
    "    Created: 2024/12/29\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_outer_splits : int\n",
    "        Number of splits for the outer cross-validation.\n",
    "    n_inner_splits : int\n",
    "        Number of splits for the inner cross-validation.\n",
    "    X : pd.DataFrame\n",
    "        Feature data.\n",
    "    y : pd.DataFrame\n",
    "        Target data.\n",
    "    axis1_params : mdo.AxisParams\n",
    "        Object representing hyperparameter search space for the first axis.\n",
    "    axis2_params : mdo.AxisParams\n",
    "        Object representing hyperparameter search space for the second axis.\n",
    "    train_model_callback : callable\n",
    "        Function to train the model.\n",
    "    kfold_random_state : int\n",
    "        Random state for reproducibility in KFold.\n",
    "    classification_col : int\n",
    "        Column index to pull classification probabilities from - 0 for not top, 1 for top.\n",
    "    top_line_thresh : float\n",
    "        Threshold to classify predictions as top or not top.\n",
    "    **kwargs : dict\n",
    "        Additional parameters for the model training function.\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing the metrics for each outer fold, including F1 Score, Sensitivity, Specificity, and Kappa.\n",
    "    \"\"\"\n",
    "\n",
    "    y_binary = bmo.classify_top(y_cont, top_line_thresh)\n",
    "    \n",
    "    kfold = KFold(n_splits=n_outer_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    # Store metrics of best model for each fold\n",
    "    kfold_metrics = pd.DataFrame(columns=['F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y_binary.iloc[train_index], y_binary.iloc[test_index]\n",
    "\n",
    "        # Find average best parameters and threshold based on f1 score using inner-fold CV\n",
    "        best_param1, best_param2, best_threshold = inner_CV_B(n_inner_splits, X_train, y_train, axis1_params, axis2_params, train_model_callback, kfold_random_state, classification_col, top_line_thresh, plot_title=f\"Outer Fold {i}\", **kwargs)\n",
    "\n",
    "        # Train model with all training and CV data of outer fold using mean best hyperparameters\n",
    "        super_model = train_model_callback(X_train, np.ravel(y_train), **dict(zip([axis1_params.name, axis2_params.name], [best_param1, best_param2])), **kwargs)\n",
    "\n",
    "        # Use trained \"super-model\" to predict test set probabilities\n",
    "        y_pred = pd.DataFrame(super_model.predict_proba(X_test)[:, classification_col], index=y_test.index, columns=y_test.columns)\n",
    "\n",
    "        # Calculate pearson coefficient of continuous predictions\n",
    "        pearson, _ = pearsonr(np.ravel(y_pred), np.ravel(y_test))\n",
    "        pearson = float(pearson)  # Convert numpy.float32 to Python float\n",
    "\n",
    "        # Classify predictions and actuals of super_model as top or not top (boolean) using the best threshold as determined by inner CV\n",
    "        y_pred_top = bmo.classify_top(y_pred, best_threshold)\n",
    "    \n",
    "        # Calculate classification metrics and add new row to kfold_metrics\n",
    "        classification_metrics = cdt.classification_metrics(y_pred_top, y_test)\n",
    "        kfold_metrics = pd.concat([kfold_metrics, classification_metrics], axis=0)\n",
    "\n",
    "    # Label each row of kfold_metrics with the fold number\n",
    "    kfold_metrics.index = range(n_outer_splits)\n",
    "    return kfold_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7457c6",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b684319b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "inner_CV_B() missing 1 required positional argument: 'top_line_thresh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m x_params_SVM_B \u001b[38;5;241m=\u001b[39m mdo\u001b[38;5;241m.\u001b[39mAxisParams(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m, bmo\u001b[38;5;241m.\u001b[39mpower_list(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      3\u001b[0m y_params_SVM_B \u001b[38;5;241m=\u001b[39m mdo\u001b[38;5;241m.\u001b[39mAxisParams(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, bmo\u001b[38;5;241m.\u001b[39mpower_list(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m16\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m metrics_SVM_B \u001b[38;5;241m=\u001b[39m \u001b[43mouter_CV_B\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_params_SVM_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_params_SVM_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbmo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_SVM_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkfold_random_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRANDOM_STATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrbf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_line_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOP_LINE_THRESH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m# Dummy values for tests\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03mx_params_SVM_B = mdo.AxisParams('gamma', bmo.power_list(2, -10, -9))\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03my_params_SVM_B = mdo.AxisParams('C', bmo.power_list(2, 0, 1))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mmetrics_SVM_B = outer_CV_B(2, 2, X_sc, y_sc, x_params_SVM_B, y_params_SVM_B, bmo.train_SVM_classifier, kfold_random_state=RANDOM_STATE, kernel='rbf', classification_col=1, top_line_thresh=TOP_LINE_THRESH, probability=True)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 49\u001b[0m, in \u001b[0;36mouter_CV_B\u001b[1;34m(n_outer_splits, n_inner_splits, X, y_cont, axis1_params, axis2_params, train_model_callback, kfold_random_state, classification_col, top_line_thresh, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y_binary\u001b[38;5;241m.\u001b[39miloc[train_index], y_binary\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Find average best parameters and threshold based on f1 score using inner-fold CV\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m best_param1, best_param2, best_threshold \u001b[38;5;241m=\u001b[39m \u001b[43minner_CV_B\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_inner_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis1_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis2_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_model_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkfold_random_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_title\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOuter Fold \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Train model with all training and CV data of outer fold using mean best hyperparameters\u001b[39;00m\n\u001b[0;32m     52\u001b[0m super_model \u001b[38;5;241m=\u001b[39m train_model_callback(X_train, np\u001b[38;5;241m.\u001b[39mravel(y_train), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m([axis1_params\u001b[38;5;241m.\u001b[39mname, axis2_params\u001b[38;5;241m.\u001b[39mname], [best_param1, best_param2])), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: inner_CV_B() missing 1 required positional argument: 'top_line_thresh'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Real test values\n",
    "x_params_SVM_B = mdo.AxisParams('gamma', bmo.power_list(2, -18, -8))\n",
    "y_params_SVM_B = mdo.AxisParams('C', bmo.power_list(2, 2, 16))\n",
    "metrics_SVM_B = outer_CV_B(10, 5, X_sc, y_sc, x_params_SVM_B, y_params_SVM_B, bmo.train_SVM_classifier, kfold_random_state=RANDOM_STATE, kernel='rbf', classification_col=1, top_line_thresh=TOP_LINE_THRESH, probability=True)\n",
    "\n",
    "\"\"\"\n",
    "# Dummy values for tests\n",
    "x_params_SVM_B = mdo.AxisParams('gamma', bmo.power_list(2, -10, -9))\n",
    "y_params_SVM_B = mdo.AxisParams('C', bmo.power_list(2, 0, 1))\n",
    "metrics_SVM_B = outer_CV_B(2, 2, X_sc, y_sc, x_params_SVM_B, y_params_SVM_B, bmo.train_SVM_classifier, kfold_random_state=RANDOM_STATE, kernel='rbf', classification_col=1, top_line_thresh=TOP_LINE_THRESH, probability=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7219ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification metrics for super-model trained on all data from each outer fold\n",
    "display(metrics_SVM_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc3995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "metrics_SVM_B_mean = metrics_SVM_B.mean().to_frame().T\n",
    "B_average_metrics.loc['SVM'] = metrics_SVM_B_mean.iloc[0]\n",
    "display(metrics_SVM_B_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf6cd8",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aeca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_params_XGB_B = mdo.AxisParams('n_estimators', [3, 7, 13, 25, 50, 100, 200, 400])\n",
    "y_params_XGB_B = mdo.AxisParams('max_depth', [1, 2, 3, 4, 6, 10, 16, 32, 64])\n",
    "metrics_XGB_B = outer_CV_B(10, 5, X_sc, y_sc, x_params_XGB_B, y_params_XGB_B, bmo.train_XGB_classifier, kfold_random_state=RANDOM_STATE, random_state=RANDOM_STATE, classification_col=1, top_line_thresh=TOP_LINE_THRESH, objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "\n",
    "\"\"\"\n",
    "# dummy values for quick tests\n",
    "x_params_XGB_B = mdo.AxisParams('n_estimators', [1, 2])\n",
    "y_params_XGB_B = mdo.AxisParams('max_depth', [1, 2])\n",
    "metrics_XGB_B = outer_CV_B(2, 2, X_sc, y_sc, x_params_XGB_B, y_params_XGB_B, bmo.train_XGB_classifier, kfold_random_state=RANDOM_STATE, random_state=RANDOM_STATE, classification_col=1, top_line_thresh=TOP_LINE_THRESH, objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display metrics\n",
    "display(metrics_XGB_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "metrics_XGB_B_mean = metrics_XGB_B.mean().to_frame().T\n",
    "B_average_metrics.loc['XGB'] = metrics_XGB_B_mean.iloc[0]\n",
    "display(metrics_XGB_B_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc98a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save serialized session variables and models to disk for later use\n",
    "dill.dump_session(f'{storage_dir}\\\\project_ipynb_env_B.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de75da",
   "metadata": {},
   "source": [
    "# Model RO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82681b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV_RO(n_splits: int, X : pd.DataFrame, y : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback, kfold_random_state: int, top_line_threshold: float, plot_title: str = \"\", **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Perform inner cross-validation (RO) to find the best model parameters and classification threshold.\n",
    "    Created: 2024/12/21\n",
    "    Parameters:\n",
    "    n_splits (int): Number of splits for K-Fold cross-validation.\n",
    "    X (pd.DataFrame): Feature data.\n",
    "    y (pd.DataFrame): Target data.\n",
    "    axis1_params (mdo.AxisParams): Hyperparameters to explore for the horizontal axis.\n",
    "    axis2_params (mdo.AxisParams): Hyperparameters to explore for the vertical axis.\n",
    "    train_model_callback (callable): Callback function to train the model.\n",
    "    kfold_random_state (int): Random state for K-Fold shuffling.\n",
    "    top_line_threshold (float): Threshold to classify top values during intermediate step in inner CV.\n",
    "    plot_title (str, optional): Title for the plot. Defaults to \"\".\n",
    "    **kwargs: Additional keyword arguments for the model training callback.\n",
    "    Returns:\n",
    "    tuple: Average best parameters for axis1 and axis2, and the best classification threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create KFold object for inner-fold cross-validation\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    # Store best parameters (param1, param2) for each fold\n",
    "    best_params = pd.DataFrame(columns=['param1', 'param2'], index=range(n_splits))\n",
    "    best_thresholds = pd.DataFrame(columns=['threshold'], index=range(n_splits))\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train numpy 2D array of models with every combination of parameters\n",
    "        model_grid = bmo.train_model_grid(X_train, y_train, axis1_params, axis2_params, train_model_callback, **kwargs)\n",
    "\n",
    "        # Use trained models to predict test set labels, and store in 2D array with each cell corresponding to a model with specific combination of parameters\n",
    "        y_preds_grid = bmo.grid_predict(X_test, model_grid)\n",
    "\n",
    "        # Create 2D array of identical dataframes containing actual labels to compare against predictions\n",
    "        y_test_grid = cdt.np_array_of_dfs(y_test, y_preds_grid.shape)\n",
    "\n",
    "        # Evaluate predictions by comparing to actuals, calculating 2D array of pearson coefficients\n",
    "        pearson_grid = bmo.calculate_pearson_coefficients(y_preds_grid, y_test_grid)\n",
    "\n",
    "        # Find index of best pearson coefficient in the 2d array of pearson coefficients\n",
    "        best_row, best_col = np.unravel_index(np.argmax(pearson_grid), pearson_grid.shape)\n",
    "        \n",
    "        # Store hyperparameters of most accurate model for this inner fold\n",
    "        best_params.loc[i] = [axis1_params.values[best_row], axis2_params.values[best_col]]\n",
    "\n",
    "        # Extract best model's continuous predictions\n",
    "        best_model_y_preds = y_preds_grid[best_row, best_col]\n",
    "\n",
    "        # Classify labels as top or not top (boolean)\n",
    "        y_test_binary = bmo.classify_top(y_test, top_line_threshold)\n",
    "\n",
    "        # Transform continuous predictions of best model to range [0, 1]\n",
    "        best_model_y_preds_transformed = (best_model_y_preds - best_model_y_preds.min()) / (best_model_y_preds.max() - best_model_y_preds.min())\n",
    "        \n",
    "        # Find classification threshold that yields lowest squared difference between sensitivity and specificity using this optimal model\n",
    "        best_thresholds.iloc[i, 0] = bmo.find_optimal_threshold(y_test_binary, best_model_y_preds_transformed)\n",
    "\n",
    "        # Create grid of scatter plots with predictions vs actuals, coloured by pearson coefficient for each model\n",
    "        scatter_grid = plot_shaded_scatter_grids(y_preds_grid, y_test_grid, axis1_params, axis2_params, pearson_grid, plot_title, i)        \n",
    "        plt.savefig(f'{storage_dir}\\\\model_RO, {train_model_callback.__name__}, ({plot_title}, Inner Fold {i}).svg', format=\"svg\")\n",
    "        \n",
    "        plt.show(scatter_grid)\n",
    "        plt.close(scatter_grid)\n",
    "\n",
    "    # Calculate average best parameters over all folds\n",
    "    avg_best_param1 = best_params['param1'].mean()\n",
    "    avg_best_param2 = best_params['param2'].mean()\n",
    "\n",
    "    # Calculate average best threshold over all folds\n",
    "    best_threshold = best_thresholds['threshold'].mean()\n",
    "\n",
    "    return avg_best_param1, avg_best_param2, best_threshold\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02c7b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_CV_RO(n_outer_splits: int, n_inner_splits: int, X : pd.DataFrame, y : pd.DataFrame, axis1_params: mdo.AxisParams, axis2_params: mdo.AxisParams, train_model_callback : callable, kfold_random_state: int, top_line_threshold : float, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform outer cross-validation with nested inner cross-validation for model RO selection and evaluation.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_outer_splits : int\n",
    "        Number of splits for the outer cross-validation.\n",
    "    n_inner_splits : int\n",
    "        Number of splits for the inner cross-validation.\n",
    "    X : pd.DataFrame\n",
    "        Feature data.\n",
    "    y : pd.DataFrame\n",
    "        Target data.\n",
    "    axis1_params : mdo.AxisParams\n",
    "        Object representing hyperparameter search space for the first axis.\n",
    "    axis2_params : mdo.AxisParams\n",
    "        Object representing hyperparameter search space for the second axis.\n",
    "    train_model_callback : callable\n",
    "        Callback function to train the model.\n",
    "    kfold_random_state : int\n",
    "        Random state for reproducibility in KFold splitting.\n",
    "    top_line_threshold : float\n",
    "        Threshold for classifying top predictions during intermediate step in inner CV.\n",
    "    **kwargs : dict\n",
    "        Additional parameters for the model training callback.\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing the evaluation metrics for each outer fold, including Pearson correlation, F1 Score, Sensitivity, Specificity, and Kappa.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create KFold object for outer loop to split data into train and test sets\n",
    "    kfold = KFold(n_splits=n_outer_splits, shuffle=True, random_state=kfold_random_state)\n",
    "\n",
    "    kfold_metrics = pd.DataFrame(columns=['Pearson', 'F1 Score', 'Sensitivity', 'Specificity', 'Kappa'])\n",
    "\n",
    "    # Iterate through each train-test split\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Find average best parameters and threshold based on pearson score using inner-fold CV\n",
    "        best_param1, best_param2, best_threshold = inner_CV_RO(n_inner_splits, X_train, y_train, axis1_params, axis2_params, train_model_callback, kfold_random_state, top_line_threshold=TOP_LINE_THRESH, plot_title=f\"Outer Fold {i}\", **kwargs)\n",
    "\n",
    "        # Train model with all training and CV data of outer fold using mean best hyperparameters\n",
    "        super_model = train_model_callback(X_train, np.ravel(y_train), **dict(zip([axis1_params.name, axis2_params.name], [best_param1, best_param2])), **kwargs)\n",
    "\n",
    "        # Use trained \"super-model\" to predict test set\n",
    "        y_pred = pd.DataFrame(super_model.predict(X_test), index=y_test.index, columns=y_test.columns)\n",
    "\n",
    "        # Calculate pearson coefficient of continuous predictions\n",
    "        pearson, _ = pearsonr(np.ravel(y_pred), np.ravel(y_test))\n",
    "\n",
    "        # Classify predictions and actuals of super_model as top or not top (boolean)\n",
    "        y_pred_top = bmo.classify_top(y_pred, best_threshold)\n",
    "        y_test_top = bmo.classify_top(y_test, best_threshold)\n",
    "\n",
    "        # Calculate classification metrics and add new row to kfold_metrics\n",
    "        classification_metrics = cdt.classification_metrics(y_pred_top, y_test_top)\n",
    "        pearson_df = pd.DataFrame([pearson], columns=['Pearson'])\n",
    "        metrics_row = pd.concat([pearson_df, classification_metrics], axis=1)\n",
    "        kfold_metrics = pd.concat([kfold_metrics, metrics_row], axis=0)\n",
    "    \n",
    "    kfold_metrics.index = range(n_outer_splits)\n",
    "    return kfold_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac635306",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e7c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_params_SVM_RO = mdo.AxisParams('gamma', bmo.power_list(2, -14, -6))\n",
    "y_params_SVM_RO = mdo.AxisParams('C', bmo.power_list(2, -2, 6))\n",
    "\n",
    "metrics_SVM_RO = outer_CV_RO(10, 5, X_sc, y_sc, x_params_SVM_RO, y_params_SVM_RO, bmo.train_SVM_regressor, kfold_random_state=RANDOM_STATE, top_line_threshold=TOP_LINE_THRESH, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975314ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display metrics\n",
    "display(metrics_SVM_RO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb307e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "metrics_SVM_RO_mean = metrics_SVM_RO.mean().to_frame().T\n",
    "RO_average_metrics.loc['SVM'] = metrics_SVM_RO_mean.iloc[0]\n",
    "display(metrics_SVM_RO_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2313db",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_params_XGB_RO = mdo.AxisParams('n_estimators', [3, 7, 13, 25, 50, 100, 200])\n",
    "y_params_XGB_RO = mdo.AxisParams('max_depth', [1, 2, 3, 4, 6, 10, 16, 32, 64])\n",
    "metrics_XGB_RO = outer_CV_RO(10, 5, X_sc, y_sc, x_params_XGB_RO, y_params_XGB_RO, bmo.train_XGB_regressor, kfold_random_state=RANDOM_STATE, random_state=RANDOM_STATE, objective=\"reg:squarederror\", eval_metric=\"rmse\", top_line_threshold=TOP_LINE_THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37545449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display metrics\n",
    "display(metrics_XGB_RO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521925c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average of each metric\n",
    "metrics_XGB_RO_mean = metrics_XGB_RO.mean().to_frame().T\n",
    "RO_average_metrics.loc['XGB'] = metrics_XGB_RO_mean.iloc[0]\n",
    "display(metrics_XGB_RO_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf6b4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save serialized session variables and models to disk for later use\n",
    "dill.dump_session(f'{storage_dir}\\\\project_ipynb_env_RO.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cdc2c5",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3691a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average metrics for each model to compare GBLUP, SVM, and XGB\n",
    "R_avg_metrics_plot = cmp.plot_model_metrics(R_average_metrics, \"R\")\n",
    "R_avg_metrics_plot.savefig(f'{storage_dir}\\\\R_avg_metrics_plot.svg', format='svg')\n",
    "plt.show(R_avg_metrics_plot)\n",
    "plt.close(R_avg_metrics_plot)\n",
    "\n",
    "B_avg_metrics_plot = cmp.plot_model_metrics(B_average_metrics, \"B\")\n",
    "B_avg_metrics_plot.savefig(f'{storage_dir}\\\\B_avg_metrics_plot.svg', format='svg')\n",
    "plt.show(B_avg_metrics_plot)\n",
    "plt.close(B_avg_metrics_plot)\n",
    "\n",
    "RO_avg_metrics_plot = cmp.plot_model_metrics(RO_average_metrics, \"RO\")\n",
    "RO_avg_metrics_plot.savefig(f'{storage_dir}\\\\RO_avg_metrics_plot.svg', format='svg')\n",
    "plt.show(RO_avg_metrics_plot)\n",
    "plt.close(RO_avg_metrics_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
